<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>3. Training a self-supervised model (CPC) &mdash; SSLTools  documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=19f00094" />
      <link rel="stylesheet" type="text/css" href="../_static/graphviz.css?v=eafc0fe6" />
      <link rel="stylesheet" type="text/css" href="../_static/nbsphinx-code-cells.css" />

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../_static/jquery.js?v=5d32c60e"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../_static/documentation_options.js?v=5929fcd5"></script>
        <script src="../_static/doctools.js?v=888ff710"></script>
        <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
        <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Using Experiments" href="04_using_experiments.html" />
    <link rel="prev" title="2. Training a Pytorch Lighning model" href="02_training_model.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            SSLTools
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../tutorials.html">Tutorials</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="01_structuring_input.html">1. Structuring the input</a></li>
<li class="toctree-l2"><a class="reference internal" href="02_training_model.html">2. Training a Pytorch Lighning model</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">3. Training a self-supervised model (CPC)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Pre-training-the-model">Pre-training the model</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#Creating-the-LightningDataModule">Creating the LightningDataModule</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id1">Pre-training the model</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#Fine-tuning-the-model">Fine-tuning the model</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id2">Creating the LightningDataModule</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id3">Fine-tuning the model</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#Next-steps">Next steps</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="04_using_experiments.html">Using Experiments</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../experiments.html">Running Experiments</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contributing.html">Contributing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api.html">Programming Reference</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">SSLTools</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../tutorials.html">Tutorials</a></li>
      <li class="breadcrumb-item active">3. Training a self-supervised model (CPC)</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/notebooks/03_training_ssl_model.ipynb.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="3.-Training-a-self-supervised-model-(CPC)">
<h1>3. Training a self-supervised model (CPC)<a class="headerlink" href="#3.-Training-a-self-supervised-model-(CPC)" title="Link to this heading"></a></h1>
<p>In this notebook, we will train a self-supervised model using the Contrastive Predictive Coding (CPC) method. This method is based on the idea of predicting future tokens in a sequence, and it has been shown to be very effective in learning useful representations for downstream tasks. This framework already provides an implementation of CPC, so we will use it to train the model.</p>
<p>We will pre-train the model using KuHar dataset, and then we will use the learned representations to train a classifier for the downstream task. For both stages of training, as the last notebook, we will:</p>
<ol class="arabic simple">
<li><p>Create a <code class="docutils literal notranslate"><span class="pre">Dataset</span></code> and then <code class="docutils literal notranslate"><span class="pre">LightningDataModule</span></code> to load the data;</p></li>
<li><p>Instantiate the CPC model; and</p></li>
<li><p>Train the model using PyTorch Lightning.</p></li>
</ol>
<p>We can instantiate the model in two ways: 1. Instantiate each element, such as the encoder, the autoregressive model, and the CPC model, and then pass them to the CPC model; or 2. Using builder methods to instantiate the model. In this case, we do not need to instantiate each element separately, but we can still customize the model by passing the desired parameters to the builder methods. This is the approach we will use in this notebook.</p>
<p>In summary, the second approach encapsulates the first one, making it easier to use and it is more convenient for our purposes.</p>
<section id="Pre-training-the-model">
<h2>Pre-training the model<a class="headerlink" href="#Pre-training-the-model" title="Link to this heading"></a></h2>
<p>We will pre-train the model using the KuHar dataset. CPC is a self-supervised method, so we do not need labels to train the model. However, CPC assumes that the input data is sequential, that is, an input is a sequence of time-steps comprising different acitivities. Thus, for HAR, usually, one sample (a multi-modal time-series) correspond to the whole time-series of a single user.</p>
<section id="Creating-the-LightningDataModule">
<h3>Creating the LightningDataModule<a class="headerlink" href="#Creating-the-LightningDataModule" title="Link to this heading"></a></h3>
<p>Our dataset must be organized in the following way:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>data/
    train/
        user1.csv
        user2.csv
        ...
    validation/
        user4.csv
        user5.csv
        ...
    test/
        user6.csv
        user7.csv
        ...
</pre></div>
</div>
<p>And the content of each file should be something like:</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>timestamp</p></th>
<th class="head"><p>accel-x</p></th>
<th class="head"><p>accel-y</p></th>
<th class="head"><p>accel-z</p></th>
<th class="head"><p>gyro-x</p></th>
<th class="head"><p>gyro-y</p></th>
<th class="head"><p>gyro-z</p></th>
<th class="head"><p>activity</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>0</p></td>
<td><p>0.1</p></td>
<td><p>0.2</p></td>
<td><p>0.3</p></td>
<td><p>0.4</p></td>
<td><p>0.5</p></td>
<td><p>0.6</p></td>
<td><p>0</p></td>
</tr>
<tr class="row-odd"><td><p>1</p></td>
<td><p>0.2</p></td>
<td><p>0.3</p></td>
<td><p>0.4</p></td>
<td><p>0.5</p></td>
<td><p>0.6</p></td>
<td><p>0.7</p></td>
<td><p>0</p></td>
</tr>
<tr class="row-even"><td><p>…</p></td>
<td><p>…</p></td>
<td><p>…</p></td>
<td><p>…</p></td>
<td><p>…</p></td>
<td><p>…</p></td>
<td><p>…</p></td>
<td><p>…</p></td>
</tr>
</tbody>
</table>
<p>Where <code class="docutils literal notranslate"><span class="pre">timestamp</span></code> is the time-stamp of the sample, <code class="docutils literal notranslate"><span class="pre">accel-x</span></code>, <code class="docutils literal notranslate"><span class="pre">accel-y</span></code>, <code class="docutils literal notranslate"><span class="pre">accel-z</span></code>, <code class="docutils literal notranslate"><span class="pre">gyro-x</span></code>, <code class="docutils literal notranslate"><span class="pre">gyro-y</span></code>, and <code class="docutils literal notranslate"><span class="pre">gyro-z</span></code> are the features of the sample, and <code class="docutils literal notranslate"><span class="pre">activity</span></code> is the label of the time-step.</p>
<p>In this way, we should use the <code class="docutils literal notranslate"><span class="pre">SeriesFolderCSVDataset</span></code> to load the data. This will create a <code class="docutils literal notranslate"><span class="pre">Dataset</span></code> for us, where each CSV file is a sample, and each row of the CSV file is a time-step, and the columns are the features.</p>
<blockquote>
<div><p><strong>NOTE</strong>: The samples may have different lengths, so, for this method, the <code class="docutils literal notranslate"><span class="pre">batch_size</span></code> must be 1.</p>
</div></blockquote>
<p>If your data is organized as above, where inside the root folder (<code class="docutils literal notranslate"><span class="pre">data/</span></code> in this case) there are sub-folders for each split (<code class="docutils literal notranslate"><span class="pre">train/</span></code>, <code class="docutils literal notranslate"><span class="pre">validation/</span></code>, and <code class="docutils literal notranslate"><span class="pre">test/</span></code>), and inside each split folder there are the CSV files, you can use the <code class="docutils literal notranslate"><span class="pre">UserActivityFolderDataModule</span></code> to create a <code class="docutils literal notranslate"><span class="pre">LightningDataModule</span></code> for you. This class will create <code class="docutils literal notranslate"><span class="pre">DataLoader</span></code> of <code class="docutils literal notranslate"><span class="pre">SeriesFolderCSVDataset</span></code> for each split (train, validation, and test), and will setup data correctly.</p>
<p>In this notebook, we will use the <code class="docutils literal notranslate"><span class="pre">UserActivityFolderDataModule</span></code> to create the <code class="docutils literal notranslate"><span class="pre">LightningDataModule</span></code> for us. This class minimally requires: - <code class="docutils literal notranslate"><span class="pre">data_path</span></code>: the root directory of the data; - <code class="docutils literal notranslate"><span class="pre">features</span></code>: the name of the features columns; - <code class="docutils literal notranslate"><span class="pre">pad</span></code>: a boolean indicating if the samples should be padded to the same length, that is, the length of the longest sample in the dataset. The padding scheme will replicate the samples, from the beginning, until the length of the longest sample is
reached.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">ssl_tools.data.data_modules</span> <span class="kn">import</span> <span class="n">UserActivityFolderDataModule</span>

<span class="n">data_path</span> <span class="o">=</span> <span class="s2">&quot;/workspaces/hiaac-m4/data/view_concatenated/KuHar_cpc&quot;</span>

<span class="n">data_module</span> <span class="o">=</span> <span class="n">UserActivityFolderDataModule</span><span class="p">(</span>
    <span class="n">data_path</span><span class="p">,</span>
    <span class="n">features</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;accel-x&quot;</span><span class="p">,</span> <span class="s2">&quot;accel-y&quot;</span><span class="p">,</span> <span class="s2">&quot;accel-z&quot;</span><span class="p">,</span> <span class="s2">&quot;gyro-x&quot;</span><span class="p">,</span> <span class="s2">&quot;gyro-y&quot;</span><span class="p">,</span> <span class="s2">&quot;gyro-z&quot;</span><span class="p">),</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>       <span class="c1"># We set to 1 for CPC</span>
    <span class="n">label</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>         <span class="c1"># We do not want to return the labels, only data.</span>
    <span class="n">pad</span><span class="o">=</span><span class="kc">False</span>           <span class="c1"># If you want padded data, set it to True.</span>
                        <span class="c1">#   This guarantees that all data have the same length.</span>
<span class="p">)</span>

<span class="n">data_module</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
UserActivityFolderDataModule(data_path=/workspaces/hiaac-m4/data/view_concatenated/KuHar_cpc, batch_size=1)
</pre></div></div>
</div>
</section>
<section id="id1">
<h3>Pre-training the model<a class="headerlink" href="#id1" title="Link to this heading"></a></h3>
<p>Here we will use the builder method <code class="docutils literal notranslate"><span class="pre">build_cpc</span></code> to instantiate the CPC model. This will instantiate an CPC self-supervised model, with the default encoder (<code class="docutils literal notranslate"><span class="pre">ssl_tools.models.layers.gru.GRUEncoder</span></code>), that is an GRU+Linear, and the default autoregressive model (<code class="docutils literal notranslate"><span class="pre">torch.nn.GRU</span></code>), a linear layer.</p>
<p>We can parametrize the creation of the model by passing the desired parameters to the builder method. The <code class="docutils literal notranslate"><span class="pre">build_cpc</span></code> method can be parametrized the following parameters: - <code class="docutils literal notranslate"><span class="pre">encoding_size</span></code>: the size of the encoded representation; - <code class="docutils literal notranslate"><span class="pre">in_channels</span></code>: number of input features; - <code class="docutils literal notranslate"><span class="pre">gru_hidden_size</span></code>: number of features in the hidden state of the GRU; - <code class="docutils literal notranslate"><span class="pre">gru_num_layers</span></code>: number of layers in the GRU; - <code class="docutils literal notranslate"><span class="pre">learning_rate</span></code>: the learning rate of the optimizer; - <code class="docutils literal notranslate"><span class="pre">window_size</span></code> : size of the input
windows (<code class="docutils literal notranslate"><span class="pre">X_t</span></code>) to be fed to the encoder (GRU).</p>
<p>All parameters are optional, and have default values. You may want to consult the documentation of the method to see the default values and additional parameters.</p>
<p>Note that the <code class="docutils literal notranslate"><span class="pre">LightningModule</span></code> returned by the <code class="docutils literal notranslate"><span class="pre">build_cpc</span></code> method is already configured to use the <code class="docutils literal notranslate"><span class="pre">CPC</span></code> loss, and the <code class="docutils literal notranslate"><span class="pre">Adam</span></code> optimizer.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ssl_tools.models.ssl.cpc</span> <span class="kn">import</span> <span class="n">build_cpc</span>
<span class="n">encoding_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">in_channels</span> <span class="o">=</span> <span class="mi">6</span>
<span class="n">gru_hidden_size</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">gru_num_layers</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">1e-3</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">build_cpc</span><span class="p">(</span>
    <span class="n">encoding_size</span><span class="o">=</span><span class="n">encoding_size</span><span class="p">,</span>
    <span class="n">in_channels</span><span class="o">=</span><span class="n">in_channels</span><span class="p">,</span>
    <span class="n">gru_hidden_size</span><span class="o">=</span><span class="n">gru_hidden_size</span><span class="p">,</span>
    <span class="n">gru_num_layers</span><span class="o">=</span><span class="n">gru_num_layers</span><span class="p">,</span>
    <span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span>
<span class="p">)</span>
<span class="n">model</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
CPC(
  (encoder): GRUEncoder(
    (rnn): GRU(6, 100, bidirectional=True)
    (nn): Linear(in_features=200, out_features=128, bias=True)
  )
  (density_estimator): Linear(in_features=128, out_features=128, bias=True)
  (auto_regressor): GRU(128, 128, batch_first=True)
  (loss_func): CrossEntropyLoss()
)
</pre></div></div>
</div>
<p>We instantiate the Trainer and call the <code class="docutils literal notranslate"><span class="pre">fit</span></code> method to train the model.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">lightning</span> <span class="k">as</span> <span class="nn">L</span>

<span class="n">max_epochs</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">L</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span><span class="n">max_epochs</span><span class="o">=</span><span class="n">max_epochs</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data_module</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]

  | Name              | Type             | Params
-------------------------------------------------------
0 | encoder           | GRUEncoder       | 90.5 K
1 | density_estimator | Linear           | 16.5 K
2 | auto_regressor    | GRU              | 99.1 K
3 | loss_func         | CrossEntropyLoss | 0
-------------------------------------------------------
206 K     Trainable params
0         Non-trainable params
206 K     Total params
0.824     Total estimated model params size (MB)
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "ae5e2aa76b724bd28d4a6a30a24741b6", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "09c22282fde24cfd9de81b97f95e86fd", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "bef77ce96a814d7285754998c34e9ac9", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "1937e63c20084b50bb692146e61413a1", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "f69d85b4c6d740a69283266cec51d423", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "b646a368e4604032afa6c76ad58e442c", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "34378bbe5c29451b8e8699f5d5e5c5f3", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "7eb66332ab514500beab85981de2cc86", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "c497708ecea642399c3972d6588834dc", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "81d632bcc570499580819d00fad1f48c", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "5f64cf4dbb41406da82a5a8028f50080", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "2c930a3f8e18484bb2fc18b2a4773d1a", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
`Trainer.fit` stopped: `max_epochs=10` reached.
</pre></div></div>
</div>
<p>This finishes the pre-training stage.</p>
<p>To obtain the latent representations of the data, we must use cpc <code class="docutils literal notranslate"><span class="pre">forward</span></code> method on the data. In this framework, the <code class="docutils literal notranslate"><span class="pre">forward</span></code> method of the SSL models returns the latent representations of the input data. Usually this is the output of the encoder, as in this case, but it may vary depending on the model.</p>
<p>We will use the encoder to obtain the latent representations of the data, and then we will use these representations to train a classifier for the downstream task.</p>
</section>
</section>
<section id="Fine-tuning-the-model">
<h2>Fine-tuning the model<a class="headerlink" href="#Fine-tuning-the-model" title="Link to this heading"></a></h2>
<p>After pre-training the model, we will use the learned representations to train a classifier for the downstream task, in this case, the HAR task.</p>
<blockquote>
<div><p><strong>NOTE</strong>: It is important that the SSL models implement the <code class="docutils literal notranslate"><span class="pre">forward</span></code> method to return the latent representations of the input data, so we can use these representations to train the classifier.</p>
</div></blockquote>
<section id="id2">
<h3>Creating the LightningDataModule<a class="headerlink" href="#id2" title="Link to this heading"></a></h3>
<p>Human acivity recognition is a supervised classification task, that usually receives multi-modal windowed time-series as input, diferently from the self-supervised task, that receives the whole time-series of a single user. Thus, we cannot use the same <code class="docutils literal notranslate"><span class="pre">LightningDataModule</span></code> to load the data for the downstream task.</p>
<p>In this notebook, we will use the windowed time-series version of the KuHar dataset, that each split is a single CSV file, containing windowed time-series of the users. The content of the file should be something like:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>KuHar/
    train.csv
    validation.csv
    test.csv
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">train.csv</span></code> file may look like this:</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>accel-x-0</p></th>
<th class="head"><p>accel-x-1</p></th>
<th class="head"><p>accel-y-0</p></th>
<th class="head"><p>accel-y-1</p></th>
<th class="head"><p>class</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>0.502123</p></td>
<td><p>0.02123</p></td>
<td><p>0.502123</p></td>
<td><p>0.502123</p></td>
<td><p>0</p></td>
</tr>
<tr class="row-odd"><td><p>0.6820123</p></td>
<td><p>0.02123</p></td>
<td><p>0.502123</p></td>
<td><p>0.502123</p></td>
<td><p>1</p></td>
</tr>
<tr class="row-even"><td><p>0.498217</p></td>
<td><p>0.00001</p></td>
<td><p>1.414141</p></td>
<td><p>3.141592</p></td>
<td><p>1</p></td>
</tr>
</tbody>
</table>
<p>As each CSV file contains time-windows signals of two 3-axis sensors (accelerometer and gyroscope), we must use the <code class="docutils literal notranslate"><span class="pre">MultiModalSeriesCSVDataset</span></code> class.</p>
<p>As in last notebook, we will use the <code class="docutils literal notranslate"><span class="pre">MultiModalHARSeriesDataModule</span></code> to facilitate the creation of the <code class="docutils literal notranslate"><span class="pre">LightningDataModule</span></code>. This class will create <code class="docutils literal notranslate"><span class="pre">DataLoader</span></code> of <code class="docutils literal notranslate"><span class="pre">MultiModalSeriesCSVDataset</span></code> for each split (train, validation, and test), and will setup data correctly.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ssl_tools.data.data_modules.har</span> <span class="kn">import</span> <span class="n">MultiModalHARSeriesDataModule</span>

<span class="n">data_path</span> <span class="o">=</span> <span class="s2">&quot;/workspaces/hiaac-m4/ssl_tools/data/standartized_balanced/KuHar/&quot;</span>

<span class="n">data_module</span> <span class="o">=</span> <span class="n">MultiModalHARSeriesDataModule</span><span class="p">(</span>
    <span class="n">data_path</span><span class="o">=</span><span class="n">data_path</span><span class="p">,</span>
    <span class="n">feature_prefixes</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;accel-x&quot;</span><span class="p">,</span> <span class="s2">&quot;accel-y&quot;</span><span class="p">,</span> <span class="s2">&quot;accel-z&quot;</span><span class="p">,</span> <span class="s2">&quot;gyro-x&quot;</span><span class="p">,</span> <span class="s2">&quot;gyro-y&quot;</span><span class="p">,</span> <span class="s2">&quot;gyro-z&quot;</span><span class="p">),</span>
    <span class="n">label</span><span class="o">=</span><span class="s2">&quot;standard activity code&quot;</span><span class="p">,</span>
    <span class="n">features_as_channels</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
    <span class="n">num_workers</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>  <span class="c1"># Sequential, for notebook compatibility</span>
<span class="p">)</span>
<span class="n">data_module</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
MultiModalHARSeriesDataModule(data_path=/workspaces/hiaac-m4/ssl_tools/data/standartized_balanced/KuHar, batch_size=64)
</pre></div></div>
</div>
</section>
<section id="id3">
<h3>Fine-tuning the model<a class="headerlink" href="#id3" title="Link to this heading"></a></h3>
<p>A model for a downstream task is usually composed of two parts: the backbone model, that is the model that generates the representations of the input data, <em>i.e.</em>, the encoder, and the prediction head, which is the model that receives the representations and outputs the predictions, usually, a MLP.</p>
<p>To handle the fine-tune process, we can design a new model, that is composed of the pre-trained backbone and the prediction head, and then train this new model with the labeled data. In order to facilitate this process, this framework provides the <code class="docutils literal notranslate"><span class="pre">SSLDiscriminator</span></code> class, that receives the backbone model and the prediction head, and then trains the classifier with the labeled data.</p>
<p>In summary, the <code class="docutils literal notranslate"><span class="pre">SSLDiscriminator</span></code> class is a <code class="docutils literal notranslate"><span class="pre">LightningModule</span></code> that generate the representations of the input data using the backbone model, that is, using the <code class="docutils literal notranslate"><span class="pre">forward</span></code> method of the backbone model, and then uses the prediction head to output the predictions. The predictions and labels are then used to compute the loss and train the model. By default, the <code class="docutils literal notranslate"><span class="pre">SSLDiscriminator</span></code> is trained using the <code class="docutils literal notranslate"><span class="pre">Adam</span></code> optimizer with the <code class="docutils literal notranslate"><span class="pre">learning_rate</span></code> defined by the user (1e-3 by default).</p>
<p>It worth to mention that the <code class="docutils literal notranslate"><span class="pre">SSLDiscriminator</span></code> class <code class="docutils literal notranslate"><span class="pre">forward</span></code> method receives the input data and the labels, and returns the predictions. This is different from the <code class="docutils literal notranslate"><span class="pre">forward</span></code> method of the self-supervised models, that receives only the input data and returns the latent representations of the input data.</p>
<p>It worth to notice that the fine-tune train process can be done in two ways: 1. Fine-tuning the whole model, that is, backbone (encoder) and classifier, with the labeled data; or 2. Fine-tuning only the classifier, with the labeled data. The <code class="docutils literal notranslate"><span class="pre">SSLDisriminator</span></code> class can handle both cases, with the <code class="docutils literal notranslate"><span class="pre">update_backbone</span></code> parameter. If <code class="docutils literal notranslate"><span class="pre">update_backbone</span></code> is <code class="docutils literal notranslate"><span class="pre">True</span></code>, the whole model is fine-tuned (case 1, above), otherwise, only the classifier is fine-tuned (case 2, above).</p>
<p>Let’s create our prediction head and <code class="docutils literal notranslate"><span class="pre">SSLDisriminator</span></code> model and train it with the labeled data. Prediction heads for most popular tasks are already implemented in the <code class="docutils literal notranslate"><span class="pre">ssl_tools.models.ssl.modules.heads</span></code> module. In this notebook, we will use the <code class="docutils literal notranslate"><span class="pre">CPCPredictionHead</span></code> prediction head, that is a MLP with 3 hidden layers and dropout.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ssl_tools.models.ssl.classifier</span> <span class="kn">import</span> <span class="n">SSLDiscriminator</span>
<span class="kn">from</span> <span class="nn">ssl_tools.models.ssl.modules.heads</span> <span class="kn">import</span> <span class="n">CPCPredictionHead</span>

<span class="n">number_of_classes</span> <span class="o">=</span> <span class="mi">6</span>

<span class="n">prediction_head</span> <span class="o">=</span> <span class="n">CPCPredictionHead</span><span class="p">(</span>
    <span class="n">input_dim</span><span class="o">=</span><span class="n">encoding_size</span><span class="p">,</span>                <span class="c1"># Size of the encoding (input)</span>
    <span class="n">hidden_dim1</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
    <span class="n">hidden_dim2</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
    <span class="n">output_dim</span><span class="o">=</span><span class="n">number_of_classes</span>            <span class="c1"># Number of classes</span>
<span class="p">)</span>

<span class="n">prediction_head</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
CPCPredictionHead(
  (layers): Sequential(
    (0): Linear(in_features=128, out_features=64, bias=True)
    (1): ReLU()
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): Sequential(
      (0): ReLU()
      (1): Dropout(p=0, inplace=False)
    )
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Softmax(dim=1)
  )
)
</pre></div></div>
</div>
<p>We will create the <code class="docutils literal notranslate"><span class="pre">SSLDisriminator</span></code> model. The <code class="docutils literal notranslate"><span class="pre">SSLDisriminator</span></code> minimally requires: - <code class="docutils literal notranslate"><span class="pre">backbone</span></code>: the backbone model, that is, the pre-trained model; - <code class="docutils literal notranslate"><span class="pre">head</span></code>: the prediction head model; - <code class="docutils literal notranslate"><span class="pre">loss_fn</span></code>: the loss function to be used to train the model;</p>
<p>Also, we can attach metrics that will be calculated with for every batch of <code class="docutils literal notranslate"><span class="pre">validation</span></code> and <code class="docutils literal notranslate"><span class="pre">test</span></code> sets. The metrics is passed using the <code class="docutils literal notranslate"><span class="pre">metrics</span></code> parameter of the <code class="docutils literal notranslate"><span class="pre">SSLDisriminator</span></code> class, that receives a dictionary with the name of the metric as key and the <code class="docutils literal notranslate"><span class="pre">torchmetrics.Metric</span></code> as value.</p>
<p>Let’s create the <code class="docutils literal notranslate"><span class="pre">SSLDiscriminator</span></code> and attach the <code class="docutils literal notranslate"><span class="pre">Accuracy</span></code> metric to the model, to check the validation accuracy per epoch.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torchmetrics</span> <span class="kn">import</span> <span class="n">Accuracy</span>
<span class="kn">from</span> <span class="nn">torch.nn</span> <span class="kn">import</span> <span class="n">CrossEntropyLoss</span>

<span class="n">acc_metric</span> <span class="o">=</span> <span class="n">Accuracy</span><span class="p">(</span>
    <span class="n">task</span><span class="o">=</span><span class="s2">&quot;multiclass&quot;</span><span class="p">,</span>              <span class="c1"># We are working with a multiclass</span>
                                    <span class="c1">#   classification, not a binary one.</span>
    <span class="n">num_classes</span><span class="o">=</span><span class="n">number_of_classes</span>   <span class="c1"># Number of classes</span>
<span class="p">)</span>

<span class="n">ssl_discriminator</span> <span class="o">=</span> <span class="n">SSLDiscriminator</span><span class="p">(</span>
    <span class="n">backbone</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>                 <span class="c1"># The model we trained before (CPC)</span>
    <span class="n">head</span><span class="o">=</span><span class="n">prediction_head</span><span class="p">,</span>           <span class="c1"># The prediction head we just created</span>
    <span class="n">loss_fn</span><span class="o">=</span><span class="n">CrossEntropyLoss</span><span class="p">(),</span>     <span class="c1"># The loss function</span>
    <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span>
    <span class="n">update_backbone</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>          <span class="c1"># We do not want to update the backbone</span>
    <span class="n">metrics</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;acc&quot;</span><span class="p">:</span> <span class="n">acc_metric</span><span class="p">}</span>     <span class="c1"># We want to track the accuracy</span>
<span class="p">)</span>
<span class="n">ssl_discriminator</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
SSLDiscriminator(
  (backbone): CPC(
    (encoder): GRUEncoder(
      (rnn): GRU(6, 100, bidirectional=True)
      (nn): Linear(in_features=200, out_features=128, bias=True)
    )
    (density_estimator): Linear(in_features=128, out_features=128, bias=True)
    (auto_regressor): GRU(128, 128, batch_first=True)
    (loss_func): CrossEntropyLoss()
  )
  (head): CPCPredictionHead(
    (layers): Sequential(
      (0): Linear(in_features=128, out_features=64, bias=True)
      (1): ReLU()
      (2): Linear(in_features=64, out_features=64, bias=True)
      (3): Sequential(
        (0): ReLU()
        (1): Dropout(p=0, inplace=False)
      )
      (4): Linear(in_features=64, out_features=6, bias=True)
      (5): Softmax(dim=1)
    )
  )
  (loss_fn): CrossEntropyLoss()
)
</pre></div></div>
</div>
<p>Then we can instantiate the Trainer and call the <code class="docutils literal notranslate"><span class="pre">fit</span></code> method to train the model.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">lightning</span> <span class="k">as</span> <span class="nn">L</span>

<span class="n">max_epochs</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">L</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span><span class="n">max_epochs</span><span class="o">=</span><span class="n">max_epochs</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">ssl_discriminator</span><span class="p">,</span> <span class="n">data_module</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]

  | Name     | Type              | Params
-----------------------------------------------
0 | backbone | CPC               | 206 K
1 | head     | CPCPredictionHead | 12.8 K
2 | loss_fn  | CrossEntropyLoss  | 0
-----------------------------------------------
12.8 K    Trainable params
206 K     Non-trainable params
218 K     Total params
0.876     Total estimated model params size (MB)
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "2cf48079d50145c7afc3309882108058", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The &#39;val_dataloader&#39; does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=47` in the `DataLoader` to improve performance.
/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The &#39;train_dataloader&#39; does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=47` in the `DataLoader` to improve performance.
/usr/local/lib/python3.10/dist-packages/lightning/pytorch/loops/fit_loop.py:293: The number of training batches (22) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "e2ae4d6c11b94de5995bb8a7ef1c495b", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "b5eb6ffc4ee4423a93c60c73a1edfbf1", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "c66686d98e9d4f6daf3e11ad6dbba580", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "f5ddf90cc6cb45c698b80b613d67ba43", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "a2e606bf41644aa3ba73f1dd1af1f0ba", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "5225a29cc4734fe2a51e0a672c017e44", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "1daec8bdfe244e98a0506f59cadce3e8", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "0bf6a6c07005402aa725b3711cfc1e8a", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "6f8c6f1f5b7e42c5b4f7a94e3ab5c929", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "e378c409ea68429b80f4e26858a472dd", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "e6535154a526421997abf0f6c82cda9f", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
`Trainer.fit` stopped: `max_epochs=10` reached.
</pre></div></div>
</div>
<p>Let’s evaluate the model using the test set. If we have added the <code class="docutils literal notranslate"><span class="pre">Accuracy</span></code> metric to the model, it will calculate the accuracy of the model on the test set. All logged metrics will be returnet by <code class="docutils literal notranslate"><span class="pre">.test()</span></code> method, as a dictionary.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">results</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">test</span><span class="p">(</span><span class="n">ssl_discriminator</span><span class="p">,</span> <span class="n">data_module</span><span class="p">)</span>
<span class="n">results</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The &#39;test_dataloader&#39; does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=47` in the `DataLoader` to improve performance.
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "0075d6e46e5243eca4724a1a3ead2011", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃<span style="font-weight: bold">        Test metric        </span>┃<span style="font-weight: bold">       DataLoader 0        </span>┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│<span style="color: #008080; text-decoration-color: #008080">         test_acc          </span>│<span style="color: #800080; text-decoration-color: #800080">    0.5277777910232544     </span>│
│<span style="color: #008080; text-decoration-color: #008080">         test_loss         </span>│<span style="color: #800080; text-decoration-color: #800080">    1.5032936334609985     </span>│
└───────────────────────────┴───────────────────────────┘
</pre></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[{&#39;test_loss&#39;: 1.5032936334609985, &#39;test_acc&#39;: 0.5277777910232544}]
</pre></div></div>
</div>
<p>Finally, if we want to get the predictions of the model, we can: 1. Call the <code class="docutils literal notranslate"><span class="pre">forward</span></code> method of the model, passing the input data (iterating over all batches of the dataloader); or 2. Use the <code class="docutils literal notranslate"><span class="pre">Trainer.predict</span></code> method, passing the data module. If you use the <code class="docutils literal notranslate"><span class="pre">Trainer.predict</span></code> method, the model will be set to evaluation mode, and the predictions will be done using the <code class="docutils literal notranslate"><span class="pre">predict_dataloader</span></code> defined in the <code class="docutils literal notranslate"><span class="pre">LightningDataModule</span></code>. This is usually the test set (<code class="docutils literal notranslate"><span class="pre">test_dataloader</span></code>).</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_hat</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">ssl_discriminator</span><span class="p">,</span> <span class="n">data_module</span><span class="p">)</span>
<span class="c1"># predictions is a list of tensors. Let&#39;s concatenate them.</span>
<span class="n">y_hat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">y_hat</span><span class="p">)</span>
<span class="n">y_hat</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The &#39;predict_dataloader&#39; does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=47` in the `DataLoader` to improve performance.
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "c344339416884a01b84c3bc5dace1252", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
torch.Size([144, 6])
</pre></div></div>
</div>
</section>
</section>
<section id="Next-steps">
<h2>Next steps<a class="headerlink" href="#Next-steps" title="Link to this heading"></a></h2>
<p>This notebook comprises the whole process of training a self-supervised model and then using the learned representations to train a classifier for the downstream task.</p>
<p>We can standardize this process to facilitate the reproduction of the experiments, and then use it to train different models and evaluate them on different datasets.</p>
<p>Nextly we will explore the <code class="docutils literal notranslate"><span class="pre">Experiment</span></code> API that is designed to simplify the process of training and evaluating models, besides of provide a standard way to log the results, save and load models, and more.</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="02_training_model.html" class="btn btn-neutral float-left" title="2. Training a Pytorch Lighning model" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="04_using_experiments.html" class="btn btn-neutral float-right" title="Using Experiments" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, H.IAAC.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>