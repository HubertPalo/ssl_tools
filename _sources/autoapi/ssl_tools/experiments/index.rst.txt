:py:mod:`ssl_tools.experiments`
===============================

.. py:module:: ssl_tools.experiments


Subpackages
-----------
.. toctree::
   :titlesonly:
   :maxdepth: 3

   har_classification/index.rst


Submodules
----------
.. toctree::
   :titlesonly:
   :maxdepth: 1

   lightning_cli/index.rst
   ssl_experiment/index.rst


Package Contents
----------------

Classes
~~~~~~~

.. autoapisummary::

   ssl_tools.experiments.LightningTest
   ssl_tools.experiments.LightningTrain
   ssl_tools.experiments.SSLTest
   ssl_tools.experiments.SSLTrain




.. py:class:: LightningTest(load, batch_size = 1, log_dir='logs', name = None, version = None, accelerator = 'cpu', devices = 1, limit_test_batches = 1.0, num_nodes = 1, num_workers = None, seed = None)


   
   Defines the parameters for testing a Lightning model. This class
   may be used to define the parameters for a Lightning experiment and
   CLI.

   Parameters
   ----------
   load : str
       Path to the checkpoint to load
   batch_size : int, optional
       The batch size
   log_dir : str, optional
       Path to the location where logs will be stored
   name: str, optional
       The name of the experiment (it will be used to compose the path of
       the experiments, such as logs and checkpoints)
   version: Union[int, str], optional
       The version of the experiment. If not is provided the current date
       and time will be used as the version
   accelerator: str, optional
       The accelerator to use. Defaults to "cpu"
   devices: int, optional
       The number of devices to use. Defaults to 1
   limit_test_batches : Union[float, int], optional
       Limit the number of batches to use for testing.
   num_nodes: int, optional
       The number of nodes to use. Defaults to 1
   num_workers: int, optional
       The number of workers to use for the dataloader.
   seed: int, optional
       The seed to use.


.. py:class:: LightningTrain(epochs = 1, batch_size = 1, learning_rate = 0.001, log_dir = 'logs', name = None, version = None, load = None, checkpoint_metric = None, checkpoint_metric_mode = 'min', accelerator = 'cpu', devices = 1, strategy = 'auto', limit_train_batches = 1.0, limit_val_batches = 1.0, num_nodes = 1, num_workers = None, seed = None)


   
   Defines the parameters for training a Lightning model. This class
   may be used to define the parameters for a Lightning experiment and
   CLI.

   Parameters
   ----------
   epochs : int, optional
       Number of epochs to pre-train the model
   batch_size : int, optional
       The batch size
   learning_rate : float, optional
       The learning rate of the optimizer
   log_dir : str, optional
       Path to the location where logs will be stored
   name: str, optional
       The name of the experiment (it will be used to compose the path of
       the experiments, such as logs and checkpoints)
   version: Union[int, str], optional
       The version of the experiment. If not is provided the current date
       and time will be used as the version
   load: str, optional
       The path to a checkpoint to load
   checkpoint_metric: str, optional
       The metric to monitor for checkpointing. If not provided, the last
       model will be saved
   checkpoint_metric_mode: str, optional
       The mode of the metric to monitor (min, max or mean). Defaults to
       "min"
   accelerator: str, optional
       The accelerator to use. Defaults to "cpu"
   devices: int, optional
       The number of devices to use. Defaults to 1
   strategy: str, optional
       The strategy to use. Defaults to "auto"
   limit_train_batches: Union[float, int], optional
       The number of batches to use for training. Defaults to 1.0 (use
       all batches)
   limit_val_batches: Union[float, int], optional
       The number of batches to use for validation. Defaults to 1.0 (use
       all batches)
   num_nodes: int, optional
       The number of nodes to use. Defaults to 1
   num_workers: int, optional
       The number of workers to use for the dataloader.
   seed: int, optional
       The seed to use.


.. py:class:: SSLTest(*args, **kwargs)


   Bases: :py:obj:`ssl_tools.experiments.lightning_cli.LightningTest`

   
   Wraps the LightningTest class to provide a more specific interface
   for SSL experiments (testing).

   .. py:attribute:: _MODEL_NAME
      :value: 'model'

      

   .. py:method:: __call__()


   .. py:method:: _get_callbacks()

      Get the callbacks to use for the experiment.

      Returns
      -------
      List[L.Callback]
          The list of callbacks to use for the experiment.


   .. py:method:: _get_logger()

      Get the logger to use for the experiment.

      Returns
      -------
      _type_
          Get the logger to use for the experiment


   .. py:method:: _get_test_data_module()
      :abstractmethod:

      The data module to use for testing.

      Returns
      -------
      L.LightningDataModule
          The data module to use for testing


   .. py:method:: _get_test_model()
      :abstractmethod:

      Get the model to use for testing.

      Returns
      -------
      L.LightningModule
          The model to use for testing


   .. py:method:: _get_trainer(logger, callbacks)


   .. py:method:: _load_model(model, path)

      Loads a model from a checkpoint.

      Parameters
      ----------
      model : L.LightningModule
          The model to load the checkpoint into
      path : str
          The path to the checkpoint


   .. py:method:: _log_hyperparams(model, logger)


   .. py:method:: _run()

      Runs the experiment. This method is called when the experiment is
      called as a function. This method:
      1. Sets the experiment name and version
      2. Instantiates the model and data module
      3. Instantiates the trainer specific resources (logger, callbacks, etc.)
      4. Logs the hyperparameters (for reproducibility purposes)
      5. Instantiates the trainer
      6. Tests the model

      Note
      ----
          The results are converted to a pandas DataFrame and saved to the
          ``results_path``. The results are also returned by this method (as 
          a list of dictionaries).

      Returns
      -------
      List[dict]
          A list of dictionary with the results


   .. py:method:: _set_experiment()

      Set the experiment name and version. This method is called before
      instantiating the model and data module. It sets the experiment path
      and results path. The experiment path is used to store the logs and 
      the results path is used to store the results.


   .. py:method:: _test(model, data_module, trainer)

      Test the model using the provided trainer.

      Parameters
      ----------
      model : L.LightningModule
          The model to test
      data_module : L.LightningDataModule
          The data module to use for testing
      trainer : L.Trainer
          The trainer to use for testing

      Returns
      -------
      _type_
          A list of dictionary with the results



.. py:class:: SSLTrain(training_mode = 'pretrain', load_backbone = None, *args, **kwargs)


   Bases: :py:obj:`ssl_tools.experiments.lightning_cli.LightningTrain`

   
   Wraps the LightningTrain class to provide a more specific interface
   for SSL experiments (training).

   Parameters
   ----------
   training_mode : str, optional
       The training mode. It could be either "pretrain" or "finetune"
   load_backbone : str, optional
       Path to the backbone to load. This is only used when training_mode
       is "finetune". In fine-tuning, the backbone is loaded and the
       using ``load_backbone``. The ``load`` parameter is used to load the
       full model (backbone + head).

   .. py:attribute:: _MODEL_NAME
      :value: 'model'

      

   .. py:method:: __call__()


   .. py:method:: _get_callbacks()

      Get the callbacks to use for the experiment.

      Returns
      -------
      List[L.Callback]
          A list of callbacks to use for the experiment


   .. py:method:: _get_finetune_data_module()
      :abstractmethod:

      The data module to use for fine-tuning.

      Returns
      -------
      L.LightningDataModule
          The data module to use for fine-tuning

      Raises
      ------
      NotImplementedError
          _description_


   .. py:method:: _get_finetune_model(load_backbone = None)
      :abstractmethod:

      Get the model to use for fine-tuning.

      Parameters
      ----------
      load_backbone : str, optional
          The path to the backbone to load. The backbone must be loaded 
          inside this method, if it is not None.

      Returns
      -------
      L.LightningModule
          The model to use for fine-tuning


   .. py:method:: _get_logger()

      Get the logger to use for the experiment.

      Returns
      -------
      __type__
          The logger to use for the experiment


   .. py:method:: _get_pretrain_data_module()
      :abstractmethod:

      The data module to use for pre-training.

      Returns
      -------
      L.LightningDataModule
          The data module to use for pre-training


   .. py:method:: _get_pretrain_model()
      :abstractmethod:

      Get the model to use for pre-training.

      Returns
      -------
      L.LightningModule
          The model to use for pre-training


   .. py:method:: _get_trainer(logger, callbacks)

      Get trainer to use for the experiment.

      Parameters
      ----------
      logger : _type_
          The logger to use for the experiment
      callbacks : List[L.Callback]
          A list of callbacks to use for the experiment

      Returns
      -------
      L.Trainer
          The trainer to use for the experiment


   .. py:method:: _load_model(model, path)

      Load a model from a checkpoint.

      Parameters
      ----------
      model : L.LightningModule
          The model to load the checkpoint into
      path : str
          The path to the checkpoint


   .. py:method:: _log_hyperparams(model, logger)

      Log the hyperparameters for reproducibility purposes.

      Parameters
      ----------
      model : L.LightningModule
          The model to log the hyperparameters from
      logger : _type_
          The logger to use for logging the hyperparameters


   .. py:method:: _run()

      Runs the experiment. This method is called when the experiment is
      called as a function. This method:
      1. Sets the experiment name and version
      2. Instantiates the model and data module (depending on the 
      ``training_mode``)
      3. Instantiates the trainer specific resources (logger, callbacks, etc.)
      4. Logs the hyperparameters (for reproducibility purposes)
      5. Instantiates the trainer
      6. Trains the model


   .. py:method:: _set_experiment()

      Set the experiment name and version. This method is called before
      instantiating the model and data module. It is used to set the
      experiment path and checkpoint path. The experiment path is used to
      store the logs and checkpoints. The checkpoint path is used to store
      the checkpoints.


   .. py:method:: _train(model, data_module, trainer)

      Train the model using the provided trainer.

      Parameters
      ----------
      model : L.LightningModule
          The model to train
      data_module : L.LightningDataModule
          The data module to use for training
      trainer : L.Trainer
          The trainer to use for training



