{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando bibliotecas\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "    \n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = 'UCI'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPC SSL Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dados de Treino\n",
    "\n",
    "data_path = Path('/workspaces/betania.silva/view_concatenated/UCI/train')\n",
    "\n",
    "datas_x_train = []\n",
    "\n",
    "data_y_train = []\n",
    "\n",
    "for f in data_path.glob('*.csv'):\n",
    "    data = pd.read_csv(f)\n",
    "    x = data[['accel-x', 'accel-y', 'accel-z', 'gyro-x', 'gyro-y', 'gyro-z']].values\n",
    "\n",
    "    # Expend dimension\n",
    "\n",
    "    x = np.swapaxes(x, 1, 0)\n",
    "    \n",
    "    datas_x_train.append(x)\n",
    "\n",
    "    y = data['standard activity code'].values\n",
    "\n",
    "    data_y_train.append(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array 1: Shape (6, 8824)\n",
      "Array 2: Shape (6, 8449)\n",
      "Array 3: Shape (6, 7671)\n",
      "Array 4: Shape (6, 8632)\n",
      "Array 5: Shape (6, 7485)\n",
      "Array 6: Shape (6, 7417)\n",
      "Array 7: Shape (6, 9541)\n",
      "Array 8: Shape (6, 7040)\n",
      "Array 9: Shape (6, 8726)\n",
      "Array 10: Shape (6, 8073)\n",
      "Array 11: Shape (6, 8771)\n",
      "Array 12: Shape (6, 9127)\n",
      "Array 13: Shape (6, 7935)\n",
      "Array 14: Shape (6, 7826)\n",
      "Array 15: Shape (6, 8194)\n",
      "Array 16: Shape (6, 9130)\n",
      "Array 17: Shape (6, 7762)\n",
      "Array 18: Shape (6, 7615)\n",
      "Array 19: Shape (6, 8422)\n",
      "Array 20: Shape (6, 8041)\n",
      "Array 21: Shape (6, 7385)\n"
     ]
    }
   ],
   "source": [
    "# Use a função shape para obter o shape de cada array na lista\n",
    "formas = [arr.shape for arr in datas_x_train]\n",
    "\n",
    "# Isso irá imprimir as formas (shapes) de cada array na lista\n",
    "for i, forma in enumerate(formas):\n",
    "    print(f\"Array {i+1}: Shape {forma}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dados de Teste\n",
    "\n",
    "data_path = Path('/workspaces/betania.silva/view_concatenated/UCI/test')\n",
    "\n",
    "datas_x_test = []\n",
    "\n",
    "data_y_test = []\n",
    "\n",
    "for f in data_path.glob('*.csv'):\n",
    "    data = pd.read_csv(f)\n",
    "    x = data[['accel-x', 'accel-y', 'accel-z', 'gyro-x', 'gyro-y', 'gyro-z']].values\n",
    "\n",
    "    # Expend dimension\n",
    "\n",
    "    x = np.swapaxes(x, 1, 0)\n",
    "    \n",
    "    datas_x_test.append(x)\n",
    "\n",
    "    y = data['standard activity code'].values\n",
    "\n",
    "    data_y_test.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = datas_x_train\n",
    "y_train = data_y_train\n",
    "x_test = datas_x_test\n",
    "y_test = data_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.36540785,  0.79206858,  0.88780439, ..., -2.36982081,\n",
       "         -3.2656766 , -2.03628733],\n",
       "        [ 0.70760726,  1.03433844,  1.04630961, ..., -0.23616228,\n",
       "         -0.08243935,  0.47299394],\n",
       "        [-0.43062068, -0.74987103, -0.88142534, ...,  0.19780182,\n",
       "         -1.84579955, -0.95706349],\n",
       "        [ 0.00965204, -0.1060456 ,  0.00898792, ...,  0.53062411,\n",
       "          1.09164325,  0.57848348],\n",
       "        [ 0.01678245, -0.23185215, -0.0690665 , ..., -0.86830583,\n",
       "         -0.61831919, -0.43782577],\n",
       "        [-0.00475177, -0.02788059, -0.03397026, ..., -0.83912011,\n",
       "         -0.8898552 , -0.44344236]]),\n",
       " array([[-0.17149129, -1.14195093,  1.06687611, ..., -0.7460073 ,\n",
       "          0.60889507, -0.62005647],\n",
       "        [ 1.06931844,  1.20454507,  1.35799043, ..., -1.34093223,\n",
       "          0.25759907,  0.02948667],\n",
       "        [ 0.97353149,  2.02599875,  1.18516601, ..., -0.2264351 ,\n",
       "         -0.28342334,  0.39331783],\n",
       "        [ 0.08992597, -0.14170856, -0.01781067, ...,  3.76012049,\n",
       "          3.11338649,  2.72376373],\n",
       "        [ 0.23533618, -0.22232715, -0.54603689, ..., -0.31939737,\n",
       "         -0.14240548, -0.43687771],\n",
       "        [ 0.06951885, -0.30803582, -0.4405668 , ...,  0.09345149,\n",
       "          0.05951015, -0.06279795]]),\n",
       " array([[ 0.70624232,  0.29598156,  0.20036543, ..., -1.64844316,\n",
       "         -2.39933065, -1.42454755],\n",
       "        [-0.03198067, -0.21424759, -0.08122113, ..., -1.22523499,\n",
       "         -0.46043619, -0.05464812],\n",
       "        [ 0.83428499,  1.82816526,  1.84076739, ..., -2.78819538,\n",
       "         -2.73528815, -2.67644896],\n",
       "        [-0.02866719, -0.01300917, -0.04623576, ...,  0.42980056,\n",
       "          0.85822925,  0.94322053],\n",
       "        [ 0.31455308,  0.11038188, -0.02453762, ..., -0.04686389,\n",
       "         -0.19394895, -0.1873419 ],\n",
       "        [-0.03366078, -0.01017816, -0.02352527, ..., -0.82634852,\n",
       "         -0.83881568, -0.63514675]]),\n",
       " array([[ 6.15998654e-01,  1.89757884e+00,  1.38358571e+00, ...,\n",
       "          1.53221895e-01, -3.93784077e+00, -1.27731098e+00],\n",
       "        [ 3.00629270e-01,  9.04273509e-01,  1.11480444e+00, ...,\n",
       "          2.82682775e+00,  2.93254832e+00,  2.59710548e+00],\n",
       "        [ 1.31501168e+00,  1.82918104e+00,  1.60850687e+00, ...,\n",
       "         -2.68963883e+00, -3.20495340e+00, -2.10239526e+00],\n",
       "        [-2.29486360e-02, -2.26220508e-01, -4.45363434e-01, ...,\n",
       "         -4.59429763e-01, -2.78821297e-01, -6.58834748e-01],\n",
       "        [-2.14378806e-01, -2.02048492e-01,  4.32629016e-01, ...,\n",
       "         -5.25572580e-01, -6.36438425e-01, -5.41903651e-01],\n",
       "        [ 5.67539622e-02,  2.69231765e-03, -1.39360167e-01, ...,\n",
       "          4.68551603e-01,  7.29866400e-01,  6.63671011e-01]]),\n",
       " array([[ 1.57176410e-02, -8.91696098e-03, -2.80790760e-02, ...,\n",
       "         -2.12972974e+00,  8.97924380e-01, -9.13666791e-01],\n",
       "        [ 6.75772172e-03,  2.76949266e-03, -2.18610351e-02, ...,\n",
       "          2.25593449e+00, -1.33590822e+00, -1.36027180e+00],\n",
       "        [-1.80014100e-02,  1.30048069e-03,  2.99478000e-03, ...,\n",
       "          5.79957993e-01, -2.31804281e+00, -1.75695586e+00],\n",
       "        [ 1.07643753e-02,  7.55216745e-03,  1.12952120e-02, ...,\n",
       "         -5.62898390e-01, -1.62145568e-01,  9.86560382e-02],\n",
       "        [-7.93807025e-03,  1.28683011e-03, -5.12299870e-03, ...,\n",
       "         -9.44525344e-01,  2.73012107e-01, -5.18758679e-03],\n",
       "        [ 5.77186939e-03, -5.78941382e-03,  2.84844658e-03, ...,\n",
       "          2.43773595e-02,  9.91785207e-02, -6.04430299e-02]]),\n",
       " array([[ 0.06448984,  0.61384031,  0.42994686, ..., -2.18996382,\n",
       "         -4.73795015, -3.92225716],\n",
       "        [ 0.908386  ,  1.3714457 ,  1.02271915, ..., -1.1270616 ,\n",
       "         -1.77133374, -0.76497874],\n",
       "        [ 1.75480519,  1.3087408 ,  0.99597943, ..., -2.05023434,\n",
       "         -0.80747168, -1.03903677],\n",
       "        [-0.01950719, -0.08206999,  0.02461841, ...,  0.20143706,\n",
       "          0.54018753,  0.38286848],\n",
       "        [-0.09054198,  0.07073359,  0.32178861, ...,  1.08743753,\n",
       "          0.72561102,  0.47580593],\n",
       "        [-0.0060068 ,  0.01994527,  0.02537044, ...,  0.84551498,\n",
       "          0.66554967,  0.47080452]])]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datas_x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CNNEncoder(nn.Module):\n",
    "    def __init__(self, num_channels, kernel_size=3, dropout_rate=0.2, device: str = \"cpu\"):\n",
    "        super(CNNEncoder, self).__init__()\n",
    "        self.device = device\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv1d(num_channels, 32, kernel_size, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv1d(32, 64, kernel_size, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv1d(64, 128, kernel_size, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(self.device)  # Mova os dados para a GPU, se disponível\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        print(\"CNN\")\n",
    "        print(x.size())\n",
    "\n",
    "        # Aplana as duas primeiras dimensões\n",
    "        x = x.reshape(-1, x.size(-1))\n",
    "\n",
    "    # Verifica as dimensões do tensor aplanado\n",
    "        print(\"Dimensões do tensor aplanado:\", x.size())\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class GRUEncoder(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        hidden_size: int = 256,\n",
    "        in_channel: int = 128,\n",
    "        encoding_size: int = 128,\n",
    "        bidirectional: bool = True,\n",
    "        device: str = \"cpu\",\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.in_channel = in_channel\n",
    "        self.encoding_size = encoding_size\n",
    "        self.bidirectional = bidirectional\n",
    "        self.device = device\n",
    "\n",
    "        # Defina uma camada GRU com duas camadas e 256 unidades em cada camada\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=in_channel,\n",
    "            hidden_size=256,  # 256 unidades em cada camada\n",
    "            num_layers=2,      # Duas camadas GRU\n",
    "            batch_first=True,\n",
    "            bidirectional=bidirectional,\n",
    "        ).to(device)\n",
    "\n",
    "        self.nn = nn.Linear(\n",
    "            self.hidden_size * (int(bidirectional) + 1), self.encoding_size\n",
    "        ).to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        print('Começando o forward:')\n",
    "        print(x.size())\n",
    "        # x = torch.squeeze(x)\n",
    "        # #x = x.permute(0,2,1)\n",
    "        # #print(\"permuta (0,2,1)\")\n",
    "        # past = torch.zeros(\n",
    "        #     4,  # Duas camadas com bidirecionalidade resulta em 4 direções\n",
    "        #     x.shape[0],\n",
    "        #     256,  # Tamanho das unidades\n",
    "        #     device=self.device,\n",
    "        # )\n",
    "        # print(\"Past\")\n",
    "        # print(past.size())\n",
    "        out, _ = self.nn(\n",
    "            x, past\n",
    "        )   #out shape = [seq_len, batch_size, num_directions*hidden_size]\n",
    "        encodings = self.nn(out[-1].squeeze(0))\n",
    "        print(encodings.size())\n",
    "        print('AQUI')\n",
    "       # encodings = self.nn(out[-1].squeeze(0))\n",
    "        print('exit')\n",
    "      #  print(encodings.size())\n",
    "        return encodings\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CPC(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        encoderCNN: torch.nn.Module,\n",
    "        auto_regressor: torch.nn.Module,\n",
    "        density_estimator: torch.nn.Module,\n",
    "        #auto_regressor: torch.nn.Module,\n",
    "        lr: float = 1e-3,\n",
    "        weight_decay: float = 0.0,\n",
    "        window_size: int = 4,\n",
    "        n_size: int = 5\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.encoderCNN = encoderCNN.to(self.device)\n",
    "        #self.encoder = encoder.to(self.device)\n",
    "        self.density_estimator = density_estimator.to(self.device)\n",
    "        self.auto_regressor = auto_regressor.to(self.device)\n",
    "        self.learning_rate = lr\n",
    "        self.weight_decay = weight_decay\n",
    "        self.window_size = window_size\n",
    "        self.n_size = n_size\n",
    "        self.training_step_losses = []\n",
    "\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        assert len(batch) == 1, \"Batch must be 1 sample only\"\n",
    "        sample = batch\n",
    "        sample = sample.squeeze(0)\n",
    "        rnd_t = np.random.randint(\n",
    "            5 * self.window_size, sample.shape[-1] - 5 * self.window_size\n",
    "        )\n",
    "        sample = torch.tensor(\n",
    "            sample[\n",
    "                :,\n",
    "                max(0, (rnd_t - 20 * self.window_size)) : min(\n",
    "                    sample.shape[-1], rnd_t + 20 * self.window_size\n",
    "                ),\n",
    "            ]\n",
    "        ).cpu()\n",
    "\n",
    "        T = sample.shape[-1]\n",
    "        \n",
    "        windowed_sample = np.split(\n",
    "            sample[:, : (T // self.window_size) * self.window_size],\n",
    "            (T // self.window_size),\n",
    "            -1,\n",
    "        )\n",
    "        windowed_sample = torch.tensor(np.stack(windowed_sample, 0), device=self.device)\n",
    "        \n",
    "\n",
    "        # Obtém as saídas do codificador CNN\n",
    "        encodings = self.encoderCNN(windowed_sample)\n",
    "        \n",
    "        print(\"Encodings depois de passar pela cnn\")\n",
    "        \n",
    "        print(encodings.size())\n",
    "\n",
    "       # encodings = self.encoder(encodings_cnn)\n",
    "\n",
    "        window_ind = torch.randint(2, len(encodings) - 2, size=(1,))\n",
    "\n",
    "        print(\"window_ind\")\n",
    "\n",
    "        print(window_ind.size())\n",
    "\n",
    "        print(\"AQUI1111\")\n",
    "\n",
    "        _, c_t = self.auto_regressor(\n",
    "            encodings[max(0, window_ind[0] - 10) : window_ind[0] + 1]\n",
    "        )\n",
    "        \n",
    "        print(\"pos probleMMMMMMMMMA\")\n",
    "        \n",
    "        density_ratios = torch.bmm(\n",
    "            encodings.unsqueeze(1),\n",
    "            self.density_estimator(c_t.squeeze(1).squeeze(0)).expand_as(encodings).unsqueeze(-1),\n",
    "        ).view(\n",
    "            -1,\n",
    "        )\n",
    "        r = set(range(0, window_ind[0] - 2))\n",
    "        r.update(set(range(window_ind[0] + 3, len(encodings))))\n",
    "        rnd_n = np.random.choice(list(r), self.n_size)\n",
    "        X_N = torch.cat(\n",
    "            [density_ratios[rnd_n], density_ratios[window_ind[0] + 1].unsqueeze(0)], 0\n",
    "        ).to(self.device)\n",
    "        labels = torch.Tensor([len(X_N) - 1]).to(self.device)\n",
    "        loss = torch.nn.CrossEntropyLoss()(X_N.view(1, -1), labels.long())\n",
    "        self.training_step_losses.append(loss)\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def on_train_epoch_end(self) -> None:\n",
    "        # do something with all training_step outputs, for example:\n",
    "        epoch_mean = torch.stack(self.training_step_losses).mean()\n",
    "        self.log(\"train_loss\", epoch_mean, on_epoch=True, on_step=False, prog_bar=True, logger=True)\n",
    "        # free up the memory\n",
    "        self.training_step_losses.clear()\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        learnable_parameters = (\n",
    "            list(self.density_estimator.parameters())\n",
    "           # + list(self.encoder.parameters())\n",
    "            + list(self.auto_regressor.parameters())\n",
    "        )\n",
    "\n",
    "        optimizer = torch.optim.Adam(\n",
    "            learnable_parameters, lr=self.learning_rate, weight_decay=self.weight_decay\n",
    "        )\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/betania_meta4/.local/lib/python3.10/site-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "num_channels = 6\n",
    "\n",
    "encoding_size=128\n",
    "\n",
    "# Cria o codificador\n",
    "encoderCNN = CNNEncoder(num_channels, device='cuda')\n",
    "\n",
    "# Cria o modelo autoregressivo com GRU\n",
    "#encoder = GRUEncoder(in_channel=128, encoding_size=256, device='cpu')\n",
    "\n",
    "density_estimator = torch.nn.Linear(encoding_size, encoding_size)\n",
    "\n",
    "auto_regressor = torch.nn.GRU(input_size=128,\n",
    "                          hidden_size=128,\n",
    "                          num_layers=2,\n",
    "                          bidirectional=False,\n",
    "                          batch_first=True,\n",
    "                          dropout=0.2)\n",
    "\n",
    "#auto_regressor = GRUEncoder(in_channel=128, encoding_size=128, device='cuda')\n",
    "\n",
    "cpc = CPC(encoderCNN, auto_regressor, density_estimator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 6)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SimpleDataset:\n",
    "    def __init__(self, X, y=None):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.y is not None:\n",
    "            return self.X[idx].astype(np.float32), self.y[idx].astype(np.float32)\n",
    "        else:\n",
    "            return self.X[idx].astype(np.float32)\n",
    "    \n",
    "train_dataset = SimpleDataset(x_train)\n",
    "test_dataset = SimpleDataset(x_test, y_test)\n",
    "len(train_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=1, num_workers=10, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, num_workers=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(max_epochs=5, accelerator=\"cuda\", devices=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name              | Type       | Params\n",
      "-------------------------------------------------\n",
      "0 | encoderCNN        | CNNEncoder | 31.5 K\n",
      "1 | density_estimator | Linear     | 16.5 K\n",
      "2 | auto_regressor    | GRU        | 99.1 K\n",
      "-------------------------------------------------\n",
      "147 K     Trainable params\n",
      "0         Non-trainable params\n",
      "147 K     Total params\n",
      "0.588     Total estimated model params size (MB)\n",
      "/home/betania_meta4/.local/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:293: The number of training batches (21) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/21 [00:00<?, ?it/s] CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 0:   5%|▍         | 1/21 [00:00<00:00, 48.46it/s, v_num=221]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 0:  10%|▉         | 2/21 [00:00<00:00, 59.51it/s, v_num=221]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 0:  14%|█▍        | 3/21 [00:00<00:00, 57.92it/s, v_num=221]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 0:  19%|█▉        | 4/21 [00:00<00:00, 63.55it/s, v_num=221]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 0:  24%|██▍       | 5/21 [00:00<00:00, 66.96it/s, v_num=221]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 0:  29%|██▊       | 6/21 [00:00<00:00, 68.56it/s, v_num=221]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 0:  33%|███▎      | 7/21 [00:00<00:00, 69.90it/s, v_num=221]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 0:  38%|███▊      | 8/21 [00:00<00:00, 70.42it/s, v_num=221]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 0:  43%|████▎     | 9/21 [00:00<00:00, 70.81it/s, v_num=221]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 0:  48%|████▊     | 10/21 [00:00<00:00, 70.24it/s, v_num=221]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 0:  52%|█████▏    | 11/21 [00:00<00:00, 70.93it/s, v_num=221]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 0:  57%|█████▋    | 12/21 [00:00<00:00, 71.55it/s, v_num=221]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 0:  62%|██████▏   | 13/21 [00:00<00:00, 71.94it/s, v_num=221]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 0:  67%|██████▋   | 14/21 [00:00<00:00, 72.30it/s, v_num=221]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_331883/726988172.py:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  sample = torch.tensor(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 0:  71%|███████▏  | 15/21 [00:00<00:00, 71.16it/s, v_num=221]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 0:  76%|███████▌  | 16/21 [00:00<00:00, 70.92it/s, v_num=221]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 0:  81%|████████  | 17/21 [00:00<00:00, 70.99it/s, v_num=221]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 0:  86%|████████▌ | 18/21 [00:00<00:00, 70.66it/s, v_num=221]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 0:  90%|█████████ | 19/21 [00:00<00:00, 70.70it/s, v_num=221]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 0:  95%|█████████▌| 20/21 [00:00<00:00, 70.37it/s, v_num=221]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 1:   0%|          | 0/21 [00:00<?, ?it/s, v_num=221]         CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 1:   5%|▍         | 1/21 [00:00<00:09,  2.22it/s, v_num=221, train_loss=1.790]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 1:  10%|▉         | 2/21 [00:00<00:04,  4.35it/s, v_num=221, train_loss=1.790]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 1:  14%|█▍        | 3/21 [00:00<00:02,  6.41it/s, v_num=221, train_loss=1.790]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 1:  19%|█▉        | 4/21 [00:00<00:02,  8.36it/s, v_num=221, train_loss=1.790]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 1:  24%|██▍       | 5/21 [00:00<00:01, 10.11it/s, v_num=221, train_loss=1.790]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 1:  29%|██▊       | 6/21 [00:00<00:01, 11.83it/s, v_num=221, train_loss=1.790]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 1:  33%|███▎      | 7/21 [00:00<00:01, 13.27it/s, v_num=221, train_loss=1.790]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 1:  38%|███▊      | 8/21 [00:00<00:00, 14.80it/s, v_num=221, train_loss=1.790]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 1:  43%|████▎     | 9/21 [00:00<00:00, 16.27it/s, v_num=221, train_loss=1.790]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 1:  48%|████▊     | 10/21 [00:00<00:00, 17.61it/s, v_num=221, train_loss=1.790]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 1:  52%|█████▏    | 11/21 [00:00<00:00, 18.96it/s, v_num=221, train_loss=1.790]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 1:  57%|█████▋    | 12/21 [00:00<00:00, 20.22it/s, v_num=221, train_loss=1.790]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 1:  62%|██████▏   | 13/21 [00:00<00:00, 21.39it/s, v_num=221, train_loss=1.790]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 1:  67%|██████▋   | 14/21 [00:00<00:00, 22.55it/s, v_num=221, train_loss=1.790]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 1:  71%|███████▏  | 15/21 [00:00<00:00, 23.66it/s, v_num=221, train_loss=1.790]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 1:  76%|███████▌  | 16/21 [00:00<00:00, 24.72it/s, v_num=221, train_loss=1.790]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 1:  81%|████████  | 17/21 [00:00<00:00, 25.73it/s, v_num=221, train_loss=1.790]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 1:  86%|████████▌ | 18/21 [00:00<00:00, 26.69it/s, v_num=221, train_loss=1.790]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 1:  90%|█████████ | 19/21 [00:00<00:00, 27.62it/s, v_num=221, train_loss=1.790]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 1:  95%|█████████▌| 20/21 [00:00<00:00, 28.45it/s, v_num=221, train_loss=1.790]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 2:   0%|          | 0/21 [00:00<?, ?it/s, v_num=221, train_loss=1.790]         CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 2:   5%|▍         | 1/21 [00:00<00:12,  1.66it/s, v_num=221, train_loss=1.830]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 2:  10%|▉         | 2/21 [00:00<00:05,  3.27it/s, v_num=221, train_loss=1.830]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 2:  14%|█▍        | 3/21 [00:00<00:03,  4.80it/s, v_num=221, train_loss=1.830]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 2:  19%|█▉        | 4/21 [00:00<00:02,  6.29it/s, v_num=221, train_loss=1.830]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 2:  24%|██▍       | 5/21 [00:00<00:02,  7.72it/s, v_num=221, train_loss=1.830]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 2:  29%|██▊       | 6/21 [00:00<00:01,  9.10it/s, v_num=221, train_loss=1.830]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 2:  33%|███▎      | 7/21 [00:00<00:01, 10.43it/s, v_num=221, train_loss=1.830]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 2:  38%|███▊      | 8/21 [00:00<00:01, 11.70it/s, v_num=221, train_loss=1.830]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 2:  43%|████▎     | 9/21 [00:00<00:00, 12.80it/s, v_num=221, train_loss=1.830]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 2:  48%|████▊     | 10/21 [00:00<00:00, 13.93it/s, v_num=221, train_loss=1.830]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 2:  52%|█████▏    | 11/21 [00:00<00:00, 15.05it/s, v_num=221, train_loss=1.830]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 2:  57%|█████▋    | 12/21 [00:00<00:00, 16.14it/s, v_num=221, train_loss=1.830]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 2:  62%|██████▏   | 13/21 [00:00<00:00, 17.20it/s, v_num=221, train_loss=1.830]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 2:  67%|██████▋   | 14/21 [00:00<00:00, 18.21it/s, v_num=221, train_loss=1.830]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 2:  71%|███████▏  | 15/21 [00:00<00:00, 19.20it/s, v_num=221, train_loss=1.830]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 2:  76%|███████▌  | 16/21 [00:00<00:00, 20.13it/s, v_num=221, train_loss=1.830]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 2:  81%|████████  | 17/21 [00:00<00:00, 21.01it/s, v_num=221, train_loss=1.830]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 2:  86%|████████▌ | 18/21 [00:00<00:00, 21.85it/s, v_num=221, train_loss=1.830]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 2:  90%|█████████ | 19/21 [00:00<00:00, 22.67it/s, v_num=221, train_loss=1.830]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 2:  95%|█████████▌| 20/21 [00:00<00:00, 23.46it/s, v_num=221, train_loss=1.830]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 3:   0%|          | 0/21 [00:00<?, ?it/s, v_num=221, train_loss=1.830]         CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 3:   5%|▍         | 1/21 [00:00<00:12,  1.58it/s, v_num=221, train_loss=1.800]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 3:  10%|▉         | 2/21 [00:00<00:06,  3.11it/s, v_num=221, train_loss=1.800]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 3:  14%|█▍        | 3/21 [00:00<00:03,  4.58it/s, v_num=221, train_loss=1.800]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 3:  19%|█▉        | 4/21 [00:00<00:02,  5.99it/s, v_num=221, train_loss=1.800]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 3:  24%|██▍       | 5/21 [00:00<00:02,  7.34it/s, v_num=221, train_loss=1.800]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 3:  29%|██▊       | 6/21 [00:00<00:01,  8.64it/s, v_num=221, train_loss=1.800]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 3:  33%|███▎      | 7/21 [00:00<00:01,  9.90it/s, v_num=221, train_loss=1.800]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 3:  38%|███▊      | 8/21 [00:00<00:01, 11.11it/s, v_num=221, train_loss=1.800]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 3:  43%|████▎     | 9/21 [00:00<00:00, 12.16it/s, v_num=221, train_loss=1.800]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 3:  48%|████▊     | 10/21 [00:00<00:00, 13.25it/s, v_num=221, train_loss=1.800]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 3:  52%|█████▏    | 11/21 [00:00<00:00, 14.33it/s, v_num=221, train_loss=1.800]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 3:  57%|█████▋    | 12/21 [00:00<00:00, 15.38it/s, v_num=221, train_loss=1.800]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 3:  62%|██████▏   | 13/21 [00:00<00:00, 16.39it/s, v_num=221, train_loss=1.800]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 3:  67%|██████▋   | 14/21 [00:00<00:00, 17.38it/s, v_num=221, train_loss=1.800]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 3:  71%|███████▏  | 15/21 [00:00<00:00, 18.34it/s, v_num=221, train_loss=1.800]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 3:  76%|███████▌  | 16/21 [00:00<00:00, 19.24it/s, v_num=221, train_loss=1.800]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 3:  81%|████████  | 17/21 [00:00<00:00, 20.11it/s, v_num=221, train_loss=1.800]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 3:  86%|████████▌ | 18/21 [00:00<00:00, 20.99it/s, v_num=221, train_loss=1.800]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 3:  90%|█████████ | 19/21 [00:00<00:00, 21.79it/s, v_num=221, train_loss=1.800]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 3:  95%|█████████▌| 20/21 [00:00<00:00, 22.55it/s, v_num=221, train_loss=1.800]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 4:   0%|          | 0/21 [00:00<?, ?it/s, v_num=221, train_loss=1.800]         CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 4:   5%|▍         | 1/21 [00:00<00:13,  1.52it/s, v_num=221, train_loss=1.810]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 4:  10%|▉         | 2/21 [00:00<00:06,  2.99it/s, v_num=221, train_loss=1.810]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 4:  14%|█▍        | 3/21 [00:00<00:04,  4.38it/s, v_num=221, train_loss=1.810]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 4:  19%|█▉        | 4/21 [00:00<00:02,  5.71it/s, v_num=221, train_loss=1.810]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 4:  24%|██▍       | 5/21 [00:00<00:02,  6.96it/s, v_num=221, train_loss=1.810]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 4:  29%|██▊       | 6/21 [00:00<00:01,  8.19it/s, v_num=221, train_loss=1.810]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 4:  33%|███▎      | 7/21 [00:00<00:01,  9.34it/s, v_num=221, train_loss=1.810]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 4:  38%|███▊      | 8/21 [00:00<00:01, 10.47it/s, v_num=221, train_loss=1.810]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 4:  43%|████▎     | 9/21 [00:00<00:01, 11.45it/s, v_num=221, train_loss=1.810]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 4:  48%|████▊     | 10/21 [00:00<00:00, 12.45it/s, v_num=221, train_loss=1.810]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 4:  52%|█████▏    | 11/21 [00:00<00:00, 13.45it/s, v_num=221, train_loss=1.810]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 4:  57%|█████▋    | 12/21 [00:00<00:00, 14.42it/s, v_num=221, train_loss=1.810]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 4:  62%|██████▏   | 13/21 [00:00<00:00, 15.36it/s, v_num=221, train_loss=1.810]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 4:  67%|██████▋   | 14/21 [00:00<00:00, 16.24it/s, v_num=221, train_loss=1.810]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 4:  71%|███████▏  | 15/21 [00:00<00:00, 17.09it/s, v_num=221, train_loss=1.810]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 4:  76%|███████▌  | 16/21 [00:00<00:00, 17.91it/s, v_num=221, train_loss=1.810]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 4:  81%|████████  | 17/21 [00:00<00:00, 18.68it/s, v_num=221, train_loss=1.810]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 4:  86%|████████▌ | 18/21 [00:00<00:00, 19.45it/s, v_num=221, train_loss=1.810]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 4:  90%|█████████ | 19/21 [00:00<00:00, 20.18it/s, v_num=221, train_loss=1.810]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 4:  95%|█████████▌| 20/21 [00:00<00:00, 20.85it/s, v_num=221, train_loss=1.810]CNN\n",
      "torch.Size([40, 4, 128])\n",
      "Dimensões do tensor aplanado: torch.Size([160, 128])\n",
      "Encodings depois de passar pela cnn\n",
      "torch.Size([160, 128])\n",
      "window_ind\n",
      "torch.Size([1])\n",
      "AQUI1111\n",
      "pos probleMMMMMMMMMA\n",
      "Epoch 4: 100%|██████████| 21/21 [00:00<00:00, 21.49it/s, v_num=221, train_loss=1.810]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 21/21 [00:01<00:00, 20.63it/s, v_num=221, train_loss=1.810]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(cpc, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensões do tensor aplanado: torch.Size([20, 6])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Suponha que você tenha um tensor tridimensional com dimensões [batch_size, dim1, dim2]\n",
    "tensor_tridimensional = torch.randn(4, 5, 6)\n",
    "\n",
    "# Aplana as duas primeiras dimensões\n",
    "tensor_aplanado = tensor_tridimensional.view(-1, tensor_tridimensional.size(-1))\n",
    "\n",
    "# Verifica as dimensões do tensor aplanado\n",
    "print(\"Dimensões do tensor aplanado:\", tensor_aplanado.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Checking if there are weights saved from previous training, else it trains from scratch\n",
    "# try:\n",
    "#     encoder.load_state_dict(torch.load(f'./weights/{DATASET_NAME}_encoder.pt'))\n",
    "# except:\n",
    "#     torch.save(encoder.state_dict(), f'./weights/{DATASET_NAME}_encoder.pt')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CPC Fine-Tuning\n",
    "\n",
    "We are going to fine-tune the CPC model on the downstream task of classification. We will use the same dataset and re-use the same encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from typing import Any, Optional\n",
    "\n",
    "# from torchmetrics.functional import accuracy\n",
    "\n",
    "# class StateClassifier(torch.nn.Module):\n",
    "#     def __init__(self, input_size: int = 10, n_classes: int = 7):\n",
    "#         super(StateClassifier, self).__init__()\n",
    "#         self.input_size = input_size\n",
    "#         self.n_classes = 7\n",
    "#         self.normalize = torch.nn.BatchNorm1d(self.input_size)\n",
    "#         self.nn = torch.nn.Linear(self.input_size, self.n_classes)\n",
    "#         torch.nn.init.xavier_uniform_(self.nn.weight)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.normalize(x)\n",
    "#         logits = self.nn(x)\n",
    "#         return logits\n",
    "\n",
    "\n",
    "# class CPC_Classifier(pl.LightningModule):\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         encoderCNN: torch.nn.Module,\n",
    "#         encoder: torch.nn.Module,\n",
    "#         classifier: torch.nn.Module,\n",
    "#         lr: float = 1e-3,\n",
    "#         weight_decay: float = 0.0,\n",
    "#         task_class: str = \"multiclass\",\n",
    "#         num_classes: int = 7\n",
    "#     ):\n",
    "#         super().__init__()\n",
    "#         self.encoderCNN = encoderCNN.to('cpu')\n",
    "#         self.encoder = encoder.to('cpu')\n",
    "#         self.classifier = classifier.to('cpu')\n",
    "#         self.learning_rate = lr\n",
    "#         self.weight_decay = weight_decay\n",
    "#         self.training_step_losses = []\n",
    "#         self.validation_step_losses = []\n",
    "#         self.loss_function = torch.nn.CrossEntropyLoss()\n",
    "#         self.task_class = task_class\n",
    "#         self.num_classes = 7\n",
    "        \n",
    "#     def configure_optimizers(self) -> Any:\n",
    "#         optimizer = torch.optim.Adam(\n",
    "#             self.classifier.parameters(), lr=self.learning_rate, weight_decay=self.weight_decay\n",
    "#         )\n",
    "#         return optimizer\n",
    "    \n",
    "#         # def configure_optimizers(self):\n",
    "#         # learnable_parameters = (\n",
    "#         #     list(self.encoderCNN.parameters())\n",
    "#         #     + list(self.encoder.parameters())\n",
    "#         #     + list(self.classifier.parameters())\n",
    "#         # )\n",
    "\n",
    "#         # optimizer = torch.optim.Adam(\n",
    "#         #     learnable_parameters, lr=self.learning_rate, weight_decay=self.weight_decay\n",
    "#         # )\n",
    "#         # return optimizer\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         encodings_cnn = self.encoderCNN(x)\n",
    "#         encodings = self.encoder(encodings_cnn)\n",
    "#         #predictions = self.classifier(encodings)\n",
    "#         #return predictions\n",
    "#         return encodings\n",
    "    \n",
    "#     def training_step(self, batch, batch_idx):\n",
    "#         x, y = batch\n",
    "#         predictions = self.forward(x)\n",
    "#         loss = self.loss_function(predictions, y.long())\n",
    "#         self.training_step_losses.append(loss)\n",
    "#         return loss\n",
    "    \n",
    "#     def on_train_epoch_end(self) -> None:\n",
    "#         # do something with all training_step outputs, for example:\n",
    "#         epoch_mean = torch.stack(self.training_step_losses).mean()\n",
    "#         self.log(\"train_loss\", epoch_mean, on_epoch=True, on_step=False, prog_bar=True, logger=True)\n",
    "#         # free up the memory\n",
    "#         self.training_step_losses.clear()\n",
    "    \n",
    "#     def validation_step(self, batch, batch_idx):\n",
    "#         loss, acc = self._shared_eval_step(batch, batch_idx)\n",
    "#         self.validation_step_losses.append(loss)\n",
    "#         metrics = {\"val_acc\": acc, \"val_loss\": loss}\n",
    "#         self.log_dict(metrics)\n",
    "#         return metrics\n",
    "    \n",
    "#     def test_step(self, batch, batch_idx):\n",
    "#         loss, acc = self._shared_eval_step(batch, batch_idx)\n",
    "#         metrics = {\"test_acc\": acc, \"test_loss\": loss}\n",
    "#         self.log_dict(metrics)\n",
    "#         return metrics\n",
    "\n",
    "        \n",
    "#     def on_validation_epoch_end(self) -> None:\n",
    "#         # do something with all training_step outputs, for example:\n",
    "#         epoch_mean = torch.stack(self.validation_step_losses).mean()\n",
    "#         self.log(\"val_loss\", epoch_mean, on_epoch=True, on_step=False, prog_bar=True, logger=True)\n",
    "#         # free up the memory\n",
    "#         self.validation_step_losses.clear()\n",
    "\n",
    "#     def _shared_eval_step(self, batch, batch_idx):\n",
    "#         x, y = batch\n",
    "#         predictions = self.forward(x)\n",
    "#         loss = self.loss_function(predictions, y.long())\n",
    "#         acc = accuracy(torch.argmax(predictions, dim=1), y.long(), task=self.task_class, num_classes=self.num_classes)\n",
    "#         return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderClassifier(nn.Module):\n",
    "    def __init__(self, num_channels, kernel_size=3, dropout_rate=0.2, device: str = \"cpu\"):\n",
    "        super(EncoderClassifier, self).__init__()\n",
    "        self.device = device\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv1d(num_channels, 32, kernel_size, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv1d(32, 64, kernel_size, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv1d(64, 128, kernel_size, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(self.device)  # Mova os dados para a GPU, se disponível\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        print(\"CNN\")\n",
    "        print(x.size())\n",
    "\n",
    "        # Aplana as duas primeiras dimensões\n",
    "        x = x.reshape(-1, x.size(-1))\n",
    "\n",
    "    # Verifica as dimensões do tensor aplanado\n",
    "       # print(\"Dimensões do tensor aplanado:\", x.size())\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Optional\n",
    "\n",
    "from torchmetrics.functional import accuracy\n",
    "\n",
    "# Classificando com uma MLP\n",
    "\n",
    "class StateClassifier(torch.nn.Module):\n",
    "    def __init__(self, input_size: int= 128, hidden_size1= 64, hidden_size2=64, n_classes= 7, dropout_prob= 0):\n",
    "        super(StateClassifier, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Linear(hidden_size1, hidden_size2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.dropout = nn.Dropout(p=dropout_prob)\n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Linear(hidden_size2, n_classes),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        print('st1_in:', x.size())\n",
    "        out = self.layer1(x)\n",
    "        print('st2_in:', x.size())\n",
    "        out = self.layer2(out)\n",
    "        print('stdp_in:', x.size())\n",
    "        out = self.dropout(out)\n",
    "        print('stout_in:', x.size())\n",
    "        out = self.output_layer(out)\n",
    "        print('out_:', x.size())\n",
    "        return out\n",
    "\n",
    "class CPC_Classifier(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        encoderCNN: torch.nn.Module,\n",
    "        classifier: torch.nn.Module,\n",
    "        lr: float = 1e-3,\n",
    "        weight_decay: float = 0.0,\n",
    "        task_class: str = \"multiclass\",\n",
    "        n_classes: int = 7\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.encoderCNN = encoderCNN.to(self.device)\n",
    "        self.classifier = classifier.to(self.device)\n",
    "        self.learning_rate = lr\n",
    "        self.weight_decay = weight_decay\n",
    "        self.training_step_losses = []\n",
    "        self.validation_step_losses = []\n",
    "        self.loss_function = torch.nn.CrossEntropyLoss()\n",
    "        self.task_class = task_class\n",
    "        self.n_classes = n_classes \n",
    "        \n",
    "    def configure_optimizers(self) -> Any:\n",
    "        optimizer = torch.optim.Adam(\n",
    "            self.classifier.parameters(), lr=self.learning_rate, weight_decay=self.weight_decay\n",
    "        )\n",
    "        return optimizer\n",
    "    \n",
    "    def forward(self, x):\n",
    "        encodings = self.encoderCNN(x)\n",
    "        print('saindo do encoding:', encodings.size())\n",
    "        predictions = self.classifier(encodings)\n",
    "        print('pred_outed:', predictions)\n",
    "        return predictions\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        predictions = self.forward(x)\n",
    "        loss = self.loss_function(predictions, y.long())\n",
    "        self.training_step_losses.append(loss)\n",
    "        return loss\n",
    "    \n",
    "    def on_train_epoch_end(self) -> None:\n",
    "        # do something with all training_step outputs, for example:\n",
    "        epoch_mean = torch.stack(self.training_step_losses).mean()\n",
    "        self.log(\"train_loss\", epoch_mean, on_epoch=True, on_step=False, prog_bar=True, logger=True)\n",
    "        # free up the memory\n",
    "        self.training_step_losses.clear()\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, acc = self._shared_eval_step(batch, batch_idx)\n",
    "        self.validation_step_losses.append(loss)\n",
    "        metrics = {\"val_acc\": acc, \"val_loss\": loss}\n",
    "        self.log_dict(metrics)\n",
    "        return metrics\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss, acc = self._shared_eval_step(batch, batch_idx)\n",
    "        metrics = {\"test_acc\": acc, \"test_loss\": loss}\n",
    "        self.log_dict(metrics)\n",
    "        return metrics\n",
    "\n",
    "        \n",
    "    def on_validation_epoch_end(self) -> None:\n",
    "        # do something with all training_step outputs, for example:\n",
    "        epoch_mean = torch.stack(self.validation_step_losses).mean()\n",
    "        self.log(\"val_loss\", epoch_mean, on_epoch=True, on_step=False, prog_bar=True, logger=True)\n",
    "        # free up the memory\n",
    "        self.validation_step_losses.clear()\n",
    "\n",
    "    def _shared_eval_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        predictions = self.forward(x)\n",
    "        loss = self.loss_function(predictions, y.long())\n",
    "        acc = accuracy(torch.argmax(predictions, dim=1), y.long(), task=self.task_class, num_classes=self.num_classes)\n",
    "        return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "BATCH_SIZE = 60\n",
    "\n",
    "# Caminho dos dados\n",
    "\n",
    "data_path_train = Path('/workspaces/betania.silva/data/standartized_balanced/UCI/train.csv')\n",
    "\n",
    "data_path_validation = Path('/workspaces/betania.silva/data/standartized_balanced/UCI/validation.csv')\n",
    "\n",
    "data_path_test = Path('/workspaces/betania.silva/data/standartized_balanced/UCI/test.csv')\n",
    "\n",
    "# Train\n",
    "\n",
    "x_train = pd.read_csv(data_path_train)\n",
    "\n",
    "x_train = x_train.iloc[:, :360]\n",
    "    \n",
    "x_train = x_train.astype(np.float32)\n",
    "\n",
    "y_train = pd.read_csv(data_path_train)\n",
    "\n",
    "y_train = y_train.iloc[:, -1]\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "\n",
    "tensor_x = torch.Tensor(np.array(x_train))\n",
    "\n",
    "tensor_y = torch.Tensor(np.array(y_train))\n",
    "\n",
    "original_dim = tensor_x.shape[0]\n",
    "\n",
    "input_shape = (original_dim, 6, 60)\n",
    "\n",
    "tensor_x = tensor_x.reshape(input_shape)\n",
    "\n",
    "dataset_train= TensorDataset(tensor_x,tensor_y)\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=BATCH_SIZE, shuffle=True, drop_last= True)\n",
    "\n",
    "# Validation\n",
    "\n",
    "x_validation = pd.read_csv(data_path_validation)\n",
    "\n",
    "x_validation = x_validation.iloc[:, :360]\n",
    "\n",
    "x_validation = x_validation.astype(np.float32)\n",
    "\n",
    "y_validation = pd.read_csv(data_path_validation)\n",
    "\n",
    "y_validation = y_validation.iloc[:, -1]\n",
    "\n",
    "y_validation = y_validation.astype(np.float32)\n",
    "\n",
    "tensor_x_val = torch.Tensor(np.array(x_validation))\n",
    "\n",
    "tensor_y_val = torch.Tensor(np.array(y_validation))\n",
    "\n",
    "original_dim_val = tensor_x_val.shape[0]\n",
    "\n",
    "tensor_x_val = tensor_x_val.reshape(original_dim_val, 6, 60)\n",
    "\n",
    "dataset_val= TensorDataset(tensor_x_val,tensor_y_val)\n",
    "\n",
    "dataloader_val = DataLoader(dataset_val, batch_size=BATCH_SIZE, shuffle=True, drop_last = True)\n",
    "\n",
    "# Test\n",
    "\n",
    "x_test = pd.read_csv(data_path_test)\n",
    "\n",
    "x_test = x_test.iloc[:, :360]\n",
    "\n",
    "x_test = x_test.astype(np.float32)\n",
    "\n",
    "y_test = pd.read_csv(data_path_test)\n",
    "\n",
    "y_test = y_test.iloc[:, -1]\n",
    "\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "tensor_x_test = torch.Tensor(np.array(x_test))\n",
    "\n",
    "tensor_y_test = torch.Tensor(np.array(y_test))\n",
    "\n",
    "original_dim_test = tensor_x_test.shape[0]\n",
    "\n",
    "tensor_x_test = tensor_x_test.reshape((original_dim_test, 6, 60))\n",
    "\n",
    "dataset_test= TensorDataset(tensor_x_test,tensor_y_test)\n",
    "\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=BATCH_SIZE, shuffle=True, drop_last= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "690"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_dim_test = tensor_x_test.shape[0]\n",
    "\n",
    "original_dim_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 4, 0, 1])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path_train = Path('/workspaces/betania.silva/data/standartized_balanced/UCI/train.csv')\n",
    "\n",
    "y_train = pd.read_csv(data_path_train)\n",
    "\n",
    "y_train = y_train.iloc[:, -1]\n",
    "\n",
    "y_train.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accel-x-0</th>\n",
       "      <th>accel-x-1</th>\n",
       "      <th>accel-x-2</th>\n",
       "      <th>accel-x-3</th>\n",
       "      <th>accel-x-4</th>\n",
       "      <th>accel-x-5</th>\n",
       "      <th>accel-x-6</th>\n",
       "      <th>accel-x-7</th>\n",
       "      <th>accel-x-8</th>\n",
       "      <th>accel-x-9</th>\n",
       "      <th>...</th>\n",
       "      <th>gyro-z-50</th>\n",
       "      <th>gyro-z-51</th>\n",
       "      <th>gyro-z-52</th>\n",
       "      <th>gyro-z-53</th>\n",
       "      <th>gyro-z-54</th>\n",
       "      <th>gyro-z-55</th>\n",
       "      <th>gyro-z-56</th>\n",
       "      <th>gyro-z-57</th>\n",
       "      <th>gyro-z-58</th>\n",
       "      <th>gyro-z-59</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.339089</td>\n",
       "      <td>-1.167666</td>\n",
       "      <td>-3.694124</td>\n",
       "      <td>-3.991698</td>\n",
       "      <td>-3.144751</td>\n",
       "      <td>-4.243802</td>\n",
       "      <td>-0.346311</td>\n",
       "      <td>4.784375</td>\n",
       "      <td>5.407283</td>\n",
       "      <td>2.445792</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022887</td>\n",
       "      <td>-0.159737</td>\n",
       "      <td>-0.375233</td>\n",
       "      <td>0.051135</td>\n",
       "      <td>0.921111</td>\n",
       "      <td>0.278494</td>\n",
       "      <td>-0.133034</td>\n",
       "      <td>-0.033831</td>\n",
       "      <td>-0.145661</td>\n",
       "      <td>-0.039100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.999586</td>\n",
       "      <td>-1.566372</td>\n",
       "      <td>-1.517025</td>\n",
       "      <td>-2.713303</td>\n",
       "      <td>0.712069</td>\n",
       "      <td>2.309685</td>\n",
       "      <td>3.010014</td>\n",
       "      <td>3.875827</td>\n",
       "      <td>1.239790</td>\n",
       "      <td>-0.457387</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.684964</td>\n",
       "      <td>-0.555177</td>\n",
       "      <td>-0.076758</td>\n",
       "      <td>0.106422</td>\n",
       "      <td>0.348305</td>\n",
       "      <td>0.280755</td>\n",
       "      <td>0.141009</td>\n",
       "      <td>-0.206322</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.119462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.876184</td>\n",
       "      <td>-1.637183</td>\n",
       "      <td>-0.968435</td>\n",
       "      <td>-4.894519</td>\n",
       "      <td>-2.211239</td>\n",
       "      <td>-0.815775</td>\n",
       "      <td>1.349346</td>\n",
       "      <td>0.910528</td>\n",
       "      <td>1.072714</td>\n",
       "      <td>2.240573</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064544</td>\n",
       "      <td>0.164004</td>\n",
       "      <td>0.180907</td>\n",
       "      <td>-0.684902</td>\n",
       "      <td>-0.689362</td>\n",
       "      <td>0.008271</td>\n",
       "      <td>0.051843</td>\n",
       "      <td>0.089196</td>\n",
       "      <td>-0.178239</td>\n",
       "      <td>0.031978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.649148</td>\n",
       "      <td>-1.854505</td>\n",
       "      <td>3.019927</td>\n",
       "      <td>3.966432</td>\n",
       "      <td>-0.782214</td>\n",
       "      <td>-2.535543</td>\n",
       "      <td>-3.642630</td>\n",
       "      <td>-2.326545</td>\n",
       "      <td>-2.164334</td>\n",
       "      <td>-0.037000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.264074</td>\n",
       "      <td>0.088056</td>\n",
       "      <td>0.465905</td>\n",
       "      <td>0.422788</td>\n",
       "      <td>-0.038715</td>\n",
       "      <td>-0.766346</td>\n",
       "      <td>0.376857</td>\n",
       "      <td>-0.127370</td>\n",
       "      <td>0.074219</td>\n",
       "      <td>0.437026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.431428</td>\n",
       "      <td>0.846879</td>\n",
       "      <td>0.397590</td>\n",
       "      <td>1.620648</td>\n",
       "      <td>-2.014615</td>\n",
       "      <td>-3.534210</td>\n",
       "      <td>-1.916457</td>\n",
       "      <td>-1.600943</td>\n",
       "      <td>-1.037111</td>\n",
       "      <td>0.433378</td>\n",
       "      <td>...</td>\n",
       "      <td>0.246871</td>\n",
       "      <td>0.168610</td>\n",
       "      <td>0.257335</td>\n",
       "      <td>0.179625</td>\n",
       "      <td>0.129522</td>\n",
       "      <td>0.167631</td>\n",
       "      <td>-0.061982</td>\n",
       "      <td>0.597766</td>\n",
       "      <td>-0.117428</td>\n",
       "      <td>-0.170377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2415</th>\n",
       "      <td>-0.055121</td>\n",
       "      <td>-0.013841</td>\n",
       "      <td>-0.015698</td>\n",
       "      <td>-0.032567</td>\n",
       "      <td>-0.020638</td>\n",
       "      <td>0.020384</td>\n",
       "      <td>0.029549</td>\n",
       "      <td>0.035703</td>\n",
       "      <td>-0.009456</td>\n",
       "      <td>-0.038961</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005325</td>\n",
       "      <td>-0.000865</td>\n",
       "      <td>-0.006344</td>\n",
       "      <td>-0.000562</td>\n",
       "      <td>-0.011373</td>\n",
       "      <td>-0.000161</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>-0.001771</td>\n",
       "      <td>-0.000563</td>\n",
       "      <td>-0.000628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2416</th>\n",
       "      <td>-0.015348</td>\n",
       "      <td>-0.050589</td>\n",
       "      <td>-0.000972</td>\n",
       "      <td>0.005511</td>\n",
       "      <td>0.010061</td>\n",
       "      <td>0.016410</td>\n",
       "      <td>-0.041210</td>\n",
       "      <td>0.058844</td>\n",
       "      <td>-0.025887</td>\n",
       "      <td>-0.011735</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018803</td>\n",
       "      <td>0.016867</td>\n",
       "      <td>0.012139</td>\n",
       "      <td>0.007154</td>\n",
       "      <td>0.008134</td>\n",
       "      <td>-0.001346</td>\n",
       "      <td>-0.000821</td>\n",
       "      <td>0.003322</td>\n",
       "      <td>-0.006642</td>\n",
       "      <td>-0.012614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2417</th>\n",
       "      <td>-0.003522</td>\n",
       "      <td>0.015157</td>\n",
       "      <td>0.029197</td>\n",
       "      <td>-0.022950</td>\n",
       "      <td>-0.015183</td>\n",
       "      <td>-0.001276</td>\n",
       "      <td>0.010532</td>\n",
       "      <td>-0.017849</td>\n",
       "      <td>-0.042912</td>\n",
       "      <td>0.004876</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001644</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.003882</td>\n",
       "      <td>0.006880</td>\n",
       "      <td>0.001106</td>\n",
       "      <td>0.005042</td>\n",
       "      <td>0.008657</td>\n",
       "      <td>0.002099</td>\n",
       "      <td>0.008879</td>\n",
       "      <td>0.005425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2418</th>\n",
       "      <td>0.162229</td>\n",
       "      <td>0.062337</td>\n",
       "      <td>-0.228693</td>\n",
       "      <td>-0.053321</td>\n",
       "      <td>0.088912</td>\n",
       "      <td>0.067402</td>\n",
       "      <td>-0.140253</td>\n",
       "      <td>-0.095661</td>\n",
       "      <td>0.138672</td>\n",
       "      <td>-0.058650</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007322</td>\n",
       "      <td>0.005421</td>\n",
       "      <td>0.004941</td>\n",
       "      <td>-0.003199</td>\n",
       "      <td>-0.009513</td>\n",
       "      <td>-0.007301</td>\n",
       "      <td>-0.003157</td>\n",
       "      <td>-0.001795</td>\n",
       "      <td>0.006901</td>\n",
       "      <td>-0.002802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2419</th>\n",
       "      <td>0.030335</td>\n",
       "      <td>-0.052862</td>\n",
       "      <td>-0.015650</td>\n",
       "      <td>0.001528</td>\n",
       "      <td>-0.020507</td>\n",
       "      <td>0.048299</td>\n",
       "      <td>0.016255</td>\n",
       "      <td>-0.020065</td>\n",
       "      <td>0.015202</td>\n",
       "      <td>0.012079</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005493</td>\n",
       "      <td>-0.007933</td>\n",
       "      <td>-0.004711</td>\n",
       "      <td>-0.013027</td>\n",
       "      <td>-0.013000</td>\n",
       "      <td>-0.009908</td>\n",
       "      <td>-0.009209</td>\n",
       "      <td>-0.009237</td>\n",
       "      <td>-0.017097</td>\n",
       "      <td>-0.003356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2420 rows × 360 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      accel-x-0  accel-x-1  accel-x-2  accel-x-3  accel-x-4  accel-x-5  \\\n",
       "0      4.339089  -1.167666  -3.694124  -3.991698  -3.144751  -4.243802   \n",
       "1     -1.999586  -1.566372  -1.517025  -2.713303   0.712069   2.309685   \n",
       "2     -0.876184  -1.637183  -0.968435  -4.894519  -2.211239  -0.815775   \n",
       "3      1.649148  -1.854505   3.019927   3.966432  -0.782214  -2.535543   \n",
       "4      3.431428   0.846879   0.397590   1.620648  -2.014615  -3.534210   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "2415  -0.055121  -0.013841  -0.015698  -0.032567  -0.020638   0.020384   \n",
       "2416  -0.015348  -0.050589  -0.000972   0.005511   0.010061   0.016410   \n",
       "2417  -0.003522   0.015157   0.029197  -0.022950  -0.015183  -0.001276   \n",
       "2418   0.162229   0.062337  -0.228693  -0.053321   0.088912   0.067402   \n",
       "2419   0.030335  -0.052862  -0.015650   0.001528  -0.020507   0.048299   \n",
       "\n",
       "      accel-x-6  accel-x-7  accel-x-8  accel-x-9  ...  gyro-z-50  gyro-z-51  \\\n",
       "0     -0.346311   4.784375   5.407283   2.445792  ...   0.022887  -0.159737   \n",
       "1      3.010014   3.875827   1.239790  -0.457387  ...  -0.684964  -0.555177   \n",
       "2      1.349346   0.910528   1.072714   2.240573  ...   0.064544   0.164004   \n",
       "3     -3.642630  -2.326545  -2.164334  -0.037000  ...  -0.264074   0.088056   \n",
       "4     -1.916457  -1.600943  -1.037111   0.433378  ...   0.246871   0.168610   \n",
       "...         ...        ...        ...        ...  ...        ...        ...   \n",
       "2415   0.029549   0.035703  -0.009456  -0.038961  ...  -0.005325  -0.000865   \n",
       "2416  -0.041210   0.058844  -0.025887  -0.011735  ...   0.018803   0.016867   \n",
       "2417   0.010532  -0.017849  -0.042912   0.004876  ...   0.001644   0.000004   \n",
       "2418  -0.140253  -0.095661   0.138672  -0.058650  ...   0.007322   0.005421   \n",
       "2419   0.016255  -0.020065   0.015202   0.012079  ...   0.005493  -0.007933   \n",
       "\n",
       "      gyro-z-52  gyro-z-53  gyro-z-54  gyro-z-55  gyro-z-56  gyro-z-57  \\\n",
       "0     -0.375233   0.051135   0.921111   0.278494  -0.133034  -0.033831   \n",
       "1     -0.076758   0.106422   0.348305   0.280755   0.141009  -0.206322   \n",
       "2      0.180907  -0.684902  -0.689362   0.008271   0.051843   0.089196   \n",
       "3      0.465905   0.422788  -0.038715  -0.766346   0.376857  -0.127370   \n",
       "4      0.257335   0.179625   0.129522   0.167631  -0.061982   0.597766   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "2415  -0.006344  -0.000562  -0.011373  -0.000161   0.007937  -0.001771   \n",
       "2416   0.012139   0.007154   0.008134  -0.001346  -0.000821   0.003322   \n",
       "2417   0.003882   0.006880   0.001106   0.005042   0.008657   0.002099   \n",
       "2418   0.004941  -0.003199  -0.009513  -0.007301  -0.003157  -0.001795   \n",
       "2419  -0.004711  -0.013027  -0.013000  -0.009908  -0.009209  -0.009237   \n",
       "\n",
       "      gyro-z-58  gyro-z-59  \n",
       "0     -0.145661  -0.039100  \n",
       "1      0.010000   0.119462  \n",
       "2     -0.178239   0.031978  \n",
       "3      0.074219   0.437026  \n",
       "4     -0.117428  -0.170377  \n",
       "...         ...        ...  \n",
       "2415  -0.000563  -0.000628  \n",
       "2416  -0.006642  -0.012614  \n",
       "2417   0.008879   0.005425  \n",
       "2418   0.006901  -0.002802  \n",
       "2419  -0.017097  -0.003356  \n",
       "\n",
       "[2420 rows x 360 columns]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0 shape: torch.Size([60, 6, 60])\n",
      "Batch 1 shape: torch.Size([60, 6, 60])\n",
      "Batch 2 shape: torch.Size([60, 6, 60])\n",
      "Batch 3 shape: torch.Size([60, 6, 60])\n",
      "Batch 4 shape: torch.Size([60, 6, 60])\n",
      "Batch 5 shape: torch.Size([60, 6, 60])\n",
      "Batch 6 shape: torch.Size([60, 6, 60])\n",
      "Batch 7 shape: torch.Size([60, 6, 60])\n",
      "Batch 8 shape: torch.Size([60, 6, 60])\n",
      "Batch 9 shape: torch.Size([60, 6, 60])\n",
      "Batch 10 shape: torch.Size([60, 6, 60])\n",
      "Batch 11 shape: torch.Size([60, 6, 60])\n",
      "Batch 12 shape: torch.Size([60, 6, 60])\n",
      "Batch 13 shape: torch.Size([60, 6, 60])\n",
      "Batch 14 shape: torch.Size([60, 6, 60])\n",
      "Batch 15 shape: torch.Size([60, 6, 60])\n",
      "Batch 16 shape: torch.Size([60, 6, 60])\n",
      "Batch 17 shape: torch.Size([60, 6, 60])\n",
      "Batch 18 shape: torch.Size([60, 6, 60])\n",
      "Batch 19 shape: torch.Size([60, 6, 60])\n",
      "Batch 20 shape: torch.Size([60, 6, 60])\n",
      "Batch 21 shape: torch.Size([60, 6, 60])\n",
      "Batch 22 shape: torch.Size([60, 6, 60])\n",
      "Batch 23 shape: torch.Size([60, 6, 60])\n",
      "Batch 24 shape: torch.Size([60, 6, 60])\n",
      "Batch 25 shape: torch.Size([60, 6, 60])\n",
      "Batch 26 shape: torch.Size([60, 6, 60])\n",
      "Batch 27 shape: torch.Size([60, 6, 60])\n",
      "Batch 28 shape: torch.Size([60, 6, 60])\n",
      "Batch 29 shape: torch.Size([60, 6, 60])\n",
      "Batch 30 shape: torch.Size([60, 6, 60])\n",
      "Batch 31 shape: torch.Size([60, 6, 60])\n",
      "Batch 32 shape: torch.Size([60, 6, 60])\n",
      "Batch 33 shape: torch.Size([60, 6, 60])\n",
      "Batch 34 shape: torch.Size([60, 6, 60])\n",
      "Batch 35 shape: torch.Size([60, 6, 60])\n",
      "Batch 36 shape: torch.Size([60, 6, 60])\n",
      "Batch 37 shape: torch.Size([60, 6, 60])\n",
      "Batch 38 shape: torch.Size([60, 6, 60])\n",
      "Batch 39 shape: torch.Size([60, 6, 60])\n",
      "Batch 0 shape: torch.Size([60])\n",
      "Batch 1 shape: torch.Size([60])\n",
      "Batch 2 shape: torch.Size([60])\n",
      "Batch 3 shape: torch.Size([60])\n",
      "Batch 4 shape: torch.Size([60])\n"
     ]
    }
   ],
   "source": [
    "# shape dataloader\n",
    "\n",
    "for i, (x, y) in enumerate(dataloader_train):\n",
    "    print(f\"Batch {i} shape: {x.shape}\")\n",
    "\n",
    "for i, (x, y) in enumerate(dataloader_val):\n",
    "    print(f\"Batch {i} shape: {y.shape}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_size = 128\n",
    "\n",
    "n_classes = 7\n",
    "\n",
    "num_channels = 6\n",
    "\n",
    "CNNclassifier = EncoderClassifier(num_channels=6, device='cuda')\n",
    "\n",
    "classifier = StateClassifier(input_size=encoding_size, n_classes=n_classes, dropout_prob=0, hidden_size1= 64, hidden_size2=32)\n",
    "\n",
    "cpc_classifier = CPC_Classifier(CNNclassifier, classifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cpc_classifier = cpc_classifier.to('cpu')\n",
    "\n",
    "# xtest = cpc_classifier.forward(tensor_x_test.to('cpu'))\n",
    "\n",
    "# xtest = xtest.detach().numpy()\n",
    "\n",
    "# xtrain = cpc_classifier.forward(tensor_x.to('cpu'))\n",
    "\n",
    "# xtrain = xtrain.detach().numpy()\n",
    "\n",
    "# ytrain = tensor_y.detach().numpy()\n",
    "\n",
    "# ytest = tensor_y_test.detach().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# random_forest_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# random_forest_model.fit(xtrain, ytrain)\n",
    "\n",
    "# # Faça previsões no conjunto de teste\n",
    "# predictions = random_forest_model.predict(xtest)\n",
    "\n",
    "# # Avalie o desempenho do modelo usando métricas, como a precisão\n",
    "# accuracy = accuracy_score(ytest, predictions)\n",
    "\n",
    "# print(f'A precisão do modelo no conjunto de teste é: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # KNN\n",
    "\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# # Criar o modelo KNN\n",
    "# knn_model = KNeighborsClassifier(n_neighbors=5)  # Pode ajustar o número de vizinhos conforme necessário\n",
    "\n",
    "# # Treinar o modelo\n",
    "# knn_model.fit(xtrain, ytrain)\n",
    "\n",
    "# # Fazer previsões no conjunto de teste\n",
    "# predictions_knn = knn_model.predict(xtest)\n",
    "\n",
    "# # Avaliar o desempenho do modelo usando métricas, como a precisão\n",
    "# accuracy_knn = accuracy_score(ytest, predictions_knn)\n",
    "\n",
    "# print(\"Accuracy (KNN):\", accuracy_knn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import SVC\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# # Criar o modelo SVM\n",
    "# svm_model = SVC(kernel='linear', C=1.0)  # Pode ajustar o kernel e C conforme necessário\n",
    "\n",
    "# # Treinar o modelo\n",
    "# svm_model.fit(xtrain, ytrain)\n",
    "\n",
    "# # Fazer previsões no conjunto de teste\n",
    "# predictions_svm = svm_model.predict(xtest)\n",
    "\n",
    "# # Avaliar o desempenho do modelo usando métricas, como a precisão\n",
    "# accuracy_svm = accuracy_score(ytest, predictions_svm)\n",
    "\n",
    "# print(\"Accuracy (SVM):\", accuracy_svm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(max_epochs=10, accelerator=\"gpu\", devices=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name          | Type              | Params\n",
      "----------------------------------------------------\n",
      "0 | encoderCNN    | EncoderClassifier | 31.5 K\n",
      "1 | classifier    | StateClassifier   | 10.6 K\n",
      "2 | loss_function | CrossEntropyLoss  | 0     \n",
      "----------------------------------------------------\n",
      "42.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "42.1 K    Total params\n",
      "0.168     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]CNN\n",
      "torch.Size([60, 60, 128])\n",
      "saindo do encoding: torch.Size([3600, 128])\n",
      "st1_in: torch.Size([3600, 128])\n",
      "st2_in: torch.Size([3600, 128])\n",
      "stdp_in: torch.Size([3600, 128])\n",
      "stout_in: torch.Size([3600, 128])\n",
      "out_: torch.Size([3600, 128])\n",
      "pred_outed: tensor([[0.1469, 0.1409, 0.1192,  ..., 0.1437, 0.1392, 0.1447],\n",
      "        [0.1465, 0.1410, 0.1195,  ..., 0.1438, 0.1392, 0.1445],\n",
      "        [0.1471, 0.1408, 0.1193,  ..., 0.1439, 0.1390, 0.1446],\n",
      "        ...,\n",
      "        [0.1468, 0.1408, 0.1191,  ..., 0.1436, 0.1391, 0.1448],\n",
      "        [0.1468, 0.1408, 0.1191,  ..., 0.1437, 0.1391, 0.1448],\n",
      "        [0.1465, 0.1413, 0.1193,  ..., 0.1435, 0.1391, 0.1445]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/betania_meta4/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:492: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
      "/home/betania_meta4/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected input batch_size (3600) to match target batch_size (60).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[160], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcpc_classifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataloader_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataloader_val\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:544\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    543\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 544\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     47\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:580\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    574\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    576\u001b[0m     ckpt_path,\n\u001b[1;32m    577\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    578\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    579\u001b[0m )\n\u001b[0;32m--> 580\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:989\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m    986\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    987\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 989\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    991\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    992\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    993\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    994\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1033\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[1;32m   1032\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m isolate_rng():\n\u001b[0;32m-> 1033\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_sanity_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1034\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[1;32m   1035\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_loop\u001b[38;5;241m.\u001b[39mrun()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1062\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1059\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;66;03m# run eval step\u001b[39;00m\n\u001b[0;32m-> 1062\u001b[0m \u001b[43mval_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1064\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_end\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1066\u001b[0m \u001b[38;5;66;03m# reset logger connector\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pytorch_lightning/loops/utilities.py:182\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m     context_manager \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mno_grad\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context_manager():\n\u001b[0;32m--> 182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py:134\u001b[0m, in \u001b[0;36m_EvaluationLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mis_last_batch \u001b[38;5;241m=\u001b[39m data_fetcher\u001b[38;5;241m.\u001b[39mdone\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;66;03m# run step hooks\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;66;03m# this needs to wrap the `*_step` call too (not just `next`) for `dataloader_iter` support\u001b[39;00m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py:391\u001b[0m, in \u001b[0;36m_EvaluationLoop._evaluation_step\u001b[0;34m(self, batch, batch_idx, dataloader_idx, dataloader_iter)\u001b[0m\n\u001b[1;32m    385\u001b[0m hook_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_step\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mtesting \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_step\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    386\u001b[0m step_args \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_step_args_from_hook_kwargs(hook_kwargs, hook_name)\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_dataloader_iter\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m (dataloader_iter,)\n\u001b[1;32m    390\u001b[0m )\n\u001b[0;32m--> 391\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstep_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_processed()\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m using_dataloader_iter:\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;66;03m# update the hook kwargs now that the step method might have consumed the iterator\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:309\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 309\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    312\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py:403\u001b[0m, in \u001b[0;36mStrategy.validation_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_redirection(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_step\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 403\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[148], line 85\u001b[0m, in \u001b[0;36mCPC_Classifier.validation_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidation_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, batch_idx):\n\u001b[0;32m---> 85\u001b[0m     loss, acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_shared_eval_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidation_step_losses\u001b[38;5;241m.\u001b[39mappend(loss)\n\u001b[1;32m     87\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_acc\u001b[39m\u001b[38;5;124m\"\u001b[39m: acc, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m: loss}\n",
      "Cell \u001b[0;32mIn[148], line 108\u001b[0m, in \u001b[0;36mCPC_Classifier._shared_eval_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m    106\u001b[0m x, y \u001b[38;5;241m=\u001b[39m batch\n\u001b[1;32m    107\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(x)\n\u001b[0;32m--> 108\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m acc \u001b[38;5;241m=\u001b[39m accuracy(torch\u001b[38;5;241m.\u001b[39margmax(predictions, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), y\u001b[38;5;241m.\u001b[39mlong(), task\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask_class, num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_classes)\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss, acc\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/loss.py:1179\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m-> 1179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1180\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1181\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/functional.py:3053\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3051\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3052\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3053\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected input batch_size (3600) to match target batch_size (60)."
     ]
    }
   ],
   "source": [
    "trainer.fit(cpc_classifier, train_dataloaders=dataloader_train, val_dataloaders=dataloader_val)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "/home/vscode/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:492: Your `test_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
      "/home/vscode/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 21/21 [00:00<00:00, 82.85it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.6592261791229248\n",
      "        test_loss           1.4835978746414185\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_acc': 0.6592261791229248, 'test_loss': 1.4835978746414185}]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(cpc_classifier, dataloader_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
