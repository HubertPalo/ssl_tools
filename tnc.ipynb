{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "    \n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import plotly.graph_objects as go\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import math\n",
    "import functools\n",
    "\n",
    "import sys\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21, 561, 281), (21, 281), (9, 561, 288), (9, 288))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = Path('data/TNC/HAR_data')\n",
    "x_train = np.load(data_path/'x_train.npy')\n",
    "y_train = np.load(data_path/'y_train.npy')\n",
    "x_test = np.load(data_path/'x_test.npy')\n",
    "y_test = np.load(data_path/'y_test.npy')\n",
    "\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TNCDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data: np.ndarray,\n",
    "        mc_sample_size: int,\n",
    "        window_size: int,\n",
    "        state: float = None,\n",
    "        adf: bool = True,\n",
    "        augmentation: int = 1  # Simple repeat the vecvor 'augmentation' times\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.time_series = data\n",
    "        self.T = data.shape[-1]\n",
    "        self.window_size = window_size\n",
    "        self.sliding_gap = int(window_size * 25.2)\n",
    "        self.window_per_sample = (self.T - 2 * self.window_size) // self.sliding_gap\n",
    "        self.mc_sample_size = mc_sample_size\n",
    "        self.state = state\n",
    "        self.adf = adf\n",
    "        self.epsilon = None\n",
    "        self.augmentation = augmentation\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.time_series) * self.augmentation\n",
    "\n",
    "    # @functools.cache\n",
    "    def __getitem__(self, ind):\n",
    "        ind = ind % len(self.time_series)       # To repeat augmentation\n",
    "        t = np.random.randint(2 * self.window_size, self.T - 2 * self.window_size)\n",
    "        x_t = self.time_series[ind][\n",
    "            :, t - self.window_size // 2 : t + self.window_size // 2\n",
    "        ]\n",
    "        X_close = self._find_neighours(self.time_series[ind], t)\n",
    "        X_distant = self._find_non_neighours(self.time_series[ind], t)\n",
    "\n",
    "        if self.state is None:\n",
    "            y_t = -1\n",
    "        else:\n",
    "            y_t = np.round(\n",
    "                np.mean(\n",
    "                    self.state[ind][\n",
    "                        t - self.window_size // 2 : t + self.window_size // 2\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "        return (\n",
    "            x_t.astype(np.float32),\n",
    "            X_close.astype(np.float32),\n",
    "            X_distant.astype(np.float32),\n",
    "            y_t,\n",
    "        )\n",
    "\n",
    "    def _find_neighours(self, x, t):\n",
    "        T = self.time_series.shape[-1]\n",
    "\n",
    "        # ---- Do the ADF test ----\n",
    "        gap = self.window_size\n",
    "        corr = []\n",
    "        for w_t in range(self.window_size, 4 * self.window_size, gap):\n",
    "            try:\n",
    "                p_val = 0\n",
    "                for f in range(x.shape[-2]):\n",
    "                    p = adfuller(\n",
    "                        np.array(\n",
    "                            x[\n",
    "                                f, max(0, t - w_t) : min(x.shape[-1], t + w_t)\n",
    "                            ].reshape(\n",
    "                                -1,\n",
    "                            )\n",
    "                        )\n",
    "                    )[1]\n",
    "                    p_val += 0.01 if math.isnan(p) else p\n",
    "                corr.append(p_val / x.shape[-2])\n",
    "            except:\n",
    "                corr.append(0.6)\n",
    "        self.epsilon = (\n",
    "            len(corr)\n",
    "            if len(np.where(np.array(corr) >= 0.01)[0]) == 0\n",
    "            else (np.where(np.array(corr) >= 0.01)[0][0] + 1)\n",
    "        )\n",
    "        self.delta = 5 * self.epsilon * self.window_size\n",
    "        # --------------------------\n",
    "\n",
    "        ## Random from a Gaussian\n",
    "        t_p = [\n",
    "            int(t + np.random.randn() * self.epsilon * self.window_size)\n",
    "            for _ in range(self.mc_sample_size)\n",
    "        ]\n",
    "        t_p = [\n",
    "            max(self.window_size // 2 + 1, min(t_pp, T - self.window_size // 2))\n",
    "            for t_pp in t_p\n",
    "        ]\n",
    "        x_p = np.stack(\n",
    "            [\n",
    "                x[:, t_ind - self.window_size // 2 : t_ind + self.window_size // 2]\n",
    "                for t_ind in t_p\n",
    "            ]\n",
    "        )\n",
    "        return x_p\n",
    "\n",
    "    def _find_non_neighours(self, x, t):\n",
    "        T = self.time_series.shape[-1]\n",
    "        if t > T / 2:\n",
    "            t_n = np.random.randint(\n",
    "                self.window_size // 2,\n",
    "                max((t - self.delta + 1), self.window_size // 2 + 1),\n",
    "                self.mc_sample_size,\n",
    "            )\n",
    "        else:\n",
    "            t_n = np.random.randint(\n",
    "                min((t + self.delta), (T - self.window_size - 1)),\n",
    "                (T - self.window_size // 2),\n",
    "                self.mc_sample_size,\n",
    "            )\n",
    "        x_n = np.stack(\n",
    "            [\n",
    "                x[:, t_ind - self.window_size // 2 : t_ind + self.window_size // 2]\n",
    "                for t_ind in t_n\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        if len(x_n) == 0:\n",
    "            rand_t = np.random.randint(0, self.window_size // 5)\n",
    "            if t > T / 2:\n",
    "                x_n = x[:, rand_t : rand_t + self.window_size].unsqueeze(0)\n",
    "            else:\n",
    "                x_n = x[:, T - rand_t - self.window_size : T - rand_t].unsqueeze(0)\n",
    "        return x_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(torch.nn.Module):\n",
    "    def __init__(self, input_size, device: str = \"cpu\"):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.input_size = input_size\n",
    "\n",
    "        self.model = torch.nn.Sequential(\n",
    "            torch.nn.Linear(2 * self.input_size, 4 * self.input_size),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Dropout(0.5),\n",
    "            torch.nn.Linear(4 * self.input_size, 1),\n",
    "        ).to(device)\n",
    "\n",
    "        torch.nn.init.xavier_uniform_(self.model[0].weight)\n",
    "        torch.nn.init.xavier_uniform_(self.model[3].weight)\n",
    "\n",
    "    def forward(self, x, x_tild):\n",
    "        \"\"\"\n",
    "        Predict the probability of the two inputs belonging to the same neighbourhood.\n",
    "        \"\"\"\n",
    "        x_all = torch.cat([x, x_tild], -1)\n",
    "        p = self.model(x_all)\n",
    "        return p.view((-1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUEncoder(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        hidden_size: int = 100,\n",
    "        in_channel: int = 561,\n",
    "        encoding_size: int = 10,\n",
    "        num_layers: int = 1,\n",
    "        dropout: float = 0.0,\n",
    "        bidirectional: bool = True,\n",
    "        device: str = \"cpu\",\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.in_channel = in_channel\n",
    "        self.num_layers = num_layers\n",
    "        self.encoding_size = encoding_size\n",
    "        self.bidirectional = bidirectional\n",
    "        self.device = device\n",
    "        \n",
    "        self.rnn = torch.nn.GRU(\n",
    "            input_size=self.in_channel,\n",
    "            hidden_size=self.hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=False,\n",
    "            dropout=dropout,\n",
    "            bidirectional=bidirectional,\n",
    "        ).to(device)\n",
    "\n",
    "        self.nn = torch.nn.Linear(\n",
    "            self.hidden_size * (int(self.bidirectional) + 1), self.encoding_size\n",
    "        ).to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(2, 0, 1)\n",
    "\n",
    "        past = torch.zeros(\n",
    "            self.num_layers * (int(self.bidirectional) + 1),\n",
    "            x.shape[1],\n",
    "            self.hidden_size,\n",
    "            device=self.device,\n",
    "        )\n",
    "\n",
    "        out, _ = self.rnn(\n",
    "            x, past\n",
    "        )  # out shape = [seq_len, batch_size, num_directions*hidden_size]\n",
    "        encodings = self.nn(out[-1].squeeze(0))\n",
    "        return encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TNC(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        encoder: torch.nn.Module,\n",
    "        discriminator: torch.nn.Module,\n",
    "        mc_sample_size: int = 20,\n",
    "        window_size: int = 4,\n",
    "        w: float = 0.05,\n",
    "        lr: float = 1e-3,\n",
    "        weight_decay: float = 1e-5,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder.to(self.device)\n",
    "        self.discriminator = discriminator.to(self.device)\n",
    "        self.mc_sample_size = mc_sample_size\n",
    "        self.window_size = window_size\n",
    "        self.w = w\n",
    "        self.learning_rate = lr\n",
    "        self.weight_decay = weight_decay\n",
    "        self.loss_func = torch.nn.BCEWithLogitsLoss()\n",
    "        self.training_step_losses = []\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x_t, x_p, x_n, _ = batch\n",
    "        mc_sample = x_p.shape[1]\n",
    "        batch_size, f_size, len_size = x_t.shape\n",
    "        x_p = x_p.view(-1, f_size, len_size)\n",
    "        x_n = x_n.view(-1, f_size, len_size)\n",
    "        x_t = x_t.repeat(mc_sample, 1, 1)\n",
    "        neighbors = torch.ones(len(x_p)).to(self.device)\n",
    "        non_neighbors = torch.zeros(len(x_n)).to(self.device)\n",
    "        x_t, x_p, x_n = x_t.to(self.device), x_p.to(self.device), x_n.to(self.device)\n",
    "\n",
    "        z_t = self.encoder(x_t)\n",
    "        z_p = self.encoder(x_p)\n",
    "        z_n = self.encoder(x_n)\n",
    "\n",
    "        d_p = self.discriminator(z_t, z_p)\n",
    "        d_n = self.discriminator(z_t, z_n)\n",
    "\n",
    "        p_loss = self.loss_func(d_p, neighbors)\n",
    "        n_loss = self.loss_func(d_n, non_neighbors)\n",
    "        n_loss_u = self.loss_func(d_n, neighbors)\n",
    "        loss = (p_loss + self.w * n_loss_u + (1 - self.w) * n_loss) / 2\n",
    "\n",
    "        self.training_step_losses.append(loss)\n",
    "        return loss\n",
    "    \n",
    "    def on_train_epoch_end(self) -> None:\n",
    "        # do something with all training_step outputs, for example:\n",
    "        epoch_mean = torch.stack(self.training_step_losses).mean()\n",
    "        self.log(\"train_loss\", epoch_mean, on_epoch=True, on_step=False, prog_bar=True, logger=True)\n",
    "        # free up the memory\n",
    "        self.training_step_losses.clear()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        learnable_parameters = list(self.discriminator.parameters()) + list(\n",
    "            self.encoder.parameters()\n",
    "        )\n",
    "\n",
    "        optimizer = torch.optim.Adam(\n",
    "            learnable_parameters, lr=self.learning_rate, weight_decay=self.weight_decay\n",
    "        )\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_size = 10\n",
    "window_size = 4\n",
    "augmentation = 5\n",
    "batch_size = 10\n",
    "mc_sample_size = 20\n",
    "workers = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 25)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train test split X_train and y_train to train and validation using sklearn train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = TNCDataset(X_train, mc_sample_size=20, window_size=4, augmentation=augmentation)\n",
    "validation_dataset = TNCDataset(X_val, mc_sample_size=20, window_size=4, augmentation=augmentation)\n",
    "\n",
    "len(train_dataset), len(validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[ 0.2763,  0.2715,  0.3049,  0.2563],\n",
       "          [-0.0189, -0.0189, -0.0117, -0.0208],\n",
       "          [-0.1015, -0.1040, -0.1243, -0.0989],\n",
       "          ...,\n",
       "          [ 0.3378,  0.3386,  0.3394,  0.3343],\n",
       "          [-0.3865, -0.3849, -0.3841, -0.3867],\n",
       "          [-0.5799, -0.5818, -0.5828, -0.5784]],\n",
       " \n",
       "         [[ 0.2279,  0.2518,  0.3161,  0.3884],\n",
       "          [-0.0422, -0.0193,  0.0090,  0.0448],\n",
       "          [-0.0994, -0.1214, -0.1238, -0.0992],\n",
       "          ...,\n",
       "          [-0.5307, -0.5237, -0.5183, -0.5252],\n",
       "          [ 0.2639,  0.2712,  0.2739,  0.2672],\n",
       "          [ 0.3025,  0.3032,  0.3058,  0.3047]],\n",
       " \n",
       "         [[ 0.3800,  0.3267,  0.2905,  0.3062],\n",
       "          [-0.0405, -0.0287, -0.0134, -0.0175],\n",
       "          [-0.1390, -0.1106, -0.1092, -0.1156],\n",
       "          ...,\n",
       "          [ 0.3761,  0.3577,  0.3407,  0.3382],\n",
       "          [-0.2828, -0.2782, -0.2726, -0.2733],\n",
       "          [-0.6969, -0.6953, -0.6947, -0.6931]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 0.2961,  0.2806,  0.2698,  0.2822],\n",
       "          [-0.0081, -0.0173, -0.0205, -0.0120],\n",
       "          [-0.0712, -0.1066, -0.1257, -0.1108],\n",
       "          ...,\n",
       "          [-0.6009, -0.6113, -0.6107, -0.6061],\n",
       "          [ 0.3300,  0.3270,  0.3276,  0.3289],\n",
       "          [ 0.1674,  0.1589,  0.1587,  0.1626]],\n",
       " \n",
       "         [[ 0.2891,  0.2651,  0.2852,  0.2592],\n",
       "          [-0.0160, -0.0693, -0.0117, -0.0176],\n",
       "          [-0.1087, -0.0271, -0.1133, -0.1083],\n",
       "          ...,\n",
       "          [ 0.6703,  0.6335,  0.6474,  0.6434],\n",
       "          [-0.2895, -0.4339, -0.4045, -0.4068],\n",
       "          [-0.7212, -0.5747, -0.6043, -0.6022]],\n",
       " \n",
       "         [[ 0.2740,  0.2874,  0.2747,  0.2720],\n",
       "          [-0.0156, -0.0198, -0.0161, -0.0142],\n",
       "          [-0.1009, -0.1206, -0.1036, -0.1013],\n",
       "          ...,\n",
       "          [-0.6706, -0.6691, -0.6732, -0.6704],\n",
       "          [-0.0162, -0.0165, -0.0156, -0.0165],\n",
       "          [-0.1882, -0.1892, -0.1864, -0.1882]]]),\n",
       " tensor([[[[ 2.7626e-01,  2.7150e-01,  3.0492e-01,  2.5630e-01],\n",
       "           [-1.8928e-02, -1.8868e-02, -1.1733e-02, -2.0838e-02],\n",
       "           [-1.0152e-01, -1.0404e-01, -1.2431e-01, -9.8935e-02],\n",
       "           ...,\n",
       "           [ 3.3783e-01,  3.3860e-01,  3.3936e-01,  3.3426e-01],\n",
       "           [-3.8645e-01, -3.8489e-01, -3.8412e-01, -3.8669e-01],\n",
       "           [-5.7991e-01, -5.8177e-01, -5.8283e-01, -5.7843e-01]],\n",
       " \n",
       "          [[ 2.7112e-01,  2.7838e-01,  2.8107e-01,  2.4593e-01],\n",
       "           [-1.9741e-02, -1.7858e-02, -1.6575e-02, -2.1870e-02],\n",
       "           [-1.0295e-01, -1.0628e-01, -1.0955e-01, -9.4494e-02],\n",
       "           ...,\n",
       "           [ 3.3246e-01,  3.3370e-01,  3.3387e-01,  3.3441e-01],\n",
       "           [-3.8974e-01, -3.8838e-01, -3.8772e-01, -3.8758e-01],\n",
       "           [-5.7467e-01, -5.7650e-01, -5.7723e-01, -5.7757e-01]],\n",
       " \n",
       "          [[ 2.8107e-01,  2.4593e-01,  2.9014e-01,  2.7626e-01],\n",
       "           [-1.6575e-02, -2.1870e-02, -1.4815e-02, -1.8928e-02],\n",
       "           [-1.0955e-01, -9.4494e-02, -1.1572e-01, -1.0152e-01],\n",
       "           ...,\n",
       "           [ 3.3387e-01,  3.3441e-01,  3.4030e-01,  3.3783e-01],\n",
       "           [-3.8772e-01, -3.8758e-01, -3.8557e-01, -3.8645e-01],\n",
       "           [-5.7723e-01, -5.7757e-01, -5.8166e-01, -5.7991e-01]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 2.7838e-01,  2.8107e-01,  2.4593e-01,  2.9014e-01],\n",
       "           [-1.7858e-02, -1.6575e-02, -2.1870e-02, -1.4815e-02],\n",
       "           [-1.0628e-01, -1.0955e-01, -9.4494e-02, -1.1572e-01],\n",
       "           ...,\n",
       "           [ 3.3370e-01,  3.3387e-01,  3.3441e-01,  3.4030e-01],\n",
       "           [-3.8838e-01, -3.8772e-01, -3.8758e-01, -3.8557e-01],\n",
       "           [-5.7650e-01, -5.7723e-01, -5.7757e-01, -5.8166e-01]],\n",
       " \n",
       "          [[ 2.7112e-01,  2.7838e-01,  2.8107e-01,  2.4593e-01],\n",
       "           [-1.9741e-02, -1.7858e-02, -1.6575e-02, -2.1870e-02],\n",
       "           [-1.0295e-01, -1.0628e-01, -1.0955e-01, -9.4494e-02],\n",
       "           ...,\n",
       "           [ 3.3246e-01,  3.3370e-01,  3.3387e-01,  3.3441e-01],\n",
       "           [-3.8974e-01, -3.8838e-01, -3.8772e-01, -3.8758e-01],\n",
       "           [-5.7467e-01, -5.7650e-01, -5.7723e-01, -5.7757e-01]],\n",
       " \n",
       "          [[ 2.7365e-01,  2.7824e-01,  2.6965e-01,  2.2459e-02],\n",
       "           [-1.8516e-02, -1.8725e-02, -1.7711e-02, -5.6728e-02],\n",
       "           [-1.0528e-01, -1.0517e-01, -1.0587e-01,  5.3845e-02],\n",
       "           ...,\n",
       "           [ 3.3787e-01,  3.3927e-01,  3.3925e-01,  3.3319e-01],\n",
       "           [-3.8537e-01, -3.8437e-01, -3.8374e-01, -3.7431e-01],\n",
       "           [-5.8103e-01, -5.8253e-01, -5.8317e-01, -5.9068e-01]]],\n",
       " \n",
       " \n",
       "         [[[ 2.2786e-01,  2.5184e-01,  3.1614e-01,  3.8845e-01],\n",
       "           [-4.2225e-02, -1.9307e-02,  8.9627e-03,  4.4817e-02],\n",
       "           [-9.9371e-02, -1.2141e-01, -1.2381e-01, -9.9195e-02],\n",
       "           ...,\n",
       "           [-5.3074e-01, -5.2369e-01, -5.1825e-01, -5.2522e-01],\n",
       "           [ 2.6391e-01,  2.7118e-01,  2.7388e-01,  2.6719e-01],\n",
       "           [ 3.0248e-01,  3.0323e-01,  3.0579e-01,  3.0475e-01]],\n",
       " \n",
       "          [[ 2.4447e-01,  2.3558e-01,  2.6215e-01,  2.8750e-01],\n",
       "           [-3.8244e-02, -3.2386e-02, -5.6822e-03, -1.8892e-02],\n",
       "           [-1.3422e-01, -1.1778e-01, -1.3254e-01, -1.0870e-01],\n",
       "           ...,\n",
       "           [-5.5091e-01, -5.4042e-01, -5.3611e-01, -5.2974e-01],\n",
       "           [ 2.5239e-01,  2.5937e-01,  2.6154e-01,  2.5928e-01],\n",
       "           [ 2.9372e-01,  2.9764e-01,  2.9970e-01,  3.0638e-01]],\n",
       " \n",
       "          [[ 2.2786e-01,  2.5184e-01,  3.1614e-01,  3.8845e-01],\n",
       "           [-4.2225e-02, -1.9307e-02,  8.9627e-03,  4.4817e-02],\n",
       "           [-9.9371e-02, -1.2141e-01, -1.2381e-01, -9.9195e-02],\n",
       "           ...,\n",
       "           [-5.3074e-01, -5.2369e-01, -5.1825e-01, -5.2522e-01],\n",
       "           [ 2.6391e-01,  2.7118e-01,  2.7388e-01,  2.6719e-01],\n",
       "           [ 3.0248e-01,  3.0323e-01,  3.0579e-01,  3.0475e-01]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 3.4958e-01,  1.8216e-01,  2.2786e-01,  2.5184e-01],\n",
       "           [-2.0710e-02, -1.0277e-01, -4.2225e-02, -1.9307e-02],\n",
       "           [-1.1911e-01, -5.1900e-02, -9.9371e-02, -1.2141e-01],\n",
       "           ...,\n",
       "           [ 3.9744e-01, -5.5081e-01, -5.3074e-01, -5.2369e-01],\n",
       "           [-2.8435e-01,  2.3740e-01,  2.6391e-01,  2.7118e-01],\n",
       "           [-7.0192e-01,  3.0300e-01,  3.0248e-01,  3.0323e-01]],\n",
       " \n",
       "          [[ 2.8750e-01,  2.9362e-01,  2.9031e-01,  2.7550e-01],\n",
       "           [-1.8892e-02, -3.6426e-02, -1.5830e-02, -1.4957e-02],\n",
       "           [-1.0870e-01, -7.0366e-02, -1.2375e-01, -1.1125e-01],\n",
       "           ...,\n",
       "           [-5.2974e-01, -5.2722e-01, -5.3661e-01, -5.3936e-01],\n",
       "           [ 2.5928e-01,  2.6373e-01,  2.6792e-01,  2.6346e-01],\n",
       "           [ 3.0638e-01,  3.0547e-01,  2.9487e-01,  2.9572e-01]],\n",
       " \n",
       "          [[ 2.5184e-01,  3.1614e-01,  3.8845e-01,  3.4283e-01],\n",
       "           [-1.9307e-02,  8.9627e-03,  4.4817e-02, -8.7929e-03],\n",
       "           [-1.2141e-01, -1.2381e-01, -9.9195e-02, -1.1987e-01],\n",
       "           ...,\n",
       "           [-5.2369e-01, -5.1825e-01, -5.2522e-01, -5.5215e-01],\n",
       "           [ 2.7118e-01,  2.7388e-01,  2.6719e-01,  2.4732e-01],\n",
       "           [ 3.0323e-01,  3.0579e-01,  3.0475e-01,  2.9596e-01]]],\n",
       " \n",
       " \n",
       "         [[[-8.7240e-01,  3.8002e-01,  3.2668e-01,  2.9050e-01],\n",
       "           [ 1.5461e-01, -4.0511e-02, -2.8691e-02, -1.3368e-02],\n",
       "           [ 3.3075e-01, -1.3901e-01, -1.1064e-01, -1.0918e-01],\n",
       "           ...,\n",
       "           [ 7.4088e-02,  3.7609e-01,  3.5768e-01,  3.4070e-01],\n",
       "           [-2.3531e-01, -2.8285e-01, -2.7818e-01, -2.7264e-01],\n",
       "           [-5.9391e-01, -6.9686e-01, -6.9534e-01, -6.9470e-01]],\n",
       " \n",
       "          [[ 3.2086e-01,  3.0536e-01,  2.7525e-01,  2.8591e-01],\n",
       "           [ 8.2959e-04,  9.1376e-03, -6.4348e-03, -1.6785e-02],\n",
       "           [-4.6410e-02, -6.7331e-02, -1.1794e-01, -9.7112e-02],\n",
       "           ...,\n",
       "           [-5.8169e-01, -6.0449e-01, -6.2307e-01, -6.2716e-01],\n",
       "           [ 1.7365e-01,  1.6555e-01,  1.5613e-01,  1.5199e-01],\n",
       "           [ 3.0794e-01,  2.9357e-01,  2.8253e-01,  2.8060e-01]],\n",
       " \n",
       "          [[ 2.7964e-01,  2.8400e-01,  3.0672e-01,  2.6604e-01],\n",
       "           [-1.9873e-02, -1.4347e-02, -4.0476e-03, -1.8702e-02],\n",
       "           [-1.0563e-01, -1.1070e-01, -1.3324e-01, -1.0650e-01],\n",
       "           ...,\n",
       "           [ 3.3175e-01,  3.3049e-01,  3.2808e-01,  3.2161e-01],\n",
       "           [-2.7346e-01, -2.7248e-01, -2.7444e-01, -2.8100e-01],\n",
       "           [-6.9056e-01, -6.9104e-01, -6.8822e-01, -6.7936e-01]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 2.9050e-01,  3.0620e-01,  2.7964e-01,  2.8400e-01],\n",
       "           [-1.3368e-02, -1.7545e-02, -1.9873e-02, -1.4347e-02],\n",
       "           [-1.0918e-01, -1.1559e-01, -1.0563e-01, -1.1070e-01],\n",
       "           ...,\n",
       "           [ 3.4070e-01,  3.3820e-01,  3.3175e-01,  3.3049e-01],\n",
       "           [-2.7264e-01, -2.7334e-01, -2.7346e-01, -2.7248e-01],\n",
       "           [-6.9470e-01, -6.9310e-01, -6.9056e-01, -6.9104e-01]],\n",
       " \n",
       "          [[ 2.8591e-01,  2.7777e-01,  2.7637e-01,  2.8262e-01],\n",
       "           [-1.6785e-02, -1.7170e-02, -1.5784e-02, -1.7185e-02],\n",
       "           [-9.7112e-02, -1.0683e-01, -1.1259e-01, -1.0647e-01],\n",
       "           ...,\n",
       "           [-6.2716e-01, -6.3050e-01, -6.2967e-01, -6.2831e-01],\n",
       "           [ 1.5199e-01,  1.5134e-01,  1.5157e-01,  1.5110e-01],\n",
       "           [ 2.8060e-01,  2.7831e-01,  2.7886e-01,  2.7997e-01]],\n",
       " \n",
       "          [[ 3.8002e-01,  3.2668e-01,  2.9050e-01,  3.0620e-01],\n",
       "           [-4.0511e-02, -2.8691e-02, -1.3368e-02, -1.7545e-02],\n",
       "           [-1.3901e-01, -1.1064e-01, -1.0918e-01, -1.1559e-01],\n",
       "           ...,\n",
       "           [ 3.7609e-01,  3.5768e-01,  3.4070e-01,  3.3820e-01],\n",
       "           [-2.8285e-01, -2.7818e-01, -2.7264e-01, -2.7334e-01],\n",
       "           [-6.9686e-01, -6.9534e-01, -6.9470e-01, -6.9310e-01]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 2.8223e-01,  2.7602e-01,  2.7537e-01,  2.9332e-01],\n",
       "           [-1.1976e-02, -1.6857e-02, -1.6495e-02, -8.3139e-03],\n",
       "           [-1.1081e-01, -1.1306e-01, -1.1929e-01, -8.6588e-02],\n",
       "           ...,\n",
       "           [-6.0607e-01, -6.0791e-01, -6.0719e-01, -6.0672e-01],\n",
       "           [ 3.2894e-01,  3.2697e-01,  3.2641e-01,  3.2540e-01],\n",
       "           [ 1.6260e-01,  1.6346e-01,  1.6528e-01,  1.6750e-01]],\n",
       " \n",
       "          [[ 2.8228e-01,  2.7012e-01,  2.6113e-01,  2.7641e-01],\n",
       "           [-9.9142e-03, -2.2320e-02, -2.1972e-02, -1.4927e-02],\n",
       "           [-1.0746e-01, -9.1740e-02, -1.4610e-01, -1.1322e-01],\n",
       "           ...,\n",
       "           [-6.0662e-01, -6.0940e-01, -6.0873e-01, -5.9993e-01],\n",
       "           [ 3.2953e-01,  3.2807e-01,  3.2954e-01,  3.3090e-01],\n",
       "           [ 1.6091e-01,  1.5968e-01,  1.5808e-01,  1.6735e-01]],\n",
       " \n",
       "          [[ 2.6113e-01,  2.7641e-01,  2.9608e-01,  2.8059e-01],\n",
       "           [-2.1972e-02, -1.4927e-02, -8.0969e-03, -1.7325e-02],\n",
       "           [-1.4610e-01, -1.1322e-01, -7.1249e-02, -1.0665e-01],\n",
       "           ...,\n",
       "           [-6.0873e-01, -5.9993e-01, -6.0095e-01, -6.1131e-01],\n",
       "           [ 3.2954e-01,  3.3090e-01,  3.3003e-01,  3.2701e-01],\n",
       "           [ 1.5808e-01,  1.6735e-01,  1.6744e-01,  1.5893e-01]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 2.8059e-01,  2.6981e-01,  2.8223e-01,  2.7602e-01],\n",
       "           [-1.7325e-02, -2.0517e-02, -1.1976e-02, -1.6857e-02],\n",
       "           [-1.0665e-01, -1.2572e-01, -1.1081e-01, -1.1306e-01],\n",
       "           ...,\n",
       "           [-6.1131e-01, -6.1073e-01, -6.0607e-01, -6.0791e-01],\n",
       "           [ 3.2701e-01,  3.2761e-01,  3.2894e-01,  3.2697e-01],\n",
       "           [ 1.5893e-01,  1.5870e-01,  1.6260e-01,  1.6346e-01]],\n",
       " \n",
       "          [[ 2.6113e-01,  2.7641e-01,  2.9608e-01,  2.8059e-01],\n",
       "           [-2.1972e-02, -1.4927e-02, -8.0969e-03, -1.7325e-02],\n",
       "           [-1.4610e-01, -1.1322e-01, -7.1249e-02, -1.0665e-01],\n",
       "           ...,\n",
       "           [-6.0873e-01, -5.9993e-01, -6.0095e-01, -6.1131e-01],\n",
       "           [ 3.2954e-01,  3.3090e-01,  3.3003e-01,  3.2701e-01],\n",
       "           [ 1.5808e-01,  1.6735e-01,  1.6744e-01,  1.5893e-01]],\n",
       " \n",
       "          [[ 2.6113e-01,  2.7641e-01,  2.9608e-01,  2.8059e-01],\n",
       "           [-2.1972e-02, -1.4927e-02, -8.0969e-03, -1.7325e-02],\n",
       "           [-1.4610e-01, -1.1322e-01, -7.1249e-02, -1.0665e-01],\n",
       "           ...,\n",
       "           [-6.0873e-01, -5.9993e-01, -6.0095e-01, -6.1131e-01],\n",
       "           [ 3.2954e-01,  3.3090e-01,  3.3003e-01,  3.2701e-01],\n",
       "           [ 1.5808e-01,  1.6735e-01,  1.6744e-01,  1.5893e-01]]],\n",
       " \n",
       " \n",
       "         [[[ 2.4598e-01,  2.6940e-01,  2.7976e-01,  2.8612e-01],\n",
       "           [-2.3302e-02, -1.8430e-02, -1.7036e-02, -1.6584e-02],\n",
       "           [-1.0403e-01, -1.0833e-01, -1.0969e-01, -1.1153e-01],\n",
       "           ...,\n",
       "           [ 6.6371e-01,  6.7035e-01,  6.7272e-01,  6.7182e-01],\n",
       "           [-2.9193e-01, -2.8936e-01, -2.8868e-01, -2.8906e-01],\n",
       "           [-7.1945e-01, -7.2134e-01, -7.2174e-01, -7.2146e-01]],\n",
       " \n",
       "          [[ 2.9860e-01,  2.9570e-01,  2.4598e-01,  2.6940e-01],\n",
       "           [-2.0174e-02, -1.5319e-02, -2.3302e-02, -1.8430e-02],\n",
       "           [-1.0343e-01, -1.0832e-01, -1.0403e-01, -1.0833e-01],\n",
       "           ...,\n",
       "           [ 6.7209e-01,  6.6757e-01,  6.6371e-01,  6.7035e-01],\n",
       "           [-2.9302e-01, -2.9145e-01, -2.9193e-01, -2.8936e-01],\n",
       "           [-7.1734e-01, -7.1951e-01, -7.1945e-01, -7.2134e-01]],\n",
       " \n",
       "          [[ 2.7976e-01,  2.8612e-01,  2.8905e-01,  2.6514e-01],\n",
       "           [-1.7036e-02, -1.6584e-02, -1.6028e-02, -6.9291e-02],\n",
       "           [-1.0969e-01, -1.1153e-01, -1.0869e-01, -2.7058e-02],\n",
       "           ...,\n",
       "           [ 6.7272e-01,  6.7182e-01,  6.7025e-01,  6.3351e-01],\n",
       "           [-2.8868e-01, -2.8906e-01, -2.8951e-01, -4.3393e-01],\n",
       "           [-7.2174e-01, -7.2146e-01, -7.2119e-01, -5.7465e-01]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 2.6972e-01,  2.7676e-01,  2.7637e-01,  3.1094e-01],\n",
       "           [-1.6811e-02, -1.6659e-02, -1.8801e-02, -1.0813e-02],\n",
       "           [-1.0831e-01, -1.1122e-01, -1.0940e-01, -1.1412e-01],\n",
       "           ...,\n",
       "           [ 6.5430e-01,  6.5560e-01,  6.5618e-01,  6.5623e-01],\n",
       "           [-4.0355e-01, -4.0356e-01, -4.0410e-01, -4.0375e-01],\n",
       "           [-6.0469e-01, -6.0457e-01, -6.0395e-01, -6.0431e-01]],\n",
       " \n",
       "          [[ 2.8612e-01,  2.8905e-01,  2.6514e-01,  2.8519e-01],\n",
       "           [-1.6584e-02, -1.6028e-02, -6.9291e-02, -1.1691e-02],\n",
       "           [-1.1153e-01, -1.0869e-01, -2.7058e-02, -1.1327e-01],\n",
       "           ...,\n",
       "           [ 6.7182e-01,  6.7025e-01,  6.3351e-01,  6.4738e-01],\n",
       "           [-2.8906e-01, -2.8951e-01, -4.3393e-01, -4.0451e-01],\n",
       "           [-7.2146e-01, -7.2119e-01, -5.7465e-01, -6.0428e-01]],\n",
       " \n",
       "          [[ 2.7976e-01,  2.8612e-01,  2.8905e-01,  2.6514e-01],\n",
       "           [-1.7036e-02, -1.6584e-02, -1.6028e-02, -6.9291e-02],\n",
       "           [-1.0969e-01, -1.1153e-01, -1.0869e-01, -2.7058e-02],\n",
       "           ...,\n",
       "           [ 6.7272e-01,  6.7182e-01,  6.7025e-01,  6.3351e-01],\n",
       "           [-2.8868e-01, -2.8906e-01, -2.8951e-01, -4.3393e-01],\n",
       "           [-7.2174e-01, -7.2146e-01, -7.2119e-01, -5.7465e-01]]],\n",
       " \n",
       " \n",
       "         [[[ 2.7203e-01,  2.9180e-01,  2.7130e-01,  2.6808e-01],\n",
       "           [-1.4210e-02, -1.7885e-02, -8.4430e-03, -1.3560e-02],\n",
       "           [-1.0127e-01, -1.3638e-01, -1.0389e-01, -9.1552e-02],\n",
       "           ...,\n",
       "           [-6.7041e-01, -6.6854e-01, -6.7689e-01, -6.7210e-01],\n",
       "           [-1.6474e-02, -1.7510e-02, -1.7732e-02, -2.1206e-02],\n",
       "           [-1.8816e-01, -1.8905e-01, -1.8206e-01, -1.8377e-01]],\n",
       " \n",
       "          [[ 2.7203e-01,  2.9180e-01,  2.7130e-01,  2.6808e-01],\n",
       "           [-1.4210e-02, -1.7885e-02, -8.4430e-03, -1.3560e-02],\n",
       "           [-1.0127e-01, -1.3638e-01, -1.0389e-01, -9.1552e-02],\n",
       "           ...,\n",
       "           [-6.7041e-01, -6.6854e-01, -6.7689e-01, -6.7210e-01],\n",
       "           [-1.6474e-02, -1.7510e-02, -1.7732e-02, -2.1206e-02],\n",
       "           [-1.8816e-01, -1.8905e-01, -1.8206e-01, -1.8377e-01]],\n",
       " \n",
       "          [[ 2.9180e-01,  2.7130e-01,  2.6808e-01,  2.7888e-01],\n",
       "           [-1.7885e-02, -8.4430e-03, -1.3560e-02, -2.1946e-02],\n",
       "           [-1.3638e-01, -1.0389e-01, -9.1552e-02, -1.1146e-01],\n",
       "           ...,\n",
       "           [-6.6854e-01, -6.7689e-01, -6.7210e-01, -6.6634e-01],\n",
       "           [-1.7510e-02, -1.7732e-02, -2.1206e-02, -2.2213e-02],\n",
       "           [-1.8905e-01, -1.8206e-01, -1.8377e-01, -1.8788e-01]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 2.7468e-01,  2.7203e-01,  2.9180e-01,  2.7130e-01],\n",
       "           [-1.6087e-02, -1.4210e-02, -1.7885e-02, -8.4430e-03],\n",
       "           [-1.0359e-01, -1.0127e-01, -1.3638e-01, -1.0389e-01],\n",
       "           ...,\n",
       "           [-6.7320e-01, -6.7041e-01, -6.6854e-01, -6.7689e-01],\n",
       "           [-1.5604e-02, -1.6474e-02, -1.7510e-02, -1.7732e-02],\n",
       "           [-1.8641e-01, -1.8816e-01, -1.8905e-01, -1.8206e-01]],\n",
       " \n",
       "          [[ 2.7219e-01,  2.7403e-01,  2.8743e-01,  2.7468e-01],\n",
       "           [-1.6641e-02, -1.5631e-02, -1.9775e-02, -1.6087e-02],\n",
       "           [-1.0117e-01, -1.0094e-01, -1.2062e-01, -1.0359e-01],\n",
       "           ...,\n",
       "           [-6.7339e-01, -6.7061e-01, -6.6912e-01, -6.7320e-01],\n",
       "           [-1.5843e-02, -1.6182e-02, -1.6451e-02, -1.5604e-02],\n",
       "           [-1.8611e-01, -1.8817e-01, -1.8922e-01, -1.8641e-01]],\n",
       " \n",
       "          [[ 2.8291e-01,  2.7926e-01,  2.8143e-01,  2.0065e-01],\n",
       "           [-1.8573e-02, -1.9091e-02, -1.8298e-02,  3.9281e-02],\n",
       "           [-1.0760e-01, -1.0716e-01, -1.1368e-01, -7.5072e-02],\n",
       "           ...,\n",
       "           [-3.6444e-01, -3.6545e-01, -3.6640e-01, -6.7571e-01],\n",
       "           [-1.9227e-01, -1.9134e-01, -1.9033e-01, -3.5941e-03],\n",
       "           [-3.0694e-01, -3.0697e-01, -3.0712e-01, -1.9130e-01]]]]),\n",
       " tensor([[[[ 2.7547e-01,  2.8924e-01,  2.8851e-01,  2.6706e-01],\n",
       "           [-1.8872e-02, -7.1438e-03, -9.1961e-03, -2.4213e-02],\n",
       "           [-1.0892e-01, -9.1342e-02, -1.0336e-01, -1.2388e-01],\n",
       "           ...,\n",
       "           [-5.9240e-01, -5.9256e-01, -6.0112e-01, -6.0561e-01],\n",
       "           [ 3.3563e-01,  3.3557e-01,  3.3130e-01,  3.2850e-01],\n",
       "           [ 1.6934e-01,  1.6925e-01,  1.6516e-01,  1.6394e-01]],\n",
       " \n",
       "          [[ 2.7439e-01,  2.8075e-01,  2.9668e-01,  2.8039e-01],\n",
       "           [-1.7725e-02, -3.5205e-02,  8.0887e-03, -1.0652e-02],\n",
       "           [-1.0455e-01, -3.5772e-01, -5.3059e-02, -8.2626e-02],\n",
       "           ...,\n",
       "           [-6.1439e-01, -9.2922e-01, -8.6305e-01, -8.8284e-01],\n",
       "           [-1.1816e-01,  1.3462e-01,  1.4225e-01,  1.3267e-01],\n",
       "           [-1.4430e-01,  5.2599e-02,  1.0599e-01,  9.5202e-02]],\n",
       " \n",
       "          [[ 2.8223e-01,  2.7602e-01,  2.7537e-01,  2.9332e-01],\n",
       "           [-1.1976e-02, -1.6857e-02, -1.6495e-02, -8.3139e-03],\n",
       "           [-1.1081e-01, -1.1306e-01, -1.1929e-01, -8.6588e-02],\n",
       "           ...,\n",
       "           [-6.0607e-01, -6.0791e-01, -6.0719e-01, -6.0672e-01],\n",
       "           [ 3.2894e-01,  3.2697e-01,  3.2641e-01,  3.2540e-01],\n",
       "           [ 1.6260e-01,  1.6346e-01,  1.6528e-01,  1.6750e-01]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 2.8761e-01,  2.7728e-01,  2.7547e-01,  2.8924e-01],\n",
       "           [-4.4451e-03, -1.5177e-02, -1.8872e-02, -7.1438e-03],\n",
       "           [-1.0289e-01, -1.1830e-01, -1.0892e-01, -9.1342e-02],\n",
       "           ...,\n",
       "           [-5.8707e-01, -5.9332e-01, -5.9240e-01, -5.9256e-01],\n",
       "           [ 3.4109e-01,  3.3638e-01,  3.3563e-01,  3.3557e-01],\n",
       "           [ 1.6726e-01,  1.6692e-01,  1.6934e-01,  1.6925e-01]],\n",
       " \n",
       "          [[ 2.9943e-01,  2.2834e-01,  2.8210e-01,  2.8368e-01],\n",
       "           [-1.1365e-02, -1.2850e-02, -3.2248e-02, -2.2701e-02],\n",
       "           [-1.0096e-01, -6.4602e-02, -9.9328e-02, -1.0889e-01],\n",
       "           ...,\n",
       "           [-5.5503e-01, -5.5537e-01, -5.5965e-01, -5.6354e-01],\n",
       "           [ 3.4919e-01,  3.5090e-01,  3.4746e-01,  3.4470e-01],\n",
       "           [ 1.9452e-01,  1.9157e-01,  1.9156e-01,  1.9100e-01]],\n",
       " \n",
       "          [[ 3.0026e-01,  2.8281e-01,  3.0770e-01,  2.9943e-01],\n",
       "           [-3.7450e-02, -3.7518e-02,  1.1907e-03, -1.1365e-02],\n",
       "           [-8.8811e-02, -1.4475e-01, -1.2077e-01, -1.0096e-01],\n",
       "           ...,\n",
       "           [-5.6277e-01, -5.6145e-01, -5.5738e-01, -5.5503e-01],\n",
       "           [ 3.4531e-01,  3.4706e-01,  3.4842e-01,  3.4919e-01],\n",
       "           [ 1.9102e-01,  1.9000e-01,  1.9286e-01,  1.9452e-01]]],\n",
       " \n",
       " \n",
       "         [[[ 3.5280e-01,  2.6906e-01,  1.9442e-01,  2.8131e-01],\n",
       "           [ 4.4743e-02, -2.0181e-02, -6.8855e-02,  1.2619e-02],\n",
       "           [-9.7056e-02, -1.5455e-01,  2.3566e-02, -1.3150e-02],\n",
       "           ...,\n",
       "           [-5.5578e-01, -5.7202e-01, -5.6207e-01, -5.7606e-01],\n",
       "           [ 2.6700e-01,  2.5091e-01,  2.5417e-01,  2.6493e-01],\n",
       "           [ 2.7955e-01,  2.7745e-01,  2.8342e-01,  2.6392e-01]],\n",
       " \n",
       "          [[ 3.2086e-01,  3.0536e-01,  2.7525e-01,  2.8591e-01],\n",
       "           [ 8.2959e-04,  9.1376e-03, -6.4348e-03, -1.6785e-02],\n",
       "           [-4.6410e-02, -6.7331e-02, -1.1794e-01, -9.7112e-02],\n",
       "           ...,\n",
       "           [-5.8169e-01, -6.0449e-01, -6.2307e-01, -6.2716e-01],\n",
       "           [ 1.7365e-01,  1.6555e-01,  1.5613e-01,  1.5199e-01],\n",
       "           [ 3.0794e-01,  2.9357e-01,  2.8253e-01,  2.8060e-01]],\n",
       " \n",
       "          [[ 4.0929e-01,  2.0586e-01,  1.1629e-01,  2.2167e-01],\n",
       "           [-3.6552e-02, -4.4459e-02, -3.2905e-02, -1.5153e-02],\n",
       "           [-9.7748e-02, -1.8450e-01, -6.8224e-02, -5.6281e-02],\n",
       "           ...,\n",
       "           [-5.7991e-01, -5.8134e-01, -5.4277e-01, -5.3076e-01],\n",
       "           [ 2.5733e-01,  2.5490e-01,  2.6359e-01,  2.7057e-01],\n",
       "           [ 2.6634e-01,  2.6691e-01,  2.9283e-01,  2.9782e-01]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 2.8989e-01,  2.5674e-01,  2.3544e-01,  2.4654e-01],\n",
       "           [-3.0142e-02, -3.6577e-02, -1.6281e-02, -7.1965e-03],\n",
       "           [-1.3711e-01, -1.2191e-01, -1.1339e-01, -1.1318e-01],\n",
       "           ...,\n",
       "           [-5.3448e-01, -5.3229e-01, -5.3151e-01, -5.3032e-01],\n",
       "           [ 2.6608e-01,  2.6446e-01,  2.6868e-01,  2.6987e-01],\n",
       "           [ 2.9792e-01,  3.0084e-01,  2.9855e-01,  2.9869e-01]],\n",
       " \n",
       "          [[ 3.0620e-01,  2.7964e-01,  2.8400e-01,  3.0672e-01],\n",
       "           [-1.7545e-02, -1.9873e-02, -1.4347e-02, -4.0476e-03],\n",
       "           [-1.1559e-01, -1.0563e-01, -1.1070e-01, -1.3324e-01],\n",
       "           ...,\n",
       "           [ 3.3820e-01,  3.3175e-01,  3.3049e-01,  3.2808e-01],\n",
       "           [-2.7334e-01, -2.7346e-01, -2.7248e-01, -2.7444e-01],\n",
       "           [-6.9310e-01, -6.9056e-01, -6.9104e-01, -6.8822e-01]],\n",
       " \n",
       "          [[ 2.7328e-01,  2.8792e-01,  2.7172e-01,  2.7247e-01],\n",
       "           [-1.4504e-02, -1.2886e-02, -2.2134e-02, -2.0010e-02],\n",
       "           [-1.2125e-01, -9.5515e-02, -1.1232e-01, -1.1310e-01],\n",
       "           ...,\n",
       "           [-5.6955e-01, -5.6784e-01, -5.7162e-01, -5.6907e-01],\n",
       "           [ 2.6193e-01,  2.6063e-01,  2.5947e-01,  2.6129e-01],\n",
       "           [ 2.7170e-01,  2.7409e-01,  2.7175e-01,  2.7258e-01]]],\n",
       " \n",
       " \n",
       "         [[[ 2.8219e-01,  4.3116e-01,  2.1268e-01,  2.8721e-01],\n",
       "           [-1.7968e-02,  2.4635e-01, -1.7124e-02, -1.2640e-02],\n",
       "           [-1.0000e-01,  2.8094e-01, -1.2401e-01, -1.0642e-01],\n",
       "           ...,\n",
       "           [-5.1539e-01, -9.0047e-01, -8.8433e-01, -8.8064e-01],\n",
       "           [ 2.3704e-01,  1.5434e-01,  4.4709e-02,  4.0530e-02],\n",
       "           [ 3.3095e-01,  5.9747e-02, -4.8157e-02, -4.7931e-02]],\n",
       " \n",
       "          [[ 2.9758e-01,  2.8224e-01,  2.7553e-01,  2.8028e-01],\n",
       "           [ 4.5975e-02, -6.4972e-03, -1.3269e-02, -2.0752e-03],\n",
       "           [-4.1356e-02, -1.1768e-01, -1.1992e-01, -9.4509e-02],\n",
       "           ...,\n",
       "           [-8.1422e-01, -8.4432e-01, -8.4850e-01, -8.4527e-01],\n",
       "           [ 1.5959e-01,  1.3860e-01,  1.3241e-01,  1.3051e-01],\n",
       "           [ 1.3586e-01,  1.2268e-01,  1.2201e-01,  1.2515e-01]],\n",
       " \n",
       "          [[ 2.8057e-01,  2.8972e-01,  2.8817e-01,  2.6987e-01],\n",
       "           [-1.4459e-02, -2.7785e-03, -8.6842e-03, -2.7444e-02],\n",
       "           [-1.0774e-01, -9.6754e-02, -9.0096e-02, -1.1396e-01],\n",
       "           ...,\n",
       "           [-5.9349e-01, -5.9646e-01, -6.0468e-01, -6.1179e-01],\n",
       "           [ 2.4022e-01,  2.3784e-01,  2.3229e-01,  2.3002e-01],\n",
       "           [ 2.6694e-01,  2.6606e-01,  2.6291e-01,  2.5855e-01]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 2.8154e-01,  2.7300e-01,  2.9950e-01,  2.7753e-01],\n",
       "           [-1.8856e-02, -2.0938e-02, -1.2221e-02, -1.9084e-02],\n",
       "           [-1.0568e-01, -1.0664e-01, -1.1499e-01, -1.0645e-01],\n",
       "           ...,\n",
       "           [ 4.1425e-01,  4.1340e-01,  4.1317e-01,  4.0824e-01],\n",
       "           [-2.7653e-01, -2.7538e-01, -2.7453e-01, -2.7638e-01],\n",
       "           [-7.1449e-01, -7.1542e-01, -7.1621e-01, -7.1298e-01]],\n",
       " \n",
       "          [[ 2.4447e-01,  2.3558e-01,  2.6215e-01,  2.8750e-01],\n",
       "           [-3.8244e-02, -3.2386e-02, -5.6822e-03, -1.8892e-02],\n",
       "           [-1.3422e-01, -1.1778e-01, -1.3254e-01, -1.0870e-01],\n",
       "           ...,\n",
       "           [-5.5091e-01, -5.4042e-01, -5.3611e-01, -5.2974e-01],\n",
       "           [ 2.5239e-01,  2.5937e-01,  2.6154e-01,  2.5928e-01],\n",
       "           [ 2.9372e-01,  2.9764e-01,  2.9970e-01,  3.0638e-01]],\n",
       " \n",
       "          [[ 2.7699e-01,  2.7666e-01,  2.7873e-01,  2.7873e-01],\n",
       "           [-1.4018e-02, -2.3890e-02, -1.7410e-02, -1.5262e-02],\n",
       "           [-1.0759e-01, -1.1375e-01, -1.0508e-01, -1.0640e-01],\n",
       "           ...,\n",
       "           [-8.5876e-01, -8.5818e-01, -8.5612e-01, -8.5734e-01],\n",
       "           [ 1.1840e-01,  1.1723e-01,  1.1965e-01,  1.2018e-01],\n",
       "           [ 1.1867e-01,  1.1937e-01,  1.2031e-01,  1.1928e-01]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 2.7930e-01,  2.7896e-01,  2.7816e-01,  2.7682e-01],\n",
       "           [-1.5093e-02, -1.2726e-02, -1.6448e-02, -1.7417e-02],\n",
       "           [-1.1368e-01, -1.1012e-01, -1.1120e-01, -1.1113e-01],\n",
       "           ...,\n",
       "           [-9.3374e-01, -9.3280e-01, -9.3275e-01, -9.3188e-01],\n",
       "           [ 1.1387e-01,  1.1271e-01,  1.1106e-01,  1.1075e-01],\n",
       "           [ 6.3989e-02,  6.5167e-02,  6.5788e-02,  6.6548e-02]],\n",
       " \n",
       "          [[ 2.7231e-01,  2.7265e-01,  2.5522e-01,  2.9669e-01],\n",
       "           [-1.6847e-02, -1.8543e-02, -1.8994e-02, -1.4363e-02],\n",
       "           [-1.0673e-01, -1.0730e-01, -1.0243e-01, -1.1496e-01],\n",
       "           ...,\n",
       "           [ 4.0748e-01,  4.0782e-01,  4.0978e-01,  4.1354e-01],\n",
       "           [-3.4101e-01, -3.4122e-01, -3.4071e-01, -3.4004e-01],\n",
       "           [-6.4747e-01, -6.4735e-01, -6.4838e-01, -6.5004e-01]],\n",
       " \n",
       "          [[ 1.4104e-01,  1.8571e-01,  2.3762e-01,  3.6711e-01],\n",
       "           [-3.2109e-02, -2.2456e-02, -7.8212e-04, -4.9324e-03],\n",
       "           [-2.1246e-01, -1.2831e-01, -1.1448e-01, -1.0396e-01],\n",
       "           ...,\n",
       "           [-5.2785e-01, -4.8860e-01, -4.7401e-01, -4.7245e-01],\n",
       "           [ 3.6301e-01,  3.7439e-01,  3.8316e-01,  3.8443e-01],\n",
       "           [ 2.0635e-01,  2.3476e-01,  2.3897e-01,  2.3898e-01]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 2.0199e-01,  3.2597e-01,  4.3452e-01,  4.4308e-01],\n",
       "           [-4.5510e-03, -9.4820e-02, -7.9175e-02, -4.2983e-03],\n",
       "           [-6.8593e-02, -1.2225e-01, -1.3709e-01, -8.0410e-03],\n",
       "           ...,\n",
       "           [-6.2005e-01, -6.2645e-01, -6.0687e-01, -5.4433e-01],\n",
       "           [ 3.1904e-01,  3.1895e-01,  3.3578e-01,  3.6920e-01],\n",
       "           [ 1.6067e-01,  1.5243e-01,  1.4955e-01,  1.7604e-01]],\n",
       " \n",
       "          [[ 2.6900e-01,  2.7254e-01,  2.8726e-01,  2.7112e-01],\n",
       "           [-1.8746e-02, -1.7668e-02, -1.5712e-02, -1.9741e-02],\n",
       "           [-1.0484e-01, -1.0570e-01, -1.1277e-01, -1.0295e-01],\n",
       "           ...,\n",
       "           [ 3.3143e-01,  3.3367e-01,  3.3474e-01,  3.3246e-01],\n",
       "           [-3.8999e-01, -3.8922e-01, -3.8894e-01, -3.8974e-01],\n",
       "           [-5.7406e-01, -5.7563e-01, -5.7629e-01, -5.7467e-01]],\n",
       " \n",
       "          [[ 2.4694e-01,  2.7552e-01,  2.8438e-01,  2.7426e-01],\n",
       "           [ 2.8695e-03, -6.3160e-03, -1.0699e-02, -1.5223e-02],\n",
       "           [-1.3666e-01, -1.0366e-01, -1.0581e-01, -1.1184e-01],\n",
       "           ...,\n",
       "           [-7.3313e-01, -7.3271e-01, -7.3214e-01, -7.3432e-01],\n",
       "           [ 1.3613e-01,  1.2462e-01,  1.2156e-01,  1.1860e-01],\n",
       "           [ 2.0674e-01,  2.0938e-01,  2.1028e-01,  2.0912e-01]]],\n",
       " \n",
       " \n",
       "         [[[ 2.8302e-01,  2.7875e-01,  2.7338e-01,  3.7108e-01],\n",
       "           [-1.3180e-02, -1.6410e-02,  8.1628e-03,  6.9089e-02],\n",
       "           [-1.1604e-01, -1.1355e-01, -7.9751e-02,  1.0316e-01],\n",
       "           ...,\n",
       "           [-8.1881e-01, -8.2318e-01, -8.2579e-01, -8.6403e-01],\n",
       "           [ 1.9653e-01,  1.9399e-01,  1.9314e-01,  1.8807e-01],\n",
       "           [-6.2864e-02, -6.1185e-02, -5.9296e-02, -1.0887e-02]],\n",
       " \n",
       "          [[ 2.8209e-01,  2.7282e-01,  2.8136e-01,  2.8279e-01],\n",
       "           [-1.6280e-02, -2.9074e-02, -1.9028e-02, -2.9776e-02],\n",
       "           [-9.1736e-02, -1.1731e-01, -8.8019e-02, -9.1010e-02],\n",
       "           ...,\n",
       "           [-8.1978e-01, -8.2415e-01, -8.1898e-01, -8.2403e-01],\n",
       "           [ 1.4520e-01,  1.4505e-01,  1.4955e-01,  1.5154e-01],\n",
       "           [ 1.3883e-01,  1.3550e-01,  1.3743e-01,  1.3241e-01]],\n",
       " \n",
       "          [[ 2.7400e-01,  2.5751e-01,  2.5854e-01,  2.7042e-01],\n",
       "           [-1.4413e-02, -1.5255e-02, -1.9929e-02, -2.3635e-02],\n",
       "           [-1.1052e-01, -1.0757e-01, -1.0444e-01, -1.0541e-01],\n",
       "           ...,\n",
       "           [ 5.8861e-01,  5.8995e-01,  5.9503e-01,  5.9955e-01],\n",
       "           [-5.3312e-02, -5.4392e-02, -5.4897e-02, -5.3413e-02],\n",
       "           [-9.7146e-01, -9.7035e-01, -9.6983e-01, -9.7130e-01]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 5.5138e-02,  1.3592e-01,  3.2444e-01,  2.9530e-01],\n",
       "           [-6.7381e-02, -2.0143e-02, -4.3164e-02, -3.8200e-02],\n",
       "           [-3.1083e-01, -1.5513e-01, -9.9709e-02, -1.4889e-01],\n",
       "           ...,\n",
       "           [-5.6547e-01, -4.7381e-01, -4.2889e-01, -4.2022e-01],\n",
       "           [ 1.9590e-01,  2.1568e-01,  2.1483e-01,  2.1937e-01],\n",
       "           [ 3.1202e-01,  3.7276e-01,  4.0658e-01,  4.1119e-01]],\n",
       " \n",
       "          [[ 2.9530e-01,  2.1496e-01,  1.7956e-01,  3.4791e-01],\n",
       "           [-3.8200e-02, -3.5510e-02,  4.3676e-03,  2.4223e-02],\n",
       "           [-1.4889e-01, -1.5118e-01, -1.0593e-01, -9.4165e-02],\n",
       "           ...,\n",
       "           [-4.2022e-01, -4.1485e-01, -4.0682e-01, -3.9457e-01],\n",
       "           [ 2.1937e-01,  2.1948e-01,  2.2051e-01,  2.2016e-01],\n",
       "           [ 4.1119e-01,  4.1513e-01,  4.2066e-01,  4.2986e-01]],\n",
       " \n",
       "          [[ 3.1866e-01,  1.5242e-01,  5.5138e-02,  1.3592e-01],\n",
       "           [-2.3410e-02, -1.3601e-02, -6.7381e-02, -2.0143e-02],\n",
       "           [-7.7431e-02, -1.0879e-01, -3.1083e-01, -1.5513e-01],\n",
       "           ...,\n",
       "           [-4.8535e-01, -4.8504e-01, -5.6547e-01, -4.7381e-01],\n",
       "           [ 1.9632e-01,  2.0294e-01,  1.9590e-01,  2.1568e-01],\n",
       "           [ 3.7167e-01,  3.6947e-01,  3.1202e-01,  3.7276e-01]]],\n",
       " \n",
       " \n",
       "         [[[ 7.6998e-02,  3.4334e-01,  3.2671e-01,  3.0568e-01],\n",
       "           [ 1.2475e-01, -3.3704e-03, -3.7999e-02, -5.5339e-02],\n",
       "           [ 1.0282e-01, -2.1747e-01, -2.0826e-01, -1.9141e-01],\n",
       "           ...,\n",
       "           [-8.1617e-01, -7.0665e-01, -7.2968e-01, -7.7031e-01],\n",
       "           [ 6.4664e-02,  5.4188e-03, -3.2762e-03,  6.5877e-03],\n",
       "           [-1.1201e-01, -1.7155e-01, -1.4757e-01, -1.1987e-01]],\n",
       " \n",
       "          [[ 3.0250e-01,  3.0583e-01,  2.7974e-01,  1.8426e-01],\n",
       "           [ 7.5384e-03, -4.1023e-02, -1.9785e-02, -6.9052e-02],\n",
       "           [-1.2009e-01, -8.7303e-02, -8.5073e-02, -1.0955e-01],\n",
       "           ...,\n",
       "           [-7.3672e-01, -7.4323e-01, -7.4852e-01, -7.6028e-01],\n",
       "           [ 2.7683e-01,  2.7219e-01,  2.6845e-01,  2.5506e-01],\n",
       "           [ 5.2737e-02,  5.3101e-02,  5.3198e-02,  7.2401e-02]],\n",
       " \n",
       "          [[ 3.0638e-01,  2.5625e-01,  2.7966e-01,  2.7125e-01],\n",
       "           [-1.8493e-02, -1.9401e-02, -1.7710e-02, -1.6500e-02],\n",
       "           [-1.2858e-01, -8.7495e-02, -1.1082e-01, -1.1184e-01],\n",
       "           ...,\n",
       "           [ 4.6836e-01,  4.5663e-01,  4.6265e-01,  4.6292e-01],\n",
       "           [-4.6829e-01, -4.7280e-01, -4.6930e-01, -4.6903e-01],\n",
       "           [-5.2927e-01, -5.2245e-01, -5.2721e-01, -5.2754e-01]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.0849e-01,  3.9011e-01,  1.7780e-01,  1.6438e-01],\n",
       "           [-4.6410e-03, -1.7978e-02, -2.6763e-02, -1.2985e-02],\n",
       "           [-6.0145e-02, -5.8127e-02, -1.8215e-01, -1.5209e-01],\n",
       "           ...,\n",
       "           [-7.9254e-01, -7.8632e-01, -7.7885e-01, -7.8913e-01],\n",
       "           [ 2.2125e-01,  2.1760e-01,  2.1252e-01,  2.1760e-01],\n",
       "           [-5.8310e-02, -7.2152e-02, -8.7312e-02, -6.8680e-02]],\n",
       " \n",
       "          [[ 2.8656e-01,  7.6998e-02,  3.4334e-01,  3.2671e-01],\n",
       "           [-2.2096e-02,  1.2475e-01, -3.3704e-03, -3.7999e-02],\n",
       "           [-1.1576e-01,  1.0282e-01, -2.1747e-01, -2.0826e-01],\n",
       "           ...,\n",
       "           [-5.2403e-01, -8.1617e-01, -7.0665e-01, -7.2968e-01],\n",
       "           [-9.3078e-02,  6.4664e-02,  5.4188e-03, -3.2762e-03],\n",
       "           [-2.5653e-01, -1.1201e-01, -1.7155e-01, -1.4757e-01]],\n",
       " \n",
       "          [[ 2.7125e-01,  2.7584e-01,  2.7093e-01,  2.7530e-01],\n",
       "           [-1.6500e-02, -1.6246e-02, -1.7950e-02, -1.8361e-02],\n",
       "           [-1.1184e-01, -1.1045e-01, -1.0416e-01, -1.0270e-01],\n",
       "           ...,\n",
       "           [ 4.6292e-01,  4.6396e-01,  4.6477e-01,  4.6609e-01],\n",
       "           [-4.6903e-01, -4.6976e-01, -4.6989e-01, -4.6898e-01],\n",
       "           [-5.2754e-01, -5.2696e-01, -5.2698e-01, -5.2816e-01]]]]),\n",
       " tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1])]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, num_workers=workers, shuffle=True)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=batch_size, num_workers=workers, shuffle=True)\n",
    "\n",
    "# Just testing the dataloader\n",
    "next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaring the model\n",
    "discriminator = Discriminator(input_size=encoding_size, device='cuda')\n",
    "encoder = GRUEncoder(encoding_size=encoding_size, device='cuda')\n",
    "tnc_model = TNC(\n",
    "    encoder=encoder,\n",
    "    discriminator=discriminator,\n",
    "    window_size=window_size,\n",
    "    mc_sample_size=mc_sample_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(max_epochs=150, accelerator=\"gpu\", devices=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA RTX A6000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name          | Type              | Params\n",
      "----------------------------------------------------\n",
      "0 | encoder       | GRUEncoder        | 399 K \n",
      "1 | discriminator | Discriminator     | 881   \n",
      "2 | loss_func     | BCEWithLogitsLoss | 0     \n",
      "----------------------------------------------------\n",
      "400 K     Trainable params\n",
      "0         Non-trainable params\n",
      "400 K     Total params\n",
      "1.603     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 8/8 [00:17<00:00,  2.23s/it, v_num=55, train_loss=0.692]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|██████████| 8/8 [01:39<00:00, 12.42s/it, v_num=55, train_loss=0.692]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(tnc_model, train_dataloader, validation_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Optional\n",
    "\n",
    "from torchmetrics.functional import accuracy\n",
    "\n",
    "\n",
    "class StateClassifier(torch.nn.Module):\n",
    "    def __init__(self, input_size: int = 10, n_classes: int = 6):\n",
    "        super(StateClassifier, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.n_classes = n_classes\n",
    "        self.normalize = torch.nn.BatchNorm1d(self.input_size)\n",
    "        self.nn = torch.nn.Linear(self.input_size, self.n_classes)\n",
    "        torch.nn.init.xavier_uniform_(self.nn.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.normalize(x)\n",
    "        logits = self.nn(x)\n",
    "        return logits\n",
    "    \n",
    "class TNC_Classifier(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        encoder: torch.nn.Module,\n",
    "        classifier: torch.nn.Module,\n",
    "        lr: float = 1e-3,\n",
    "        weight_decay: float = 0.0,\n",
    "        task_class: str = \"multiclass\",\n",
    "        num_classes: int = 6\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder.to(self.device)\n",
    "        self.classifier = classifier.to(self.device)\n",
    "        self.learning_rate = lr\n",
    "        self.weight_decay = weight_decay\n",
    "        self.training_step_losses = []\n",
    "        self.validation_step_losses = []\n",
    "        self.loss_function = torch.nn.CrossEntropyLoss()\n",
    "        self.task_class = task_class\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "    def configure_optimizers(self) -> Any:\n",
    "        optimizer = torch.optim.Adam(\n",
    "            self.classifier.parameters(), lr=self.learning_rate, weight_decay=self.weight_decay\n",
    "        )\n",
    "        return optimizer\n",
    "    \n",
    "    def forward(self, x):\n",
    "        encodings = self.encoder(x)\n",
    "        predictions = self.classifier(encodings)\n",
    "        return predictions\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        predictions = self.forward(x)\n",
    "        loss = self.loss_function(predictions, y.long())\n",
    "        self.training_step_losses.append(loss)\n",
    "        return loss\n",
    "    \n",
    "    def on_train_epoch_end(self) -> None:\n",
    "        # do something with all training_step outputs, for example:\n",
    "        epoch_mean = torch.stack(self.training_step_losses).mean()\n",
    "        self.log(\"train_loss\", epoch_mean, on_epoch=True, on_step=False, prog_bar=True, logger=True)\n",
    "        # free up the memory\n",
    "        self.training_step_losses.clear()\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, acc = self._shared_eval_step(batch, batch_idx)\n",
    "        self.validation_step_losses.append(loss)\n",
    "        metrics = {\"val_acc\": acc, \"val_loss\": loss}\n",
    "        self.log_dict(metrics)\n",
    "        return metrics\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss, acc = self._shared_eval_step(batch, batch_idx)\n",
    "        metrics = {\"test_acc\": acc, \"test_loss\": loss}\n",
    "        self.log_dict(metrics)\n",
    "        return metrics\n",
    "\n",
    "        \n",
    "    def on_validation_epoch_end(self) -> None:\n",
    "        # do something with all training_step outputs, for example:\n",
    "        epoch_mean = torch.stack(self.validation_step_losses).mean()\n",
    "        self.log(\"val_loss\", epoch_mean, on_epoch=True, on_step=False, prog_bar=True, logger=True)\n",
    "        # free up the memory\n",
    "        self.validation_step_losses.clear()\n",
    "\n",
    "    def _shared_eval_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        predictions = self.forward(x)\n",
    "        loss = self.loss_function(predictions, y.long())\n",
    "        acc = accuracy(torch.argmax(predictions, dim=1), y.long(), task=self.task_class, num_classes=self.num_classes)\n",
    "        return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21, 561, 281), (21, 281), (9, 561, 288), (9, 288))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = Path('data/TNC/HAR_data')\n",
    "x_train = np.load(data_path/'x_train.npy')\n",
    "y_train = np.load(data_path/'y_train.npy')\n",
    "x_test = np.load(data_path/'x_test.npy')\n",
    "y_test = np.load(data_path/'y_test.npy')\n",
    "\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 9)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SimpleDataset:\n",
    "    def __init__(self, X, y=None):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.y is not None:\n",
    "            return self.X[idx].astype(np.float32), self.y[idx].astype(np.float32)\n",
    "        else:\n",
    "            return self.X[idx].astype(np.float32)\n",
    "        \n",
    "train_dataset = SimpleDataset(x_train)\n",
    "test_dataset = SimpleDataset(x_test, y_test)\n",
    "len(train_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_simulated_dataset(\n",
    "    X_train, Y_train, X_test, Y_test, window_size=50, batch_size=100\n",
    "):\n",
    "    n_train = int(0.8 * len(X_train))\n",
    "    n_valid = len(X_train) - n_train\n",
    "    n_test = len(X_test)\n",
    "    x_train, y_train = X_train[:n_train], Y_train[:n_train]\n",
    "    x_valid, y_valid = X_train[n_train:], Y_train[n_train:]\n",
    "    x_test, y_test = X_test, Y_test\n",
    "\n",
    "    datasets = []\n",
    "    for x, y, size in [\n",
    "        (x_train, y_train, n_train),\n",
    "        (x_test, y_test, n_test),\n",
    "        (x_valid, y_valid, n_valid),\n",
    "    ]:\n",
    "        T = x.shape[-1]\n",
    "        windows = np.split(\n",
    "            x[:, :, : window_size * (T // window_size)], (T // window_size), -1\n",
    "        )\n",
    "        windows = np.concatenate(windows, 0)\n",
    "        labels = np.split(\n",
    "            y[:, : window_size * (T // window_size)], (T // window_size), -1\n",
    "        )\n",
    "        labels = np.round(np.mean(np.concatenate(labels, 0), -1))\n",
    "        dset = SimpleDataset(windows, labels)\n",
    "        datasets.append(dset)\n",
    "\n",
    "    trainset, testset, validset = datasets[0], datasets[1], datasets[2]\n",
    "    train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "    valid_loader = DataLoader(validset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(testset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    return train_loader, valid_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, valid_loader, test_loader = create_simulated_dataset(x_train, y_train, x_test, y_test, window_size=50, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_size = 10\n",
    "n_classes = 6\n",
    "\n",
    "classifier = StateClassifier(input_size=encoding_size, n_classes=n_classes)\n",
    "tnc_classifier = TNC_Classifier(encoder, classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(max_epochs=1000, accelerator=\"gpu\", devices=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | encoder       | GRUEncoder       | 399 K \n",
      "1 | classifier    | StateClassifier  | 86    \n",
      "2 | loss_function | CrossEntropyLoss | 0     \n",
      "---------------------------------------------------\n",
      "399 K     Trainable params\n",
      "0         Non-trainable params\n",
      "399 K     Total params\n",
      "1.600     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  80%|████████  | 4/5 [00:00<00:00, 68.53it/s, v_num=66]           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 5/5 [00:00<00:00, 45.61it/s, v_num=66, val_loss=1.330, train_loss=0.485]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 5/5 [00:00<00:00, 34.44it/s, v_num=66, val_loss=1.330, train_loss=0.485]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(tnc_classifier, train_dataloaders=train_loader, val_dataloaders=valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 3/3 [00:00<00:00,  4.32it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.8444444537162781\n",
      "        test_loss           0.6172979474067688\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_acc': 0.8444444537162781, 'test_loss': 0.6172979474067688}]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(tnc_classifier, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
