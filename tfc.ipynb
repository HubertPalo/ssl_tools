{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.10/site-packages/umap/distances.py:1063: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/home/vscode/.local/lib/python3.10/site-packages/umap/distances.py:1071: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/home/vscode/.local/lib/python3.10/site-packages/umap/distances.py:1086: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/home/vscode/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/vscode/.local/lib/python3.10/site-packages/umap/umap_.py:660: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from typing import List, Tuple, Any\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from ssl_tools.transforms import *\n",
    "\n",
    "from typing import Any\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "\n",
    "class TFCContrastiveDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data: torch.Tensor,\n",
    "        labels: torch.Tensor = None,\n",
    "        length_alignment: int = 178,\n",
    "        time_transforms: Union[Transform, List[Transform]] = None,\n",
    "        frequency_transforms: Union[Transform, List[Transform]] = None,\n",
    "    ):\n",
    "        assert len(data) == len(labels), \"Data and labels must have the same length\"\n",
    "        \n",
    "        self.data_time = data\n",
    "        self.labels = labels\n",
    "        self.length_alignment = length_alignment\n",
    "        self.time_transforms = time_transforms or []\n",
    "        self.frequency_transforms = frequency_transforms or []\n",
    "        \n",
    "        if not isinstance(self.time_transforms, list):\n",
    "            self.time_transforms = [self.time_transforms]\n",
    "        if not isinstance(self.frequency_transforms, list):\n",
    "            self.frequency_transforms = [self.frequency_transforms]\n",
    "\n",
    "        if len(self.data_time.shape) < 3:\n",
    "            self.data_time = self.data_time.unsqueeze(2)\n",
    "\n",
    "        if self.data_time.shape.index(min(self.data_time.shape)) != 1:\n",
    "            self.data_time = self.data_time.permute(0, 2, 1)\n",
    "\n",
    "        \"\"\"Align the data to the same length, removing the extra features\"\"\"\n",
    "        self.data_time = self.data_time[:, :1, : self.length_alignment]\n",
    "        \n",
    "        \"\"\"Calculcate the FFT of the data and apply the transforms (if any)\"\"\"\n",
    "        self.data_freq = torch.fft.fft(self.data_time).abs()\n",
    "        \n",
    "        # This could be done in the __getitem__ method\n",
    "        # For now, we do it here to be more similar to the original implementation\n",
    "        self.data_time_augmented = self.apply_transforms(self.data_time, self.time_transforms)\n",
    "        self.data_freq_augmented = self.apply_transforms(self.data_freq, self.frequency_transforms)\n",
    "        \n",
    "    def apply_transforms(self, x: torch.Tensor, transforms: List[Transform]) -> torch.Tensor:\n",
    "        for transform in transforms:\n",
    "            x = transform.fit_transform(x)\n",
    "        return x\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data_time)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # Time processing\n",
    "        return (\n",
    "            self.data_time[index].float(),\n",
    "            self.labels[index],\n",
    "            self.data_time_augmented[index].float(),\n",
    "            self.data_freq[index].float(),\n",
    "            self.data_freq_augmented[index].float(),\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-C Pre-train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([371055, 1, 178])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = Path(\"data/TFC/SleepEEG\")\n",
    "\n",
    "dataset = torch.load(data_path / \"train.pt\")\n",
    "X_train, y_train = dataset[\"samples\"], dataset[\"labels\"]\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "jitter_ratio = 2\n",
    "length_alignment = 178\n",
    "drop_last = True\n",
    "batch_size = 128\n",
    "num_workers = 10\n",
    "learning_rate = 3e-4\n",
    "temperature = 0.2\n",
    "use_cosine_similarity = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_transforms = [\n",
    "    AddGaussianNoise(std=jitter_ratio)\n",
    "]\n",
    "\n",
    "frequency_transforms = [\n",
    "    AddRemoveFrequency()\n",
    "]\n",
    "\n",
    "train_dataset = TFCContrastiveDataset(\n",
    "    data=X_train,\n",
    "    labels=y_train,\n",
    "    time_transforms=time_transforms,\n",
    "    frequency_transforms=frequency_transforms,\n",
    ")\n",
    "\n",
    "len(train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,\n",
       " torch.Size([128, 1, 178]),\n",
       " torch.Size([128]),\n",
       " torch.Size([128, 1, 178]),\n",
       " torch.Size([128, 1, 178]),\n",
       " torch.Size([128, 1, 178]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=drop_last,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "test_batch = next(iter(train_loader))\n",
    "len(test_batch), test_batch[0].shape, test_batch[1].shape, test_batch[2].shape, test_batch[3].shape, test_batch[4].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NTXentLoss_poly(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        batch_size,\n",
    "        temperature: float = 0.2,\n",
    "        use_cosine_similarity: bool = True,\n",
    "        device: str = \"cpu\",\n",
    "    ):\n",
    "        super(NTXentLoss_poly, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.temperature = temperature\n",
    "        self.device = device\n",
    "        self.softmax = torch.nn.Softmax(dim=-1)\n",
    "        self.mask_samples_from_same_repr = self._get_correlated_mask().type(torch.bool)\n",
    "        self.similarity_function = self._get_similarity_function(use_cosine_similarity)\n",
    "        self.criterion = torch.nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "\n",
    "    def _get_similarity_function(self, use_cosine_similarity):\n",
    "        if use_cosine_similarity:\n",
    "            self._cosine_similarity = torch.nn.CosineSimilarity(dim=-1)\n",
    "            return self._cosine_simililarity\n",
    "        else:\n",
    "            return self._dot_simililarity\n",
    "\n",
    "    def _get_correlated_mask(self):\n",
    "        diag = np.eye(2 * self.batch_size)\n",
    "        l1 = np.eye((2 * self.batch_size), 2 * self.batch_size, k=-self.batch_size)\n",
    "        l2 = np.eye((2 * self.batch_size), 2 * self.batch_size, k=self.batch_size)\n",
    "        mask = torch.from_numpy((diag + l1 + l2))\n",
    "        mask = (1 - mask).type(torch.bool)\n",
    "        return mask.to(self.device)\n",
    "\n",
    "    @staticmethod\n",
    "    def _dot_simililarity(x, y):\n",
    "        v = torch.tensordot(x.unsqueeze(1), y.T.unsqueeze(0), dims=2)\n",
    "        # x shape: (N, 1, C)\n",
    "        # y shape: (1, C, 2N)\n",
    "        # v shape: (N, 2N)\n",
    "        return v\n",
    "\n",
    "    def _cosine_simililarity(self, x, y):\n",
    "        # x shape: (N, 1, C)\n",
    "        # y shape: (1, 2N, C)\n",
    "        # v shape: (N, 2N)\n",
    "        v = self._cosine_similarity(x.unsqueeze(1), y.unsqueeze(0))\n",
    "        return v\n",
    "\n",
    "    def forward(self, zis, zjs):\n",
    "        representations = torch.cat([zjs, zis], dim=0)\n",
    "\n",
    "        similarity_matrix = self.similarity_function(representations, representations)\n",
    "\n",
    "        # filter out the scores from the positive samples\n",
    "        l_pos = torch.diag(similarity_matrix, self.batch_size)\n",
    "        r_pos = torch.diag(similarity_matrix, -self.batch_size)\n",
    "        positives = torch.cat([l_pos, r_pos]).view(2 * self.batch_size, 1)\n",
    "\n",
    "        negatives = similarity_matrix[self.mask_samples_from_same_repr].view(\n",
    "            2 * self.batch_size, -1\n",
    "        )\n",
    "\n",
    "        logits = torch.cat((positives, negatives), dim=1)\n",
    "        logits /= self.temperature\n",
    "\n",
    "        \"\"\"Criterion has an internal one-hot function. Here, make all positives as 1 while all negatives as 0. \"\"\"\n",
    "        labels = torch.zeros(2 * self.batch_size).to(self.device).long()\n",
    "        CE = self.criterion(logits, labels)\n",
    "\n",
    "        onehot_label = (\n",
    "            torch.cat(\n",
    "                (\n",
    "                    torch.ones(2 * self.batch_size, 1),\n",
    "                    torch.zeros(2 * self.batch_size, negatives.shape[-1]),\n",
    "                ),\n",
    "                dim=-1,\n",
    "            )\n",
    "            .to(self.device)\n",
    "            .long()\n",
    "        )\n",
    "        # Add poly loss\n",
    "        pt = torch.mean(onehot_label * torch.nn.functional.softmax(logits, dim=-1))\n",
    "\n",
    "        epsilon = self.batch_size\n",
    "        # loss = CE/ (2 * self.batch_size) + epsilon*(1-pt) # replace 1 by 1/self.batch_size\n",
    "        loss = CE / (2 * self.batch_size) + epsilon * (1 / self.batch_size - pt)\n",
    "        # loss = CE / (2 * self.batch_size)\n",
    "\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFC(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        time_encoder: nn.Module,\n",
    "        frequency_encoder: nn.Module,\n",
    "        time_projector: nn.Module,\n",
    "        frequency_projector: nn.Module,\n",
    "        nxtent_criterion: nn.Module,\n",
    "        lr: float = 1e-3,\n",
    "        loss_lambda: float = 0.2,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.time_encoder = time_encoder.to(self.device)\n",
    "        self.time_projector = time_projector.to(self.device)\n",
    "        self.frequency_encoder = frequency_encoder.to(self.device)\n",
    "        self.frequency_projector = frequency_projector.to(self.device)\n",
    "        self.learning_rate = lr\n",
    "        self.nxtent_criterion = nxtent_criterion.to(self.device)\n",
    "        self.loss_lambda = loss_lambda\n",
    "\n",
    "    def forward(self, x_in_t, x_in_f):\n",
    "        \"\"\"Use Transformer\"\"\"\n",
    "        x = self.time_encoder(x_in_t)\n",
    "        h_time = x.reshape(x.shape[0], -1)\n",
    "\n",
    "        \"\"\"Cross-space projector\"\"\"\n",
    "        z_time = self.time_projector(h_time)\n",
    "\n",
    "        \"\"\"Frequency-based contrastive encoder\"\"\"\n",
    "        f = self.frequency_encoder(x_in_f)\n",
    "        h_freq = f.reshape(f.shape[0], -1)\n",
    "\n",
    "        \"\"\"Cross-space projector\"\"\"\n",
    "        z_freq = self.frequency_projector(h_freq)\n",
    "\n",
    "        return h_time, z_time, h_freq, z_freq\n",
    "\n",
    "    def configure_optimizers(self) -> Any:\n",
    "        learnable_parameters = (\n",
    "            list(self.time_encoder.parameters()) +\n",
    "            list(self.time_projector.parameters()) +\n",
    "            list(self.frequency_encoder.parameters()) +\n",
    "            list(self.frequency_projector.parameters())\n",
    "        )\n",
    "        optimizer = torch.optim.Adam(learnable_parameters, lr=self.learning_rate)\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        data, labels, aug1, data_f, aug1_f = batch\n",
    "        \n",
    "        \"\"\"Producing embeddings\"\"\"\n",
    "        h_t, z_t, h_f, z_f = self(data, data_f)\n",
    "        h_t_aug, z_t_aug, h_f_aug, z_f_aug = self(aug1, aug1_f)\n",
    "        \n",
    "        \"\"\"Calculate losses\"\"\"\n",
    "        loss_time = self.nxtent_criterion(h_t, h_t_aug)\n",
    "        loss_freq = self.nxtent_criterion(h_f, h_f_aug)\n",
    "        loss_consistency = self.nxtent_criterion(z_t, z_f)\n",
    "        loss = self.loss_lambda * (loss_time + loss_freq) + loss_consistency\n",
    "        \n",
    "        # log loss, only to appear on epoch\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "time_encoder = TransformerEncoder(\n",
    "    TransformerEncoderLayer(\n",
    "        length_alignment, dim_feedforward=2 * length_alignment, nhead=2\n",
    "    ),\n",
    "    num_layers=2,\n",
    ")\n",
    "frequency_encoder = TransformerEncoder(\n",
    "    TransformerEncoderLayer(\n",
    "        length_alignment, dim_feedforward=2 * length_alignment, nhead=2\n",
    "    ),\n",
    "    num_layers=2,\n",
    ")\n",
    "\n",
    "time_projector = nn.Sequential(\n",
    "    nn.Linear(length_alignment, 256),\n",
    "    nn.BatchNorm1d(256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 128),\n",
    ")\n",
    "frequency_projector = nn.Sequential(\n",
    "    nn.Linear(length_alignment, 256),\n",
    "    nn.BatchNorm1d(256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 128),\n",
    ")\n",
    "\n",
    "nxtent = NTXentLoss_poly(\n",
    "    batch_size=batch_size,\n",
    "    temperature=temperature,\n",
    "    use_cosine_similarity=use_cosine_similarity,\n",
    "    device=\"cuda\",\n",
    ")\n",
    "\n",
    "tfc_model = TFC(\n",
    "    time_encoder=time_encoder,\n",
    "    frequency_encoder=frequency_encoder,\n",
    "    time_projector=time_projector,\n",
    "    frequency_projector=frequency_projector,\n",
    "    nxtent_criterion=nxtent,\n",
    "    lr=learning_rate,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/vscode/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:67: UserWarning: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "  warning_cache.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(max_epochs=1, accelerator=\"gpu\", devices=1, limit_train_batches=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA RTX A6000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name                | Type               | Params\n",
      "-----------------------------------------------------------\n",
      "0 | time_encoder        | TransformerEncoder | 510 K \n",
      "1 | time_projector      | Sequential         | 79.2 K\n",
      "2 | frequency_encoder   | TransformerEncoder | 510 K \n",
      "3 | frequency_projector | Sequential         | 79.2 K\n",
      "4 | nxtent_criterion    | NTXentLoss_poly    | 0     \n",
      "-----------------------------------------------------------\n",
      "1.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 M     Total params\n",
      "4.721     Total estimated model params size (MB)\n",
      "/home/vscode/.local/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:281: PossibleUserWarning: The number of training batches (10) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 10/10 [00:01<00:00,  7.14it/s, v_num=94, train_loss_step=8.520, train_loss_epoch=8.870]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 10/10 [00:01<00:00,  6.32it/s, v_num=94, train_loss_step=8.520, train_loss_epoch=8.870]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(tfc_model, train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-C Fine-Tune "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"data/TFC/Epilepsy\")\n",
    "\n",
    "dataset_train = torch.load(data_path / \"train.pt\")\n",
    "X_train, y_train = dataset[\"samples\"], dataset[\"labels\"]\n",
    "\n",
    "dataset_validation = torch.load(data_path / \"val.pt\")\n",
    "X_validation, y_validation = dataset[\"samples\"], dataset[\"labels\"]\n",
    "\n",
    "dataset_test = torch.load(data_path / \"test.pt\")\n",
    "X_test, y_test = dataset[\"samples\"], dataset[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 60\n",
    "n_classes = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TFCContrastiveDataset(\n",
    "    data=X_train,\n",
    "    labels=y_train,\n",
    "    time_transforms=None,\n",
    "    frequency_transforms=None,\n",
    ")\n",
    "\n",
    "validation_dataset = TFCContrastiveDataset(\n",
    "    data=X_validation,\n",
    "    labels=y_validation,\n",
    "    time_transforms=None,\n",
    "    frequency_transforms=None,\n",
    ")\n",
    "\n",
    "test_dataset = TFCContrastiveDataset(\n",
    "    data=X_test,\n",
    "    labels=y_test,\n",
    "    time_transforms=None,\n",
    "    frequency_transforms=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=drop_last,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "validation_loader = DataLoader(\n",
    "    validation_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=drop_last,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=drop_last,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import Any\n",
    "\n",
    "from torchmetrics.functional import accuracy\n",
    "\n",
    "\n",
    "class SimpleClassifier(torch.nn.Module):\n",
    "    def __init__(self, num_classes: int = 2):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.fc = torch.nn.Linear(2 * 128, 64)\n",
    "        self.fc2 = torch.nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        emb_flatten = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc(emb_flatten)\n",
    "        x = torch.sigmoid(x)\n",
    "        y = self.fc2(x)\n",
    "        return y\n",
    "\n",
    "\n",
    "class TFC_classifier(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        tfc_model: torch.nn.Module,\n",
    "        classifier: torch.nn.Module,\n",
    "        nxtent_criterion: nn.Module,\n",
    "        lr: float = 1e-3,\n",
    "        loss_lambda: float = 0.1,\n",
    "        n_classes: int = 2,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.tfc_model = tfc_model\n",
    "        self.classifier = classifier\n",
    "        self.nxtent_criterion = nxtent_criterion\n",
    "        self.learning_rate = lr\n",
    "        self.n_classes = n_classes\n",
    "        self.loss_lambda = loss_lambda\n",
    "        self.loss_func = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    def configure_optimizers(self) -> Any:\n",
    "        learnable_parameters = list(self.tfc_model.parameters()) + list(\n",
    "            self.classifier.parameters()\n",
    "        )\n",
    "        optimizer = torch.optim.Adam(learnable_parameters, lr=self.learning_rate)\n",
    "        return optimizer\n",
    "\n",
    "    def forward(self, x_in_t, x_in_f):\n",
    "        return self.tfc_model(x_in_t, x_in_f)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        data, labels, aug1, data_f, aug1_f = batch\n",
    "\n",
    "        \"\"\"Producing embeddings\"\"\"\n",
    "        h_t, z_t, h_f, z_f = self(data, data_f)\n",
    "        h_t_aug, z_t_aug, h_f_aug, z_f_aug = self(aug1, aug1_f)\n",
    "\n",
    "        \"\"\"Add supervised loss\"\"\"\n",
    "        fea_concat = torch.cat((z_t, z_f), dim=1)\n",
    "        predictions = self.classifier(fea_concat)\n",
    "        # fea_concat_flat = fea_concat.reshape(fea_concat.shape[0], -1)\n",
    "\n",
    "        \"\"\"Calculate losses\"\"\"\n",
    "        loss_time = self.nxtent_criterion(h_t, h_t_aug)\n",
    "        loss_freq = self.nxtent_criterion(h_f, h_f_aug)\n",
    "        loss_consistency = self.nxtent_criterion(z_t, z_f)\n",
    "        loss_p = self.loss_func(predictions, labels)\n",
    "        loss = loss_p + self.loss_lambda * (loss_time + loss_freq) + loss_consistency\n",
    "\n",
    "        self.log(\n",
    "            \"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True\n",
    "        )\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, acc = self._shared_eval_step(batch, batch_idx)\n",
    "        self.log(\n",
    "            \"val_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True\n",
    "        )\n",
    "        self.log(\n",
    "            \"val_acc\", acc, on_step=True, on_epoch=True, prog_bar=True, logger=True\n",
    "        )\n",
    "        return {\"val_loss\": loss, \"val_acc\": acc}\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss, acc = self._shared_eval_step(batch, batch_idx)\n",
    "        self.log(\n",
    "            \"test_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True\n",
    "        )\n",
    "        self.log(\n",
    "            \"test_acc\", acc, on_step=True, on_epoch=True, prog_bar=True, logger=True\n",
    "        )\n",
    "        return {\"test_loss\": loss, \"test_acc\": acc}\n",
    "\n",
    "    def _shared_eval_step(self, batch, batch_idx):\n",
    "        data, labels, aug1, data_f, aug1_f = batch\n",
    "\n",
    "        \"\"\"Producing embeddings\"\"\"\n",
    "        h_t, z_t, h_f, z_f = self(data, data_f)\n",
    "        h_t_aug, z_t_aug, h_f_aug, z_f_aug = self(aug1, aug1_f)\n",
    "        \n",
    "        # print(h_t.shape, z_t.shape, h_f.shape, z_f.shape, h_t_aug.shape, z_t_aug.shape, h_f_aug.shape, z_f_aug.shape)\n",
    "        loss_time = self.nxtent_criterion(h_t, h_t_aug)\n",
    "        loss_freq = self.nxtent_criterion(h_f, h_f_aug)\n",
    "        loss_consistency = self.nxtent_criterion(z_t, z_f)\n",
    "\n",
    "        \"\"\"Add supervised loss\"\"\"\n",
    "        fea_concat = torch.cat((z_t, z_f), dim=1)\n",
    "        predictions = self.classifier(fea_concat)\n",
    "        loss_p = self.loss_func(predictions, labels)\n",
    "        \n",
    "        loss = loss_p + self.loss_lambda * (loss_time + loss_freq) + loss_consistency\n",
    "\n",
    "        acc = accuracy(\n",
    "            torch.argmax(predictions, dim=1),\n",
    "            labels,\n",
    "            task=\"multiclass\",\n",
    "            num_classes=self.n_classes,\n",
    "        )\n",
    "\n",
    "        return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = SimpleClassifier(num_classes=n_classes)\n",
    "nxtent = NTXentLoss_poly(\n",
    "    batch_size=batch_size,\n",
    "    temperature=temperature,\n",
    "    use_cosine_similarity=use_cosine_similarity,\n",
    "    device=\"cuda\",\n",
    ")\n",
    "\n",
    "tfc_classifier = TFC_classifier(\n",
    "    tfc_model=tfc_model,\n",
    "    classifier=classifier,\n",
    "    nxtent_criterion=nxtent,\n",
    "    lr=learning_rate,\n",
    "    n_classes=n_classes,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(max_epochs=1, accelerator=\"gpu\", devices=1, limit_train_batches=10, limit_test_batches=10, limit_val_batches=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name             | Type             | Params\n",
      "------------------------------------------------------\n",
      "0 | tfc_model        | TFC              | 1.2 M \n",
      "1 | classifier       | SimpleClassifier | 16.8 K\n",
      "2 | nxtent_criterion | NTXentLoss_poly  | 0     \n",
      "3 | loss_func        | CrossEntropyLoss | 0     \n",
      "------------------------------------------------------\n",
      "1.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 M     Total params\n",
      "4.788     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 10/10 [00:02<00:00,  4.41it/s, v_num=95, train_loss_step=7.970, val_loss_step=8.830, val_acc_step=0.000, val_loss_epoch=8.430, val_acc_epoch=0.500, train_loss_epoch=8.050]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 10/10 [00:02<00:00,  4.08it/s, v_num=95, train_loss_step=7.970, val_loss_step=8.830, val_acc_step=0.000, val_loss_epoch=8.430, val_acc_epoch=0.500, train_loss_epoch=8.050]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(tfc_classifier, train_loader, validation_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 10/10 [00:00<00:00, 37.32it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_acc_epoch       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            0.5            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_loss_epoch      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     8.430386543273926     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_acc_epoch      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.5           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_loss_epoch     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    8.430386543273926    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss_epoch': 8.430386543273926, 'test_acc_epoch': 0.5}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(tfc_classifier, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
